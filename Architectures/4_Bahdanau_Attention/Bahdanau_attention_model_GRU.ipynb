{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112fb076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Device name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "writer = SummaryWriter('runs/Bhahdanau_attention_experiment_1')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "dc8a45bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127262</th>\n",
       "      <td>because he was, in fact, dyslexic.</td>\n",
       "      <td>क्योंकि असल में, वो डिस्लेक्सिक थे।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22160</th>\n",
       "      <td>Moulik , Sishir Kumar Ghose , Nirapado Roy are...</td>\n",
       "      <td>अभियुक्तों परेश चौधरी मलिक , शिशिर कुमार घोष ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104635</th>\n",
       "      <td>They are wanderers and like living in tents or...</td>\n",
       "      <td>ये लोग चलते फिरते डेरा में रहते है.खुले आकश के...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88814</th>\n",
       "      <td>Nobody could work for the unity of India in su...</td>\n",
       "      <td>ऐसे वातावरण में कोई भारत की एकता के लिए पहल नह...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30628</th>\n",
       "      <td>This is what you see.</td>\n",
       "      <td>आपको यहाँ येही दिखाई देगा</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  English  \\\n",
       "127262                 because he was, in fact, dyslexic.   \n",
       "22160   Moulik , Sishir Kumar Ghose , Nirapado Roy are...   \n",
       "104635  They are wanderers and like living in tents or...   \n",
       "88814   Nobody could work for the unity of India in su...   \n",
       "30628                               This is what you see.   \n",
       "\n",
       "                                                    Hindi  \n",
       "127262                क्योंकि असल में, वो डिस्लेक्सिक थे।  \n",
       "22160   अभियुक्तों परेश चौधरी मलिक , शिशिर कुमार घोष ,...  \n",
       "104635  ये लोग चलते फिरते डेरा में रहते है.खुले आकश के...  \n",
       "88814   ऐसे वातावरण में कोई भारत की एकता के लिए पहल नह...  \n",
       "30628                           आपको यहाँ येही दिखाई देगा  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/Dataset_English_Hindi.csv\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ac125bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['English'].apply(lambda x: isinstance(x, str)) & data['Hindi'].apply(lambda x: isinstance(x, str))\n",
    "data = data.loc[mask].copy()\n",
    "data['English'] = data['English'].str.lower()\n",
    "data['Hindi'] = data['Hindi'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f4e9d7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after filtering: 77743\n"
     ]
    }
   ],
   "source": [
    "MAX_SENT_LEN = 15\n",
    "data = data[data['English'].str.split().apply(len) < MAX_SENT_LEN].copy()\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(f\"Rows after filtering: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6a566f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Distribution of English Sentence Lengths'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['English'].str.split().apply(len).plot(kind='hist', bins=14, title='Distribution of English Sentence Lengths', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f05dc2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, texts):\n",
    "        self.oov_token = \"<|unknown|>\"\n",
    "        self.start_token = \"<|startoftext|>\"\n",
    "        self.end_token = \"<|endoftext|>\"\n",
    "        self.padding_token = \"<|pad|>\"\n",
    "        self.word_index = {self.oov_token: 0, self.start_token: 1, self.end_token: 2, self.padding_token: 3}\n",
    "    \n",
    "        for text in texts:\n",
    "            text = text.replace('!', '')\n",
    "            text = text.replace('.', '')\n",
    "            text = text.replace('(', '')\n",
    "            text = text.replace(')', '')\n",
    "            text = text.replace('?', '')\n",
    "            text = text.replace('-', ' ')\n",
    "\n",
    "            text = text.split()\n",
    "            for word in text:\n",
    "                if word not in self.word_index:\n",
    "                    self.word_index[word] = len(self.word_index) + 1\n",
    "        self.index_word = {idx : word for word, idx in self.word_index.items()}\n",
    "\n",
    "        self.vocab_size = len(self.word_index)\n",
    "    def encode(self, texts):\n",
    "        tokenized_texts = []\n",
    "        for text in texts:\n",
    "            text = text.replace('!', '')\n",
    "            text = text.replace('.', '')\n",
    "            text = text.replace('(', '')\n",
    "            text = text.replace(')', '')\n",
    "            text = text.replace('?', '')\n",
    "            text = text.replace('-', ' ')\n",
    "            tokenized_text = []\n",
    "            text = text.split()\n",
    "            for word in text:\n",
    "                tokenized_text.append(self.word_index.get(word, self.word_index[self.oov_token]))\n",
    "            tokenized_texts.append(tokenized_text)\n",
    "        return tokenized_texts\n",
    "    def decode(self, sequences):\n",
    "        decoded_texts = []\n",
    "        for sequence in sequences:\n",
    "            decoded_text = []\n",
    "            for index in sequence:\n",
    "                decoded_text.append(self.index_word.get(index, self.oov_token))\n",
    "            decoded_texts.append(' '.join(decoded_text))\n",
    "        return decoded_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "643d75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 43114\n",
      "Hindi Vocabulary Size: 43014\n"
     ]
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(data['English'])\n",
    "hin_tokenizer = Tokenizer(data['Hindi'])\n",
    "print(f\"English Vocabulary Size: {eng_tokenizer.vocab_size}\")# 80223\n",
    "print(f\"Hindi Vocabulary Size: {hin_tokenizer.vocab_size}\")# 85059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3f4ecc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 82, 83, 62, 8266, 26951, 0, 0], [94, 104, 110, 2144], [123, 104, 183, 306]]\n",
      "['hello how are you raj neelam <|unknown|> <|unknown|>', 'this is a test', 'what is your name']\n",
      "\n",
      "[[27205, 122, 123, 124, 3305, 28591, 5206, 0], [143, 111, 14354, 80], [404, 433, 114, 80]]\n",
      "['नमस्ते आप कैसे हैं राज नीलम गौरव <|unknown|>', 'यह एक परीक्षण है', 'तुम्हारा नाम क्या है']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = eng_tokenizer.encode([\"hello how are you raj neelam gaurav convolution\", \"this is a test\", \"what is your name\"])\n",
    "print(tokenized_text)\n",
    "print(eng_tokenizer.decode(tokenized_text))\n",
    "print()\n",
    "tokenized_text = hin_tokenizer.encode([\"नमस्ते आप कैसे हैं राज नीलम गौरव कन्वोल्यूशन\", \"यह एक परीक्षण है\", \"तुम्हारा नाम क्या है\"])\n",
    "print(tokenized_text)\n",
    "print(hin_tokenizer.decode(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d1df5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "START_LR = 0.005\n",
    "END_LR = 0.000001\n",
    "TOTAL_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2284e149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69968, 7775)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, test_data = train_test_split(data, test_size=0.1)\n",
    "len(data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2a22353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      English  \\\n",
      "50590  or if they get an extra ration of food   \n",
      "77309   or con thing, but now it is in thing.   \n",
      "73400    this wars main anchors were also 18|   \n",
      "1531          both he and his wife have cars.   \n",
      "58136                because of online crime.   \n",
      "\n",
      "                                            Hindi  \n",
      "50590                अगर हफ्ते के आखिर में उन्हें  \n",
      "77309         कुछ बुरी चीज़, लेकिन अब वापस आ गया।  \n",
      "73400   इस युद्ध के प्रमुख सूत्रधार भी अठारह हैं।  \n",
      "1531   वह और उसकी पत्नी दोनो के पास गाड़ियाँ हैं।  \n",
      "58136                    ऑनलाइन अपराध की वजह से .  \n",
      "                                             English  \\\n",
      "0                    about the middle east conflict.   \n",
      "1                           this lady, she developed   \n",
      "2  the internal room of tajmahal is very differen...   \n",
      "3  i feel angry when i see cruelty to human being...   \n",
      "4                     that sort of phallic bit there   \n",
      "\n",
      "                                               Hindi  \n",
      "0         मध्य-पूर्वी क्षेत्र के संघर्ष के बारे में.  \n",
      "1                       इन महिला को देखिये, इन्होंने  \n",
      "2  ताजमहल का आंतरिक कक्ष परंपरागत अलंकरण अवयवों स...  \n",
      "3  जब कभी किसी इंसान या जानवर को सताया जाता देखता...  \n",
      "4                                   यह कलम जैसी चीज़  \n"
     ]
    }
   ],
   "source": [
    "# shuffle data\n",
    "print(data.head())\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "64bf46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, eng_tokenizer, hin_tokenizer):\n",
    "        self.data = data\n",
    "        self.eng_tokenizer = eng_tokenizer\n",
    "        self.hin_tokenizer = hin_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng_text = self.data.iloc[idx]['English']\n",
    "        hin_text = self.data.iloc[idx]['Hindi']\n",
    "\n",
    "        eng_tokenized = self.eng_tokenizer.encode([eng_text])[0]\n",
    "        if len(eng_tokenized) > MAX_SENT_LEN:\n",
    "            eng_tokenized = eng_tokenized[:MAX_SENT_LEN]\n",
    "\n",
    "        eng_padded = [self.eng_tokenizer.word_index[self.eng_tokenizer.padding_token]] * (MAX_SENT_LEN - len(eng_tokenized)) + eng_tokenized\n",
    "\n",
    "        hin_tokenized = self.hin_tokenizer.encode([hin_text])[0]\n",
    "\n",
    "        if len(hin_tokenized) > MAX_SENT_LEN - 2:\n",
    "            hin_tokenized = hin_tokenized[:MAX_SENT_LEN - 2]\n",
    "        hin_padded = [self.hin_tokenizer.word_index[self.hin_tokenizer.start_token]] + hin_tokenized + [self.hin_tokenizer.word_index[self.hin_tokenizer.end_token]] + [self.hin_tokenizer.word_index[self.hin_tokenizer.padding_token]] * (MAX_SENT_LEN - len(hin_tokenized) - 2)\n",
    "\n",
    "        return {\n",
    "            'eng_input': torch.tensor(eng_padded),\n",
    "            'hin_target': torch.tensor(hin_padded)\n",
    "        }\n",
    "\n",
    "dataset = DataLoader(MyDataset(data, eng_tokenizer, hin_tokenizer), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = DataLoader(MyDataset(test_data, eng_tokenizer, hin_tokenizer), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "78518f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, EMBED_DIM)\n",
    "        self.rnn = nn.GRU(EMBED_DIM, HIDDEN_DIM, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        src: (batch_size, src_len)\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(src)               # (B, T, E)\n",
    "        outputs, hidden = self.rnn(embedded)         # outputs: all h_t, hidden: last h_T\n",
    "        return outputs, hidden                       # hidden = context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3218c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(hidden_dim, hidden_dim) # For encoder outputs\n",
    "        self.W2 = nn.Linear(hidden_dim, hidden_dim) # For decoder hidden state\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hidden: (num_layers, B, H) -> we take the top layer\n",
    "        # encoder_outputs: (B, T, H)\n",
    "        \n",
    "        # We use the last layer of the decoder hidden state\n",
    "        last_hidden = decoder_hidden[-1].unsqueeze(1) # (B, 1, H)\n",
    "        \n",
    "        # Calculate scores: V * tanh(W1(enc) + W2(dec))\n",
    "        # (B, T, H) + (B, 1, H) -> (B, T, H) via broadcasting\n",
    "        score = self.V(torch.tanh(self.W1(encoder_outputs) + self.W2(last_hidden)))\n",
    "        \n",
    "        # score: (B, T, 1) -> weights: (B, 1, T)\n",
    "        attention_weights = F.softmax(score, dim=1).transpose(1, 2)\n",
    "        \n",
    "        # context_vector: (B, 1, T) @ (B, T, H) -> (B, 1, H)\n",
    "        context_vector = torch.bmm(attention_weights, encoder_outputs)\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a0154729",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, hidden_dim, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.attention = BahdanauAttention(hidden_dim)\n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
    "        \n",
    "        # GRU input: embedding + context vector\n",
    "        self.rnn = nn.GRU(embed_dim + hidden_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim + hidden_dim + embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_token, hidden, encoder_outputs):\n",
    "        # input_token: (B)\n",
    "        input_token = input_token.unsqueeze(1) # (B, 1)\n",
    "        embedded = self.embedding(input_token) # (B, 1, E)\n",
    "\n",
    "        # 1. Get attention context\n",
    "        context, weights = self.attention(hidden, encoder_outputs)\n",
    "\n",
    "        # 2. Concatenate embedding and context\n",
    "        rnn_input = torch.cat((embedded, context), dim=2) # (B, 1, E + H)\n",
    "\n",
    "        # 3. Feed to RNN\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "\n",
    "        # 4. Predict (Final FC can use context, rnn_output, and embedding)\n",
    "        prediction = self.fc(torch.cat((output.squeeze(1), context.squeeze(1), embedded.squeeze(1)), dim=1))\n",
    "\n",
    "        return prediction, hidden, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b151a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
    "        \n",
    "        # Get all encoder hidden states\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        input_token = trg[:, 0] # <start> token\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, _ = self.decoder(input_token, hidden, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            \n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input_token = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "47ad428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=eng_tokenizer.vocab_size+1)\n",
    "decoder = Decoder(output_dim=hin_tokenizer.vocab_size+1, embed_dim=EMBED_DIM, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0ea43c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:24: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
      "c:\\Python310\\lib\\site-packages\\torch\\jit\\_trace.py:1209: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 71557553 / 82588800 (86.6%)\n",
      "Greatest absolute difference: 2.0307735204696655 at index (19, 5, 7991) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 44533239.85714286 at index (3, 3, 15525) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    },
    {
     "ename": "TracingCheckError",
     "evalue": "Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%self.1 : __torch__.Seq2Seq,\n\t\t        %src : Tensor,\n\t\t        %trg : Tensor):\n\t\t    %decoder : __torch__.Decoder = prim::GetAttr[name=\"decoder\"](%self.1)\n\t\t    %encoder : __torch__.Encoder = prim::GetAttr[name=\"encoder\"](%self.1)\n\t\t    %5 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:9:0\n\t\t    %6 : int = aten::size(%src, %5) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:9:0\n\t\t    %batch_size : Tensor = prim::NumToTensor(%6)\n\t\t    %8 : int = aten::Int(%batch_size)\n\t\t    %9 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:10:0\n\t\t    %10 : int = aten::size(%trg, %9) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:10:0\n\t\t    %trg_len : Tensor = prim::NumToTensor(%10)\n\t\t    %12 : int = aten::Int(%trg_len)\n\t\t    %13 : int = prim::Constant[value=43015]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %14 : int[] = prim::ListConstruct(%8, %12, %13)\n\t\t    %15 : NoneType = prim::Constant()\n\t\t    %16 : NoneType = prim::Constant()\n\t\t    %17 : Device = prim::Constant[value=\"cpu\"]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %18 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %19 : Tensor = aten::zeros(%14, %15, %16, %17, %18) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %20 : int = prim::Constant[value=6]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %21 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %22 : Device = prim::Constant[value=\"cuda\"]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %23 : NoneType = prim::Constant()\n\t\t    %24 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %25 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %26 : NoneType = prim::Constant()\n\t\t    %outputs : Tensor = aten::to(%19, %20, %21, %22, %23, %24, %25, %26) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t-   %293 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1375:0\n\t\t?    --\n\t\t+   %303 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1375:0\n\t\t?     ++\n\t\t-   %294 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t+   %304 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t-   %295 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t+   %305 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t-   %296 : int = prim::Constant[value=6](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t+   %306 : int = prim::Constant[value=6](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t-   %297 : NoneType = prim::Constant(), scope: __module.encoder/__module.encoder.rnn\n\t\t?    ^^\n\t\t+   %307 : NoneType = prim::Constant(), scope: __module.encoder/__module.encoder.rnn\n\t\t?    ^^\n\t\t-   %298 : Device = prim::Constant[value=\"cuda:0\"](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t+   %308 : Device = prim::Constant[value=\"cuda:0\"](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t-   %299 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    ^ -\n\t\t+   %309 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    ^^\n\t\t-   %300 : float = prim::Constant[value=0.](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %310 : float = prim::Constant[value=0.](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     +\n\t\t-   %301 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     -\n\t\t+   %311 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      +\n\t\t-   %302 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %312 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t    %rnn.1 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%encoder)\n\t\t    %embedding.1 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%encoder)\n\t\t    %weight.5 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.1)\n\t\t-   %input.1 : Tensor = aten::embedding(%weight.5, %src, %301, %302, %302), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                          ^     ^     ^\n\t\t+   %input.1 : Tensor = aten::embedding(%weight.5, %src, %311, %312, %312), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                          ^     ^     ^\n\t\t    %bias_hh_l2.1 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.1)\n\t\t    %bias_ih_l2.1 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.1)\n\t\t    %weight_hh_l2.1 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.1)\n\t\t    %weight_ih_l2.1 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.1)\n\t\t    %bias_hh_l1.1 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.1)\n\t\t    %bias_ih_l1.1 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.1)\n\t\t    %weight_hh_l1.1 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.1)\n\t\t    %weight_ih_l1.1 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.1)\n\t\t    %bias_hh_l0.1 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.1)\n\t\t    %bias_ih_l0.1 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.1)\n\t\t    %weight_hh_l0.1 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.1)\n\t\t    %weight_ih_l0.1 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.1)\n\t\t-   %319 : int = aten::size(%input.1, %293), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1375:0\n\t\t?     ^                                ^^\n\t\t+   %329 : int = aten::size(%input.1, %303), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1375:0\n\t\t?     ^                                ^^\n\t\t-   %320 : int[] = prim::ListConstruct(%294, %319, %295), scope: __module.encoder/__module.encoder.rnn\n\t\t?     ^                                   -    ^^^^^^^\n\t\t+   %330 : int[] = prim::ListConstruct(%304, %329, %305), scope: __module.encoder/__module.encoder.rnn\n\t\t?     ^                                 +++++++      ^\n\t\t-   %hx : Tensor = aten::zeros(%320, %296, %297, %298, %302), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?                                ^  ------------------\n\t\t+   %hx : Tensor = aten::zeros(%330, %306, %307, %308, %312), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?                                ^      ++++++++++++++++++\n\t\t-   %322 : Tensor[] = prim::ListConstruct(%weight_ih_l0.1, %weight_hh_l0.1, %bias_ih_l0.1, %bias_hh_l0.1, %weight_ih_l1.1, %weight_hh_l1.1, %bias_ih_l1.1, %bias_hh_l1.1, %weight_ih_l2.1, %weight_hh_l2.1, %bias_ih_l2.1, %bias_hh_l2.1), scope: __module.encoder/__module.encoder.rnn\n\t\t?     ^^^^\n\t\t+   %332 : Tensor[] = prim::ListConstruct(%weight_ih_l0.1, %weight_hh_l0.1, %bias_ih_l0.1, %bias_hh_l0.1, %weight_ih_l1.1, %weight_hh_l1.1, %bias_ih_l1.1, %bias_hh_l1.1, %weight_ih_l2.1, %weight_hh_l2.1, %bias_ih_l2.1, %bias_hh_l2.1), scope: __module.encoder/__module.encoder.rnn\n\t\t?     ^^^^\n\t\t-   %input.5 : Tensor, %decoder_hidden.1 : Tensor = aten::gru(%input.1, %hx, %322, %299, %294, %300, %302, %302, %299), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.5 : Tensor, %decoder_hidden.1 : Tensor = aten::gru(%input.1, %hx, %332, %309, %304, %310, %312, %312, %309), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                             +  +++++++++++++++++++++++    ++ ^^^^^\n\t\t-   %325 : (Tensor, Tensor) = prim::TupleConstruct(%decoder_hidden.1, %input.5)\n\t\t?     ^\n\t\t+   %335 : (Tensor, Tensor) = prim::TupleConstruct(%decoder_hidden.1, %input.5)\n\t\t?     ^\n\t\t-   %326 : Tensor, %327 : Tensor = prim::TupleUnpack(%325)\n\t\t?     ^              ^                                 ^\n\t\t+   %336 : Tensor, %337 : Tensor = prim::TupleUnpack(%335)\n\t\t?     ^              ^                                 ^\n\t\t-   %328 : (Tensor, Tensor) = prim::TupleConstruct(%326, %327)\n\t\t?     ^                                              ^     ^\n\t\t+   %338 : (Tensor, Tensor) = prim::TupleConstruct(%336, %337)\n\t\t?     ^                                              ^     ^\n\t\t-   %29 : Tensor, %30 : Tensor = prim::TupleUnpack(%328)\n\t\t?                                                    ^\n\t\t+   %29 : Tensor, %30 : Tensor = prim::TupleUnpack(%338)\n\t\t?                                                    ^\n\t\t    %31 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %32 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %33 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %34 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %35 : Tensor = aten::slice(%trg, %31, %32, %33, %34) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %36 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %37 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %input_token.1 : Tensor = aten::select(%35, %36, %37) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t-   %329 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %339 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %330 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %340 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %331 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %341 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %332 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %342 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %333 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      -\n\t\t+   %343 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     +\n\t\t-   %334 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     -\n\t\t+   %344 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      +\n\t\t-   %335 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %345 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %336 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %346 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %337 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %347 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.3 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.1 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.3 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.3 : Tensor = aten::unsqueeze(%input_token.1, %337), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                         ^\n\t\t+   %input.3 : Tensor = aten::unsqueeze(%input_token.1, %347), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                         ^\n\t\t    %weight.7 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.3)\n\t\t-   %embedded.1 : Tensor = aten::embedding(%weight.7, %input.3, %335, %336, %336), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                 ^     ^     ^\n\t\t+   %embedded.1 : Tensor = aten::embedding(%weight.7, %input.3, %345, %346, %346), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                 ^     ^     ^\n\t\t    %V.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.1)\n\t\t    %W2.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.1)\n\t\t    %W1.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.1)\n\t\t-   %348 : Tensor = aten::select(%29, %332, %335), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                                 ^     ^\n\t\t+   %358 : Tensor = aten::select(%29, %342, %345), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                                 ^     ^\n\t\t-   %input.7 : Tensor = aten::unsqueeze(%348, %337), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                         ^     ^\n\t\t+   %input.7 : Tensor = aten::unsqueeze(%358, %347), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                         ^     ^\n\t\t    %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%W1.1)\n\t\t    %weight.9 : Tensor = prim::GetAttr[name=\"weight\"](%W1.1)\n\t\t-   %352 : Tensor = aten::linear(%30, %weight.9, %bias.1), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %362 : Tensor = aten::linear(%30, %weight.9, %bias.1), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.3 : Tensor = prim::GetAttr[name=\"bias\"](%W2.1)\n\t\t    %weight.11 : Tensor = prim::GetAttr[name=\"weight\"](%W2.1)\n\t\t-   %355 : Tensor = aten::linear(%input.7, %weight.11, %bias.3), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^\n\t\t+   %365 : Tensor = aten::linear(%input.7, %weight.11, %bias.3), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     + ^^\n\t\t-   %356 : Tensor = aten::add(%352, %355, %337), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     -                         ^     ^     ^\n\t\t+   %366 : Tensor = aten::add(%362, %365, %347), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      +                        ^     ^     ^\n\t\t-   %input.9 : Tensor = aten::tanh(%356), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                    ^\n\t\t+   %input.9 : Tensor = aten::tanh(%366), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                    ^\n\t\t    %bias.5 : Tensor = prim::GetAttr[name=\"bias\"](%V.1)\n\t\t    %weight.13 : Tensor = prim::GetAttr[name=\"weight\"](%V.1)\n\t\t    %input.11 : Tensor = aten::linear(%input.9, %weight.13, %bias.5), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %361 : Tensor = aten::softmax(%input.11, %337, %333), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t+   %371 : Tensor = aten::softmax(%input.11, %347, %343), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t-   %attention_weights.1 : Tensor = aten::transpose(%361, %337, %334), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^     ^     ^\n\t\t+   %attention_weights.1 : Tensor = aten::transpose(%371, %347, %344), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^     ^     ^\n\t\t    %context.1 : Tensor = aten::bmm(%attention_weights.1, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %364 : Tensor[] = prim::ListConstruct(%embedded.1, %context.1), scope: __module.decoder\n\t\t?     ^\n\t\t+   %374 : Tensor[] = prim::ListConstruct(%embedded.1, %context.1), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.13 : Tensor = aten::cat(%364, %334), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t+   %input.13 : Tensor = aten::cat(%374, %344), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t    %bias_hh_l2.3 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.3)\n\t\t    %bias_ih_l2.3 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.3)\n\t\t    %weight_hh_l2.3 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.3)\n\t\t    %weight_ih_l2.3 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.3)\n\t\t    %bias_hh_l1.3 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.3)\n\t\t    %bias_ih_l1.3 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.3)\n\t\t    %weight_hh_l1.3 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.3)\n\t\t    %weight_ih_l1.3 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.3)\n\t\t    %bias_hh_l0.3 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.3)\n\t\t    %bias_ih_l0.3 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.3)\n\t\t    %weight_hh_l0.3 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.3)\n\t\t    %weight_ih_l0.3 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.3)\n\t\t-   %378 : Tensor[] = prim::ListConstruct(%weight_ih_l0.3, %weight_hh_l0.3, %bias_ih_l0.3, %bias_hh_l0.3, %weight_ih_l1.3, %weight_hh_l1.3, %bias_ih_l1.3, %bias_hh_l1.3, %weight_ih_l2.3, %weight_hh_l2.3, %bias_ih_l2.3, %bias_hh_l2.3), scope: __module.decoder/__module.decoder.rnn\n\t\t?     - ^^\n\t\t+   %388 : Tensor[] = prim::ListConstruct(%weight_ih_l0.3, %weight_hh_l0.3, %bias_ih_l0.3, %bias_hh_l0.3, %weight_ih_l1.3, %weight_hh_l1.3, %bias_ih_l1.3, %bias_hh_l1.3, %weight_ih_l2.3, %weight_hh_l2.3, %bias_ih_l2.3, %bias_hh_l2.3), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^\n\t\t-   %output.1 : Tensor, %decoder_hidden.3 : Tensor = aten::gru(%input.13, %29, %378, %329, %330, %331, %336, %336, %329), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                - ^^^^^^^^^^^     ^^^^^^^     ^     ^\n\t\t+   %output.1 : Tensor, %decoder_hidden.3 : Tensor = aten::gru(%input.13, %29, %388, %339, %340, %341, %346, %346, %339), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                 ^^^^^^^^^^^^     ^^^^^^^     ^     ^\n\t\t-   %381 : (Tensor, Tensor) = prim::TupleConstruct(%output.1, %decoder_hidden.3)\n\t\t?     ^\n\t\t+   %391 : (Tensor, Tensor) = prim::TupleConstruct(%output.1, %decoder_hidden.3)\n\t\t?     ^\n\t\t-   %382 : Tensor, %383 : Tensor = prim::TupleUnpack(%381)\n\t\t?     ^              ^                                 ^\n\t\t+   %392 : Tensor, %393 : Tensor = prim::TupleUnpack(%391)\n\t\t?     ^              ^                                 ^\n\t\t-   %384 : Tensor = aten::squeeze(%382, %337), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %394 : Tensor = aten::squeeze(%392, %347), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %385 : Tensor = aten::squeeze(%context.1, %337), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t+   %395 : Tensor = aten::squeeze(%context.1, %347), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t-   %386 : Tensor = aten::squeeze(%embedded.1, %337), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %396 : Tensor = aten::squeeze(%embedded.1, %347), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %387 : Tensor[] = prim::ListConstruct(%384, %385, %386), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %397 : Tensor[] = prim::ListConstruct(%394, %395, %396), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.15 : Tensor = aten::cat(%387, %337), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.15 : Tensor = aten::cat(%397, %347), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.7 : Tensor = prim::GetAttr[name=\"bias\"](%fc.1)\n\t\t    %weight.15 : Tensor = prim::GetAttr[name=\"weight\"](%fc.1)\n\t\t    %output.3 : Tensor = aten::linear(%input.15, %weight.15, %bias.7), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %392 : (Tensor, Tensor) = prim::TupleConstruct(%output.3, %383)\n\t\t?    ^^                                                         ^\n\t\t+   %402 : (Tensor, Tensor) = prim::TupleConstruct(%output.3, %393)\n\t\t?    ^^                                                         ^\n\t\t-   %40 : Tensor, %41 : Tensor = prim::TupleUnpack(%392)\n\t\t?                                                   ^^\n\t\t+   %40 : Tensor, %41 : Tensor = prim::TupleUnpack(%402)\n\t\t?                                                   ^^\n\t\t    %42 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %43 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %44 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %45 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %46 : Tensor = aten::slice(%outputs, %42, %43, %44, %45) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %47 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %48 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %49 : Tensor = aten::select(%46, %47, %48) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %50 : bool = prim::Constant[value=0]()\n\t\t    %51 : Tensor = aten::copy_(%49, %40, %50) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %52 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %53 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %54 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %55 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %56 : Tensor = aten::slice(%trg, %52, %53, %54, %55) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %57 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %58 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %input_token.3 : Tensor = aten::select(%56, %57, %58) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %393 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     --\n\t\t+   %403 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    ++\n\t\t-   %394 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    --\n\t\t+   %404 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ++\n\t\t-   %395 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    ^^\n\t\t+   %405 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    ^^\n\t\t-   %396 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?    ^^\n\t\t+   %406 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?    ^^\n\t\t-   %397 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?    ^^\n\t\t+   %407 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?    ^^\n\t\t-   %398 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?    ^^\n\t\t+   %408 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?    ^^\n\t\t-   %399 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^ -\n\t\t+   %409 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^^\n\t\t-   %400 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      -\n\t\t+   %410 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     +\n\t\t-   %401 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     -\n\t\t+   %411 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      +\n\t\t    %fc.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.5 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.3 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.5 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.17 : Tensor = aten::unsqueeze(%input_token.3, %401), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t+   %input.17 : Tensor = aten::unsqueeze(%input_token.3, %411), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t    %weight.17 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.5)\n\t\t-   %embedded.3 : Tensor = aten::embedding(%weight.17, %input.17, %399, %400, %400), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                 ------        ^\n\t\t+   %embedded.3 : Tensor = aten::embedding(%weight.17, %input.17, %409, %410, %410), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ++++++     ^\n\t\t    %V.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.3)\n\t\t    %W2.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.3)\n\t\t    %W1.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.3)\n\t\t-   %412 : Tensor = aten::select(%41, %396, %399), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     -                                ^^    ^^\n\t\t+   %422 : Tensor = aten::select(%41, %406, %409), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      +                               ^^    ^^\n\t\t-   %input.19 : Tensor = aten::unsqueeze(%412, %401), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t+   %input.19 : Tensor = aten::unsqueeze(%422, %411), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t    %bias.9 : Tensor = prim::GetAttr[name=\"bias\"](%W1.3)\n\t\t    %weight.19 : Tensor = prim::GetAttr[name=\"weight\"](%W1.3)\n\t\t-   %416 : Tensor = aten::linear(%30, %weight.19, %bias.9), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %426 : Tensor = aten::linear(%30, %weight.19, %bias.9), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.11 : Tensor = prim::GetAttr[name=\"bias\"](%W2.3)\n\t\t    %weight.21 : Tensor = prim::GetAttr[name=\"weight\"](%W2.3)\n\t\t-   %419 : Tensor = aten::linear(%input.19, %weight.21, %bias.11), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %429 : Tensor = aten::linear(%input.19, %weight.21, %bias.11), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t-   %420 : Tensor = aten::add(%416, %419, %401), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^      ------\n\t\t+   %430 : Tensor = aten::add(%426, %429, %411), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^  ++++++\n\t\t-   %input.21 : Tensor = aten::tanh(%420), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.21 : Tensor = aten::tanh(%430), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.13 : Tensor = prim::GetAttr[name=\"bias\"](%V.3)\n\t\t    %weight.23 : Tensor = prim::GetAttr[name=\"weight\"](%V.3)\n\t\t    %input.23 : Tensor = aten::linear(%input.21, %weight.23, %bias.13), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %425 : Tensor = aten::softmax(%input.23, %401, %397), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                         ------\n\t\t+   %435 : Tensor = aten::softmax(%input.23, %411, %407), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                      ++++++\n\t\t-   %attention_weights.3 : Tensor = aten::transpose(%425, %401, %398), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^      ------\n\t\t+   %attention_weights.3 : Tensor = aten::transpose(%435, %411, %408), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^  ++++++\n\t\t    %context.3 : Tensor = aten::bmm(%attention_weights.3, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %428 : Tensor[] = prim::ListConstruct(%embedded.3, %context.3), scope: __module.decoder\n\t\t?     ^\n\t\t+   %438 : Tensor[] = prim::ListConstruct(%embedded.3, %context.3), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.25 : Tensor = aten::cat(%428, %398), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^    ^^\n\t\t+   %input.25 : Tensor = aten::cat(%438, %408), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^    ^^\n\t\t    %bias_hh_l2.5 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.5)\n\t\t    %bias_ih_l2.5 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.5)\n\t\t    %weight_hh_l2.5 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.5)\n\t\t    %weight_ih_l2.5 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.5)\n\t\t    %bias_hh_l1.5 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.5)\n\t\t    %bias_ih_l1.5 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.5)\n\t\t    %weight_hh_l1.5 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.5)\n\t\t    %weight_ih_l1.5 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.5)\n\t\t    %bias_hh_l0.5 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.5)\n\t\t    %bias_ih_l0.5 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.5)\n\t\t    %weight_hh_l0.5 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.5)\n\t\t    %weight_ih_l0.5 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.5)\n\t\t-   %442 : Tensor[] = prim::ListConstruct(%weight_ih_l0.5, %weight_hh_l0.5, %bias_ih_l0.5, %bias_hh_l0.5, %weight_ih_l1.5, %weight_hh_l1.5, %bias_ih_l1.5, %bias_hh_l1.5, %weight_ih_l2.5, %weight_hh_l2.5, %bias_ih_l2.5, %bias_hh_l2.5), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t+   %452 : Tensor[] = prim::ListConstruct(%weight_ih_l0.5, %weight_hh_l0.5, %bias_ih_l0.5, %bias_hh_l0.5, %weight_ih_l1.5, %weight_hh_l1.5, %bias_ih_l1.5, %bias_hh_l1.5, %weight_ih_l2.5, %weight_hh_l2.5, %bias_ih_l2.5, %bias_hh_l2.5), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t-   %output.5 : Tensor, %decoder_hidden.5 : Tensor = aten::gru(%input.25, %41, %442, %393, %394, %395, %400, %400, %393), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                ^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.5 : Tensor, %decoder_hidden.5 : Tensor = aten::gru(%input.25, %41, %452, %403, %404, %405, %410, %410, %403), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                ^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %445 : (Tensor, Tensor) = prim::TupleConstruct(%output.5, %decoder_hidden.5)\n\t\t?     -\n\t\t+   %455 : (Tensor, Tensor) = prim::TupleConstruct(%output.5, %decoder_hidden.5)\n\t\t?      +\n\t\t-   %446 : Tensor, %447 : Tensor = prim::TupleUnpack(%445)\n\t\t?     ^              ^                                 ^\n\t\t+   %456 : Tensor, %457 : Tensor = prim::TupleUnpack(%455)\n\t\t?     ^              ^                                 ^\n\t\t-   %448 : Tensor = aten::squeeze(%446, %401), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %458 : Tensor = aten::squeeze(%456, %411), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %449 : Tensor = aten::squeeze(%context.3, %401), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t+   %459 : Tensor = aten::squeeze(%context.3, %411), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t-   %450 : Tensor = aten::squeeze(%embedded.3, %401), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %460 : Tensor = aten::squeeze(%embedded.3, %411), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %451 : Tensor[] = prim::ListConstruct(%448, %449, %450), scope: __module.decoder\n\t\t?     ^                                     ^  ------\n\t\t+   %461 : Tensor[] = prim::ListConstruct(%458, %459, %460), scope: __module.decoder\n\t\t?     ^                                     ^      ++++++\n\t\t-   %input.27 : Tensor = aten::cat(%451, %401), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.27 : Tensor = aten::cat(%461, %411), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.15 : Tensor = prim::GetAttr[name=\"bias\"](%fc.3)\n\t\t    %weight.25 : Tensor = prim::GetAttr[name=\"weight\"](%fc.3)\n\t\t    %output.7 : Tensor = aten::linear(%input.27, %weight.25, %bias.15), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %456 : (Tensor, Tensor) = prim::TupleConstruct(%output.7, %447)\n\t\t?     -                                                         ^\n\t\t+   %466 : (Tensor, Tensor) = prim::TupleConstruct(%output.7, %457)\n\t\t?      +                                                        ^\n\t\t-   %61 : Tensor, %62 : Tensor = prim::TupleUnpack(%456)\n\t\t?                                                    ^\n\t\t+   %61 : Tensor, %62 : Tensor = prim::TupleUnpack(%466)\n\t\t?                                                    ^\n\t\t    %63 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %64 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %65 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %66 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %67 : Tensor = aten::slice(%outputs, %63, %64, %65, %66) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %68 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %69 : int = prim::Constant[value=2]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %70 : Tensor = aten::select(%67, %68, %69) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %71 : bool = prim::Constant[value=0]()\n\t\t    %72 : Tensor = aten::copy_(%70, %61, %71) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %73 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                    ^                                                                       ^\n\t\t+   %73 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                    ^                                                                       ^\n\t\t-   %74 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?         ^^^^                                                                                                ^\n\t\t+   %74 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?         ^^^                                                                                                ^\n\t\t+   %75 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %76 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %77 : Tensor = aten::slice(%trg, %73, %74, %75, %76) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %78 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %79 : int = prim::Constant[value=2]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %input_token.5 : Tensor = aten::argmax(%61, %73, %74) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                   ^^^^^^  ^^    ^    ^                                                                     ^\n\t\t+   %input_token.5 : Tensor = aten::select(%77, %78, %79) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                   ^^^^^^  ^^    ^    ^                                                                     ^\n\t\t-   %457 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %467 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %458 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %468 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %459 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %469 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %460 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %470 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %461 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %471 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %462 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %472 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %463 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %473 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %464 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %474 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %465 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %475 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.7 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.5 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.7 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.29 : Tensor = aten::unsqueeze(%input_token.5, %465), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t+   %input.29 : Tensor = aten::unsqueeze(%input_token.5, %475), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t    %weight.27 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.7)\n\t\t-   %embedded.5 : Tensor = aten::embedding(%weight.27, %input.29, %463, %464, %464), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                   ^     ^     ^\n\t\t+   %embedded.5 : Tensor = aten::embedding(%weight.27, %input.29, %473, %474, %474), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                   ^     ^     ^\n\t\t    %V.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.5)\n\t\t    %W2.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.5)\n\t\t    %W1.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.5)\n\t\t-   %476 : Tensor = aten::select(%62, %460, %463), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                                 ^     ^\n\t\t+   %486 : Tensor = aten::select(%62, %470, %473), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                                 ^     ^\n\t\t-   %input.31 : Tensor = aten::unsqueeze(%476, %465), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t+   %input.31 : Tensor = aten::unsqueeze(%486, %475), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t    %bias.17 : Tensor = prim::GetAttr[name=\"bias\"](%W1.5)\n\t\t    %weight.29 : Tensor = prim::GetAttr[name=\"weight\"](%W1.5)\n\t\t-   %480 : Tensor = aten::linear(%30, %weight.29, %bias.17), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t+   %490 : Tensor = aten::linear(%30, %weight.29, %bias.17), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t    %bias.19 : Tensor = prim::GetAttr[name=\"bias\"](%W2.5)\n\t\t    %weight.31 : Tensor = prim::GetAttr[name=\"weight\"](%W2.5)\n\t\t-   %483 : Tensor = aten::linear(%input.31, %weight.31, %bias.19), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t+   %493 : Tensor = aten::linear(%input.31, %weight.31, %bias.19), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t-   %484 : Tensor = aten::add(%480, %483, %465), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %494 : Tensor = aten::add(%490, %493, %475), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.33 : Tensor = aten::tanh(%484), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.33 : Tensor = aten::tanh(%494), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.21 : Tensor = prim::GetAttr[name=\"bias\"](%V.5)\n\t\t    %weight.33 : Tensor = prim::GetAttr[name=\"weight\"](%V.5)\n\t\t    %input.35 : Tensor = aten::linear(%input.33, %weight.33, %bias.21), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %489 : Tensor = aten::softmax(%input.35, %465, %461), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     -                                        ^     ^\n\t\t+   %499 : Tensor = aten::softmax(%input.35, %475, %471), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      +                                       ^     ^\n\t\t-   %attention_weights.5 : Tensor = aten::transpose(%489, %465, %462), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^     ^     ^\n\t\t+   %attention_weights.5 : Tensor = aten::transpose(%499, %475, %472), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^     ^     ^\n\t\t    %context.5 : Tensor = aten::bmm(%attention_weights.5, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %492 : Tensor[] = prim::ListConstruct(%embedded.5, %context.5), scope: __module.decoder\n\t\t?    ^^\n\t\t+   %502 : Tensor[] = prim::ListConstruct(%embedded.5, %context.5), scope: __module.decoder\n\t\t?    ^^\n\t\t-   %input.37 : Tensor = aten::cat(%492, %462), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                   ^^     ^\n\t\t+   %input.37 : Tensor = aten::cat(%502, %472), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                   ^^     ^\n\t\t    %bias_hh_l2.7 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.7)\n\t\t    %bias_ih_l2.7 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.7)\n\t\t    %weight_hh_l2.7 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.7)\n\t\t    %weight_ih_l2.7 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.7)\n\t\t    %bias_hh_l1.7 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.7)\n\t\t    %bias_ih_l1.7 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.7)\n\t\t    %weight_hh_l1.7 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.7)\n\t\t    %weight_ih_l1.7 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.7)\n\t\t    %bias_hh_l0.7 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.7)\n\t\t    %bias_ih_l0.7 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.7)\n\t\t    %weight_hh_l0.7 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.7)\n\t\t    %weight_ih_l0.7 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.7)\n\t\t-   %506 : Tensor[] = prim::ListConstruct(%weight_ih_l0.7, %weight_hh_l0.7, %bias_ih_l0.7, %bias_hh_l0.7, %weight_ih_l1.7, %weight_hh_l1.7, %bias_ih_l1.7, %bias_hh_l1.7, %weight_ih_l2.7, %weight_hh_l2.7, %bias_ih_l2.7, %bias_hh_l2.7), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t+   %516 : Tensor[] = prim::ListConstruct(%weight_ih_l0.7, %weight_hh_l0.7, %bias_ih_l0.7, %bias_hh_l0.7, %weight_ih_l1.7, %weight_hh_l1.7, %bias_ih_l1.7, %bias_hh_l1.7, %weight_ih_l2.7, %weight_hh_l2.7, %bias_ih_l2.7, %bias_hh_l2.7), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t-   %output.9 : Tensor, %decoder_hidden.7 : Tensor = aten::gru(%input.37, %62, %506, %457, %458, %459, %464, %464, %457), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                ^^^^^^^^^^^^^     ^     ^^^^^^^^^^^^^\n\t\t+   %output.9 : Tensor, %decoder_hidden.7 : Tensor = aten::gru(%input.37, %62, %516, %467, %468, %469, %474, %474, %467), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                ^^^^^^^^^^^^^     ^     ^^^^^^^^^^^^^\n\t\t-   %509 : (Tensor, Tensor) = prim::TupleConstruct(%output.9, %decoder_hidden.7)\n\t\t?     ^\n\t\t+   %519 : (Tensor, Tensor) = prim::TupleConstruct(%output.9, %decoder_hidden.7)\n\t\t?     ^\n\t\t-   %510 : Tensor, %511 : Tensor = prim::TupleUnpack(%509)\n\t\t?     ^               -                                ^\n\t\t+   %520 : Tensor, %521 : Tensor = prim::TupleUnpack(%519)\n\t\t?     ^              +                                 ^\n\t\t-   %512 : Tensor = aten::squeeze(%510, %465), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     -                             ^     ^\n\t\t+   %522 : Tensor = aten::squeeze(%520, %475), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      +                            ^     ^\n\t\t-   %513 : Tensor = aten::squeeze(%context.5, %465), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t+   %523 : Tensor = aten::squeeze(%context.5, %475), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t-   %514 : Tensor = aten::squeeze(%embedded.5, %465), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %524 : Tensor = aten::squeeze(%embedded.5, %475), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %515 : Tensor[] = prim::ListConstruct(%512, %513, %514), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %525 : Tensor[] = prim::ListConstruct(%522, %523, %524), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.39 : Tensor = aten::cat(%515, %465), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.39 : Tensor = aten::cat(%525, %475), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.23 : Tensor = prim::GetAttr[name=\"bias\"](%fc.5)\n\t\t    %weight.35 : Tensor = prim::GetAttr[name=\"weight\"](%fc.5)\n\t\t    %output.11 : Tensor = aten::linear(%input.39, %weight.35, %bias.23), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %520 : (Tensor, Tensor) = prim::TupleConstruct(%output.11, %511)\n\t\t?     ^                                                          ^\n\t\t+   %530 : (Tensor, Tensor) = prim::TupleConstruct(%output.11, %521)\n\t\t?     ^                                                          ^\n\t\t-   %77 : Tensor, %78 : Tensor = prim::TupleUnpack(%520)\n\t\t?    ^^            -                                 ^\n\t\t+   %82 : Tensor, %83 : Tensor = prim::TupleUnpack(%530)\n\t\t?    ^^             +                                ^\n\t\t-   %79 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %80 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %84 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %85 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %81 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %86 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %82 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %87 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %83 : Tensor = aten::slice(%outputs, %79, %80, %81, %82) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                  -----  ^    ^    ^\n\t\t+   %88 : Tensor = aten::slice(%outputs, %84, %85, %86, %87) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                    ^    ^    ^^^^^^\n\t\t-   %84 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %89 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %85 : int = prim::Constant[value=3]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^\n\t\t+   %90 : int = prim::Constant[value=3]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^\n\t\t-   %86 : Tensor = aten::select(%83, %84, %85) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                           ^    ^   ^^\n\t\t+   %91 : Tensor = aten::select(%88, %89, %90) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                           ^    ^   ^^\n\t\t-   %87 : bool = prim::Constant[value=0]()\n\t\t?    ^^\n\t\t+   %92 : bool = prim::Constant[value=0]()\n\t\t?    ^^\n\t\t-   %88 : Tensor = aten::copy_(%86, %77, %87) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                         ^^ -----   ^\n\t\t+   %93 : Tensor = aten::copy_(%91, %82, %92) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                         ^^    ^^^^^^\n\t\t-   %89 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?    -\n\t\t+   %94 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     +\n\t\t-   %90 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^\n\t\t+   %95 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^\n\t\t-   %input_token.7 : Tensor = aten::argmax(%77, %89, %90) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                           ^^ -----   ^\n\t\t+   %input_token.7 : Tensor = aten::argmax(%82, %94, %95) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                           ^^    ^^^^^^\n\t\t-   %521 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %531 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %522 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %532 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     +\n\t\t-   %523 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     -\n\t\t+   %533 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      +\n\t\t-   %524 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %534 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %525 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %535 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %526 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %536 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %527 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %537 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %528 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %538 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %529 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %539 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.9 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.7 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.9 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.41 : Tensor = aten::unsqueeze(%input_token.7, %529), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t+   %input.41 : Tensor = aten::unsqueeze(%input_token.7, %539), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t    %weight.37 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.9)\n\t\t-   %embedded.7 : Tensor = aten::embedding(%weight.37, %input.41, %527, %528, %528), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                   ^     ^     ^\n\t\t+   %embedded.7 : Tensor = aten::embedding(%weight.37, %input.41, %537, %538, %538), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                   ^     ^     ^\n\t\t    %V.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.7)\n\t\t    %W2.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.7)\n\t\t    %W1.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.7)\n\t\t-   %540 : Tensor = aten::select(%78, %524, %527), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                           -     ^     ^\n\t\t+   %550 : Tensor = aten::select(%83, %534, %537), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            +    ^     ^\n\t\t-   %input.43 : Tensor = aten::unsqueeze(%540, %529), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t+   %input.43 : Tensor = aten::unsqueeze(%550, %539), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t    %bias.25 : Tensor = prim::GetAttr[name=\"bias\"](%W1.7)\n\t\t    %weight.39 : Tensor = prim::GetAttr[name=\"weight\"](%W1.7)\n\t\t-   %544 : Tensor = aten::linear(%30, %weight.39, %bias.25), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^\n\t\t+   %554 : Tensor = aten::linear(%30, %weight.39, %bias.25), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?    +  ^^\n\t\t    %bias.27 : Tensor = prim::GetAttr[name=\"bias\"](%W2.7)\n\t\t    %weight.41 : Tensor = prim::GetAttr[name=\"weight\"](%W2.7)\n\t\t-   %547 : Tensor = aten::linear(%input.43, %weight.41, %bias.27), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %557 : Tensor = aten::linear(%input.43, %weight.41, %bias.27), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t-   %548 : Tensor = aten::add(%544, %547, %529), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %558 : Tensor = aten::add(%554, %557, %539), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.45 : Tensor = aten::tanh(%548), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.45 : Tensor = aten::tanh(%558), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.29 : Tensor = prim::GetAttr[name=\"bias\"](%V.7)\n\t\t    %weight.43 : Tensor = prim::GetAttr[name=\"weight\"](%V.7)\n\t\t    %input.47 : Tensor = aten::linear(%input.45, %weight.43, %bias.29), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %553 : Tensor = aten::softmax(%input.47, %529, %525), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t+   %563 : Tensor = aten::softmax(%input.47, %539, %535), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t-   %attention_weights.7 : Tensor = aten::transpose(%553, %529, %526), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                           ^^^^^^^\n\t\t+   %attention_weights.7 : Tensor = aten::transpose(%563, %539, %536), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     +++++  +    ^\n\t\t    %context.7 : Tensor = aten::bmm(%attention_weights.7, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %556 : Tensor[] = prim::ListConstruct(%embedded.7, %context.7), scope: __module.decoder\n\t\t?     -\n\t\t+   %566 : Tensor[] = prim::ListConstruct(%embedded.7, %context.7), scope: __module.decoder\n\t\t?      +\n\t\t-   %input.49 : Tensor = aten::cat(%556, %526), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t+   %input.49 : Tensor = aten::cat(%566, %536), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t    %bias_hh_l2.9 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.9)\n\t\t    %bias_ih_l2.9 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.9)\n\t\t    %weight_hh_l2.9 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.9)\n\t\t    %weight_ih_l2.9 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.9)\n\t\t    %bias_hh_l1.9 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.9)\n\t\t    %bias_ih_l1.9 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.9)\n\t\t    %weight_hh_l1.9 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.9)\n\t\t    %weight_ih_l1.9 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.9)\n\t\t    %bias_hh_l0.9 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.9)\n\t\t    %bias_ih_l0.9 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.9)\n\t\t    %weight_hh_l0.9 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.9)\n\t\t    %weight_ih_l0.9 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.9)\n\t\t-   %570 : Tensor[] = prim::ListConstruct(%weight_ih_l0.9, %weight_hh_l0.9, %bias_ih_l0.9, %bias_hh_l0.9, %weight_ih_l1.9, %weight_hh_l1.9, %bias_ih_l1.9, %bias_hh_l1.9, %weight_ih_l2.9, %weight_hh_l2.9, %bias_ih_l2.9, %bias_hh_l2.9), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t+   %580 : Tensor[] = prim::ListConstruct(%weight_ih_l0.9, %weight_hh_l0.9, %bias_ih_l0.9, %bias_hh_l0.9, %weight_ih_l1.9, %weight_hh_l1.9, %bias_ih_l1.9, %bias_hh_l1.9, %weight_ih_l2.9, %weight_hh_l2.9, %bias_ih_l2.9, %bias_hh_l2.9), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t-   %output.13 : Tensor, %decoder_hidden.9 : Tensor = aten::gru(%input.49, %78, %570, %521, %522, %523, %528, %528, %521), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                           ^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.13 : Tensor, %decoder_hidden.9 : Tensor = aten::gru(%input.49, %83, %580, %531, %532, %533, %538, %538, %531), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                           ^^^^^^^     +++++++ ^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %573 : (Tensor, Tensor) = prim::TupleConstruct(%output.13, %decoder_hidden.9)\n\t\t?     ^\n\t\t+   %583 : (Tensor, Tensor) = prim::TupleConstruct(%output.13, %decoder_hidden.9)\n\t\t?     ^\n\t\t-   %574 : Tensor, %575 : Tensor = prim::TupleUnpack(%573)\n\t\t?     ^              ^                                 ^\n\t\t+   %584 : Tensor, %585 : Tensor = prim::TupleUnpack(%583)\n\t\t?     ^              ^                                 ^\n\t\t-   %576 : Tensor = aten::squeeze(%574, %529), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %586 : Tensor = aten::squeeze(%584, %539), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %577 : Tensor = aten::squeeze(%context.7, %529), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      -                                        ^\n\t\t+   %587 : Tensor = aten::squeeze(%context.7, %539), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     +                                         ^\n\t\t-   %578 : Tensor = aten::squeeze(%embedded.7, %529), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     -                                          ^\n\t\t+   %588 : Tensor = aten::squeeze(%embedded.7, %539), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      +                                         ^\n\t\t-   %579 : Tensor[] = prim::ListConstruct(%576, %577, %578), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %589 : Tensor[] = prim::ListConstruct(%586, %587, %588), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.51 : Tensor = aten::cat(%579, %529), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.51 : Tensor = aten::cat(%589, %539), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.31 : Tensor = prim::GetAttr[name=\"bias\"](%fc.7)\n\t\t    %weight.45 : Tensor = prim::GetAttr[name=\"weight\"](%fc.7)\n\t\t    %output.15 : Tensor = aten::linear(%input.51, %weight.45, %bias.31), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %584 : (Tensor, Tensor) = prim::TupleConstruct(%output.15, %575)\n\t\t?     ^                                                          ^\n\t\t+   %594 : (Tensor, Tensor) = prim::TupleConstruct(%output.15, %585)\n\t\t?     ^                                                          ^\n\t\t-   %93 : Tensor, %94 : Tensor = prim::TupleUnpack(%584)\n\t\t?     ^             ^                                ^\n\t\t+   %98 : Tensor, %99 : Tensor = prim::TupleUnpack(%594)\n\t\t?     ^             ^                                ^\n\t\t-   %95 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %96 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %97 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %98 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %99 : Tensor = aten::slice(%outputs, %95, %96, %97, %98) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %100 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                     ^\n\t\t+   %100 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                     ^\n\t\t-   %101 : int = prim::Constant[value=4]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                     ^\n\t\t+   %101 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                     ^\n\t\t+   %102 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %103 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %102 : Tensor = aten::select(%99, %100, %101) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^                    ----  ^^\n\t\t+   %104 : Tensor = aten::slice(%outputs, %100, %101, %102, %103) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^                   +++   ^^^^^^^            ++++++++++++\n\t\t-   %103 : bool = prim::Constant[value=0]()\n\t\t-   %104 : Tensor = aten::copy_(%102, %93, %103) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %105 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                                                                                             ^\n\t\t+   %105 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                                                                                             ^\n\t\t-   %106 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?          ^^^^                        ^                                                                       ^\n\t\t+   %106 : int = prim::Constant[value=4]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?          ^^^                        ^                                                                       ^\n\t\t+   %107 : Tensor = aten::select(%104, %105, %106) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %108 : bool = prim::Constant[value=0]()\n\t\t+   %109 : Tensor = aten::copy_(%107, %98, %108) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %110 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %111 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %112 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %113 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %114 : Tensor = aten::slice(%trg, %110, %111, %112, %113) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %115 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %116 : int = prim::Constant[value=4]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %input_token.9 : Tensor = aten::argmax(%93, %105, %106) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                   ^^^^^^  ^^    ^     ^                                                                      ^\n\t\t+   %input_token.9 : Tensor = aten::select(%114, %115, %116) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                   ^^^^^^  ^^^    ^     ^                                                                      ^\n\t\t-   %585 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %595 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %586 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %596 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %587 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %597 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %588 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      -\n\t\t+   %598 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     +\n\t\t-   %589 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     -\n\t\t+   %599 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      +\n\t\t-   %590 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?    ^^\n\t\t+   %600 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?    ^ +\n\t\t-   %591 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^^\n\t\t+   %601 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^^\n\t\t-   %592 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^^\n\t\t+   %602 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^^\n\t\t-   %593 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?    ^^\n\t\t+   %603 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?    ^^\n\t\t    %fc.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.11 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.9 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.11 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.53 : Tensor = aten::unsqueeze(%input_token.9, %593), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                         ^^\n\t\t+   %input.53 : Tensor = aten::unsqueeze(%input_token.9, %603), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                         ^^\n\t\t    %weight.47 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.11)\n\t\t-   %embedded.9 : Tensor = aten::embedding(%weight.47, %input.53, %591, %592, %592), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                  ^^    ^^    ^^\n\t\t+   %embedded.9 : Tensor = aten::embedding(%weight.47, %input.53, %601, %602, %602), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                  ^^    ^^    ^^\n\t\t    %V.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.9)\n\t\t    %W2.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.9)\n\t\t    %W1.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.9)\n\t\t-   %604 : Tensor = aten::select(%94, %588, %591), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^ ------\n\t\t+   %614 : Tensor = aten::select(%99, %598, %601), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^     ++++++\n\t\t-   %input.55 : Tensor = aten::unsqueeze(%604, %593), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^    ^^\n\t\t+   %input.55 : Tensor = aten::unsqueeze(%614, %603), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^    ^^\n\t\t    %bias.33 : Tensor = prim::GetAttr[name=\"bias\"](%W1.9)\n\t\t    %weight.49 : Tensor = prim::GetAttr[name=\"weight\"](%W1.9)\n\t\t-   %608 : Tensor = aten::linear(%30, %weight.49, %bias.33), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %618 : Tensor = aten::linear(%30, %weight.49, %bias.33), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.35 : Tensor = prim::GetAttr[name=\"bias\"](%W2.9)\n\t\t    %weight.51 : Tensor = prim::GetAttr[name=\"weight\"](%W2.9)\n\t\t-   %611 : Tensor = aten::linear(%input.55, %weight.51, %bias.35), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t+   %621 : Tensor = aten::linear(%input.55, %weight.51, %bias.35), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t-   %612 : Tensor = aten::add(%608, %611, %593), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     -                         ^     ^    ^^\n\t\t+   %622 : Tensor = aten::add(%618, %621, %603), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      +                        ^     ^    ^^\n\t\t-   %input.57 : Tensor = aten::tanh(%612), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.57 : Tensor = aten::tanh(%622), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.37 : Tensor = prim::GetAttr[name=\"bias\"](%V.9)\n\t\t    %weight.53 : Tensor = prim::GetAttr[name=\"weight\"](%V.9)\n\t\t    %input.59 : Tensor = aten::linear(%input.57, %weight.53, %bias.37), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %617 : Tensor = aten::softmax(%input.59, %593, %589), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                         ------\n\t\t+   %627 : Tensor = aten::softmax(%input.59, %603, %599), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                      ++++++\n\t\t-   %attention_weights.9 : Tensor = aten::transpose(%617, %593, %590), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^    ^^    ^^\n\t\t+   %attention_weights.9 : Tensor = aten::transpose(%627, %603, %600), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^    ^^    ^^\n\t\t    %context.9 : Tensor = aten::bmm(%attention_weights.9, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %620 : Tensor[] = prim::ListConstruct(%embedded.9, %context.9), scope: __module.decoder\n\t\t?     ^\n\t\t+   %630 : Tensor[] = prim::ListConstruct(%embedded.9, %context.9), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.61 : Tensor = aten::cat(%620, %590), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^    ^^\n\t\t+   %input.61 : Tensor = aten::cat(%630, %600), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^    ^^\n\t\t    %bias_hh_l2.11 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.11)\n\t\t    %bias_ih_l2.11 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.11)\n\t\t    %weight_hh_l2.11 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.11)\n\t\t    %weight_ih_l2.11 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.11)\n\t\t    %bias_hh_l1.11 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.11)\n\t\t    %bias_ih_l1.11 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.11)\n\t\t    %weight_hh_l1.11 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.11)\n\t\t    %weight_ih_l1.11 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.11)\n\t\t    %bias_hh_l0.11 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.11)\n\t\t    %bias_ih_l0.11 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.11)\n\t\t    %weight_hh_l0.11 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.11)\n\t\t    %weight_ih_l0.11 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.11)\n\t\t-   %634 : Tensor[] = prim::ListConstruct(%weight_ih_l0.11, %weight_hh_l0.11, %bias_ih_l0.11, %bias_hh_l0.11, %weight_ih_l1.11, %weight_hh_l1.11, %bias_ih_l1.11, %bias_hh_l1.11, %weight_ih_l2.11, %weight_hh_l2.11, %bias_ih_l2.11, %bias_hh_l2.11), scope: __module.decoder/__module.decoder.rnn\n\t\t?     - ^^\n\t\t+   %644 : Tensor[] = prim::ListConstruct(%weight_ih_l0.11, %weight_hh_l0.11, %bias_ih_l0.11, %bias_hh_l0.11, %weight_ih_l1.11, %weight_hh_l1.11, %bias_ih_l1.11, %bias_hh_l1.11, %weight_ih_l2.11, %weight_hh_l2.11, %bias_ih_l2.11, %bias_hh_l2.11), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^\n\t\t-   %output.17 : Tensor, %decoder_hidden.11 : Tensor = aten::gru(%input.61, %94, %634, %585, %586, %587, %592, %592, %585), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              -----     ^^^^^^^^^^^^^    ^^    ^^     ^\n\t\t+   %output.17 : Tensor, %decoder_hidden.11 : Tensor = aten::gru(%input.61, %99, %644, %595, %596, %597, %602, %602, %595), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                             +++++      ^^^^^^^^^^^^^    ^^    ^^     ^\n\t\t-   %637 : (Tensor, Tensor) = prim::TupleConstruct(%output.17, %decoder_hidden.11)\n\t\t?     ^\n\t\t+   %647 : (Tensor, Tensor) = prim::TupleConstruct(%output.17, %decoder_hidden.11)\n\t\t?     ^\n\t\t-   %638 : Tensor, %639 : Tensor = prim::TupleUnpack(%637)\n\t\t?     ^              ^                                 ^\n\t\t+   %648 : Tensor, %649 : Tensor = prim::TupleUnpack(%647)\n\t\t?     ^              ^                                 ^\n\t\t-   %640 : Tensor = aten::squeeze(%638, %593), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^    ^^\n\t\t+   %650 : Tensor = aten::squeeze(%648, %603), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^    ^^\n\t\t-   %641 : Tensor = aten::squeeze(%context.9, %593), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                        ^^\n\t\t+   %651 : Tensor = aten::squeeze(%context.9, %603), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                        ^^\n\t\t-   %642 : Tensor = aten::squeeze(%embedded.9, %593), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^^\n\t\t+   %652 : Tensor = aten::squeeze(%embedded.9, %603), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^^\n\t\t-   %643 : Tensor[] = prim::ListConstruct(%640, %641, %642), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %653 : Tensor[] = prim::ListConstruct(%650, %651, %652), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.63 : Tensor = aten::cat(%643, %593), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^    ^^\n\t\t+   %input.63 : Tensor = aten::cat(%653, %603), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^    ^^\n\t\t    %bias.39 : Tensor = prim::GetAttr[name=\"bias\"](%fc.9)\n\t\t    %weight.55 : Tensor = prim::GetAttr[name=\"weight\"](%fc.9)\n\t\t    %output.19 : Tensor = aten::linear(%input.63, %weight.55, %bias.39), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %648 : (Tensor, Tensor) = prim::TupleConstruct(%output.19, %639)\n\t\t?     ^                                                          ^\n\t\t+   %658 : (Tensor, Tensor) = prim::TupleConstruct(%output.19, %649)\n\t\t?     ^                                                          ^\n\t\t-   %109 : Tensor, %110 : Tensor = prim::TupleUnpack(%648)\n\t\t?     ^              ^                                 ^\n\t\t+   %119 : Tensor, %120 : Tensor = prim::TupleUnpack(%658)\n\t\t?     ^              ^                                 ^\n\t\t-   %111 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -\n\t\t+   %121 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +\n\t\t-   %112 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %122 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %113 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %123 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %114 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %124 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %115 : Tensor = aten::slice(%outputs, %111, %112, %113, %114) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^           ^^^^^^^\n\t\t+   %125 : Tensor = aten::slice(%outputs, %121, %122, %123, %124) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     +++++  +    ^\n\t\t-   %116 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %126 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %117 : int = prim::Constant[value=5]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %127 : int = prim::Constant[value=5]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %118 : Tensor = aten::select(%115, %116, %117) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t+   %128 : Tensor = aten::select(%125, %126, %127) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t-   %119 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t+   %129 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t-   %120 : Tensor = aten::copy_(%118, %109, %119) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^  ------\n\t\t+   %130 : Tensor = aten::copy_(%128, %119, %129) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^       ++++++\n\t\t-   %121 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                               ^                                                                       ^\n\t\t+   %131 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^                               ^                                                                       ^\n\t\t-   %122 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      -   ^^^                                                                                                ^\n\t\t+   %132 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     +    ^^^^                                                                                                ^\n\t\t-   %123 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %124 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %125 : Tensor = aten::slice(%trg, %121, %122, %123, %124) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %126 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %127 : int = prim::Constant[value=5]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %input_token.11 : Tensor = aten::select(%125, %126, %127) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                    ^^^^^^   ^^    ^^     -                                                                     ^\n\t\t+   %input_token.11 : Tensor = aten::argmax(%119, %131, %132) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                    ^^^^^^   ^^    ^^    +                                                                      ^\n\t\t-   %649 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %659 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %650 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %660 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %651 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %661 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %652 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %662 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %653 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %663 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %654 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %664 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %655 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      -\n\t\t+   %665 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     +\n\t\t-   %656 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     -\n\t\t+   %666 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      +\n\t\t-   %657 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %667 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.13 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.11 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.13 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.65 : Tensor = aten::unsqueeze(%input_token.11, %657), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t+   %input.65 : Tensor = aten::unsqueeze(%input_token.11, %667), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t    %weight.57 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.13)\n\t\t-   %embedded.11 : Tensor = aten::embedding(%weight.57, %input.65, %655, %656, %656), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^     ^     ^\n\t\t+   %embedded.11 : Tensor = aten::embedding(%weight.57, %input.65, %665, %666, %666), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^     ^     ^\n\t\t    %V.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.11)\n\t\t    %W2.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.11)\n\t\t    %W1.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.11)\n\t\t-   %668 : Tensor = aten::select(%110, %652, %655), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^     ^     ^\n\t\t+   %678 : Tensor = aten::select(%120, %662, %665), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^     ^     ^\n\t\t-   %input.67 : Tensor = aten::unsqueeze(%668, %657), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t+   %input.67 : Tensor = aten::unsqueeze(%678, %667), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t    %bias.41 : Tensor = prim::GetAttr[name=\"bias\"](%W1.11)\n\t\t    %weight.59 : Tensor = prim::GetAttr[name=\"weight\"](%W1.11)\n\t\t-   %672 : Tensor = aten::linear(%30, %weight.59, %bias.41), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %682 : Tensor = aten::linear(%30, %weight.59, %bias.41), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.43 : Tensor = prim::GetAttr[name=\"bias\"](%W2.11)\n\t\t    %weight.61 : Tensor = prim::GetAttr[name=\"weight\"](%W2.11)\n\t\t-   %675 : Tensor = aten::linear(%input.67, %weight.61, %bias.43), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %685 : Tensor = aten::linear(%input.67, %weight.61, %bias.43), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t-   %676 : Tensor = aten::add(%672, %675, %657), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %686 : Tensor = aten::add(%682, %685, %667), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.69 : Tensor = aten::tanh(%676), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.69 : Tensor = aten::tanh(%686), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.45 : Tensor = prim::GetAttr[name=\"bias\"](%V.11)\n\t\t    %weight.63 : Tensor = prim::GetAttr[name=\"weight\"](%V.11)\n\t\t    %input.71 : Tensor = aten::linear(%input.69, %weight.63, %bias.45), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %681 : Tensor = aten::softmax(%input.71, %657, %653), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t+   %691 : Tensor = aten::softmax(%input.71, %667, %663), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t-   %attention_weights.11 : Tensor = aten::transpose(%681, %657, %654), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t+   %attention_weights.11 : Tensor = aten::transpose(%691, %667, %664), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t    %context.11 : Tensor = aten::bmm(%attention_weights.11, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %684 : Tensor[] = prim::ListConstruct(%embedded.11, %context.11), scope: __module.decoder\n\t\t?     ^\n\t\t+   %694 : Tensor[] = prim::ListConstruct(%embedded.11, %context.11), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.73 : Tensor = aten::cat(%684, %654), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t+   %input.73 : Tensor = aten::cat(%694, %664), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t    %bias_hh_l2.13 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.13)\n\t\t    %bias_ih_l2.13 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.13)\n\t\t    %weight_hh_l2.13 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.13)\n\t\t    %weight_ih_l2.13 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.13)\n\t\t    %bias_hh_l1.13 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.13)\n\t\t    %bias_ih_l1.13 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.13)\n\t\t    %weight_hh_l1.13 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.13)\n\t\t    %weight_ih_l1.13 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.13)\n\t\t    %bias_hh_l0.13 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.13)\n\t\t    %bias_ih_l0.13 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.13)\n\t\t    %weight_hh_l0.13 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.13)\n\t\t    %weight_ih_l0.13 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.13)\n\t\t-   %698 : Tensor[] = prim::ListConstruct(%weight_ih_l0.13, %weight_hh_l0.13, %bias_ih_l0.13, %bias_hh_l0.13, %weight_ih_l1.13, %weight_hh_l1.13, %bias_ih_l1.13, %bias_hh_l1.13, %weight_ih_l2.13, %weight_hh_l2.13, %bias_ih_l2.13, %bias_hh_l2.13), scope: __module.decoder/__module.decoder.rnn\n\t\t?    ^^\n\t\t+   %708 : Tensor[] = prim::ListConstruct(%weight_ih_l0.13, %weight_hh_l0.13, %bias_ih_l0.13, %bias_hh_l0.13, %weight_ih_l1.13, %weight_hh_l1.13, %bias_ih_l1.13, %bias_hh_l1.13, %weight_ih_l2.13, %weight_hh_l2.13, %bias_ih_l2.13, %bias_hh_l2.13), scope: __module.decoder/__module.decoder.rnn\n\t\t?    ^^\n\t\t-   %output.21 : Tensor, %decoder_hidden.13 : Tensor = aten::gru(%input.73, %110, %698, %649, %650, %651, %656, %656, %649), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                             ^^^^^^ ^^^^^^^^    ------------------------\n\t\t+   %output.21 : Tensor, %decoder_hidden.13 : Tensor = aten::gru(%input.73, %120, %708, %659, %660, %661, %666, %666, %659), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                             ^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %701 : (Tensor, Tensor) = prim::TupleConstruct(%output.21, %decoder_hidden.13)\n\t\t?     -\n\t\t+   %711 : (Tensor, Tensor) = prim::TupleConstruct(%output.21, %decoder_hidden.13)\n\t\t?      +\n\t\t-   %702 : Tensor, %703 : Tensor = prim::TupleUnpack(%701)\n\t\t?     ^              ^                                 ^\n\t\t+   %712 : Tensor, %713 : Tensor = prim::TupleUnpack(%711)\n\t\t?     ^              ^                                 ^\n\t\t-   %704 : Tensor = aten::squeeze(%702, %657), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %714 : Tensor = aten::squeeze(%712, %667), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %705 : Tensor = aten::squeeze(%context.11, %657), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %715 : Tensor = aten::squeeze(%context.11, %667), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %706 : Tensor = aten::squeeze(%embedded.11, %657), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t+   %716 : Tensor = aten::squeeze(%embedded.11, %667), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t-   %707 : Tensor[] = prim::ListConstruct(%704, %705, %706), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %717 : Tensor[] = prim::ListConstruct(%714, %715, %716), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.75 : Tensor = aten::cat(%707, %657), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.75 : Tensor = aten::cat(%717, %667), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.47 : Tensor = prim::GetAttr[name=\"bias\"](%fc.11)\n\t\t    %weight.65 : Tensor = prim::GetAttr[name=\"weight\"](%fc.11)\n\t\t    %output.23 : Tensor = aten::linear(%input.75, %weight.65, %bias.47), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %712 : (Tensor, Tensor) = prim::TupleConstruct(%output.23, %703)\n\t\t?     -                                                          ^\n\t\t+   %722 : (Tensor, Tensor) = prim::TupleConstruct(%output.23, %713)\n\t\t?      +                                                         ^\n\t\t-   %130 : Tensor, %131 : Tensor = prim::TupleUnpack(%712)\n\t\t?      ^              ^                                ^\n\t\t+   %135 : Tensor, %136 : Tensor = prim::TupleUnpack(%722)\n\t\t?      ^              ^                                ^\n\t\t-   %132 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t+   %137 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t-   %133 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t+   %138 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t-   %134 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t+   %139 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t-   %135 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %140 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %136 : Tensor = aten::slice(%outputs, %132, %133, %134, %135) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                                     ^     ^     ^    ^^\n\t\t+   %141 : Tensor = aten::slice(%outputs, %137, %138, %139, %140) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                                     ^     ^     ^    ^^\n\t\t-   %137 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %138 : int = prim::Constant[value=6]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %139 : Tensor = aten::select(%136, %137, %138) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %140 : bool = prim::Constant[value=0]()\n\t\t-   %141 : Tensor = aten::copy_(%139, %130, %140) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %142 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                                                                                             ^\n\t\t+   %142 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                                                                                             ^\n\t\t-   %143 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?          ^^^^                        ^                                                                       ^\n\t\t+   %143 : int = prim::Constant[value=6]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?          ^^^                        ^                                                                       ^\n\t\t+   %144 : Tensor = aten::select(%141, %142, %143) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %145 : bool = prim::Constant[value=0]()\n\t\t+   %146 : Tensor = aten::copy_(%144, %135, %145) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %147 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %148 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %149 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %150 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %151 : Tensor = aten::slice(%trg, %147, %148, %149, %150) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %152 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %153 : int = prim::Constant[value=6]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %input_token.13 : Tensor = aten::argmax(%130, %142, %143) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                    ^^^^^^   ^^    ^     ^                                                                      ^\n\t\t+   %input_token.13 : Tensor = aten::select(%151, %152, %153) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                    ^^^^^^   ^^    ^     ^                                                                      ^\n\t\t-   %713 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %723 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %714 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %724 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %715 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %725 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %716 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %726 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %717 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %727 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %718 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %728 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %719 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %729 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %720 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %730 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %721 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %731 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.15 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.13 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.15 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.77 : Tensor = aten::unsqueeze(%input_token.13, %721), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t+   %input.77 : Tensor = aten::unsqueeze(%input_token.13, %731), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t    %weight.67 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.15)\n\t\t-   %embedded.13 : Tensor = aten::embedding(%weight.67, %input.77, %719, %720, %720), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                  ------        ^\n\t\t+   %embedded.13 : Tensor = aten::embedding(%weight.67, %input.77, %729, %730, %730), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                     ++++++     ^\n\t\t    %V.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.13)\n\t\t    %W2.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.13)\n\t\t    %W1.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.13)\n\t\t-   %732 : Tensor = aten::select(%131, %716, %719), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                             ^    ^     ^\n\t\t+   %742 : Tensor = aten::select(%136, %726, %729), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                             ^    ^     ^\n\t\t-   %input.79 : Tensor = aten::unsqueeze(%732, %721), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t+   %input.79 : Tensor = aten::unsqueeze(%742, %731), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t    %bias.49 : Tensor = prim::GetAttr[name=\"bias\"](%W1.13)\n\t\t    %weight.69 : Tensor = prim::GetAttr[name=\"weight\"](%W1.13)\n\t\t-   %736 : Tensor = aten::linear(%30, %weight.69, %bias.49), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %746 : Tensor = aten::linear(%30, %weight.69, %bias.49), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.51 : Tensor = prim::GetAttr[name=\"bias\"](%W2.13)\n\t\t    %weight.71 : Tensor = prim::GetAttr[name=\"weight\"](%W2.13)\n\t\t-   %739 : Tensor = aten::linear(%input.79, %weight.71, %bias.51), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %749 : Tensor = aten::linear(%input.79, %weight.71, %bias.51), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t-   %740 : Tensor = aten::add(%736, %739, %721), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^      ------\n\t\t+   %750 : Tensor = aten::add(%746, %749, %731), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^  ++++++\n\t\t-   %input.81 : Tensor = aten::tanh(%740), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.81 : Tensor = aten::tanh(%750), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.53 : Tensor = prim::GetAttr[name=\"bias\"](%V.13)\n\t\t    %weight.73 : Tensor = prim::GetAttr[name=\"weight\"](%V.13)\n\t\t    %input.83 : Tensor = aten::linear(%input.81, %weight.73, %bias.53), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %745 : Tensor = aten::softmax(%input.83, %721, %717), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     -                                         ------\n\t\t+   %755 : Tensor = aten::softmax(%input.83, %731, %727), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      +                                     ++++++\n\t\t-   %attention_weights.13 : Tensor = aten::transpose(%745, %721, %718), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^      ------\n\t\t+   %attention_weights.13 : Tensor = aten::transpose(%755, %731, %728), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^  ++++++\n\t\t    %context.13 : Tensor = aten::bmm(%attention_weights.13, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %748 : Tensor[] = prim::ListConstruct(%embedded.13, %context.13), scope: __module.decoder\n\t\t?     ^\n\t\t+   %758 : Tensor[] = prim::ListConstruct(%embedded.13, %context.13), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.85 : Tensor = aten::cat(%748, %718), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t+   %input.85 : Tensor = aten::cat(%758, %728), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t    %bias_hh_l2.15 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.15)\n\t\t    %bias_ih_l2.15 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.15)\n\t\t    %weight_hh_l2.15 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.15)\n\t\t    %weight_ih_l2.15 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.15)\n\t\t    %bias_hh_l1.15 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.15)\n\t\t    %bias_ih_l1.15 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.15)\n\t\t    %weight_hh_l1.15 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.15)\n\t\t    %weight_ih_l1.15 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.15)\n\t\t    %bias_hh_l0.15 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.15)\n\t\t    %bias_ih_l0.15 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.15)\n\t\t    %weight_hh_l0.15 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.15)\n\t\t    %weight_ih_l0.15 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.15)\n\t\t-   %762 : Tensor[] = prim::ListConstruct(%weight_ih_l0.15, %weight_hh_l0.15, %bias_ih_l0.15, %bias_hh_l0.15, %weight_ih_l1.15, %weight_hh_l1.15, %bias_ih_l1.15, %bias_hh_l1.15, %weight_ih_l2.15, %weight_hh_l2.15, %bias_ih_l2.15, %bias_hh_l2.15), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t+   %772 : Tensor[] = prim::ListConstruct(%weight_ih_l0.15, %weight_hh_l0.15, %bias_ih_l0.15, %bias_hh_l0.15, %weight_ih_l1.15, %weight_hh_l1.15, %bias_ih_l1.15, %bias_hh_l1.15, %weight_ih_l2.15, %weight_hh_l2.15, %bias_ih_l2.15, %bias_hh_l2.15), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t-   %output.25 : Tensor, %decoder_hidden.15 : Tensor = aten::gru(%input.85, %131, %762, %713, %714, %715, %720, %720, %713), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ----- ^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.25 : Tensor, %decoder_hidden.15 : Tensor = aten::gru(%input.85, %136, %772, %723, %724, %725, %730, %730, %723), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                               ^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^\n\t\t-   %765 : (Tensor, Tensor) = prim::TupleConstruct(%output.25, %decoder_hidden.15)\n\t\t?     ^\n\t\t+   %775 : (Tensor, Tensor) = prim::TupleConstruct(%output.25, %decoder_hidden.15)\n\t\t?     ^\n\t\t-   %766 : Tensor, %767 : Tensor = prim::TupleUnpack(%765)\n\t\t?      -             -                                 ^\n\t\t+   %776 : Tensor, %777 : Tensor = prim::TupleUnpack(%775)\n\t\t?     +               +                                ^\n\t\t-   %768 : Tensor = aten::squeeze(%766, %721), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %778 : Tensor = aten::squeeze(%776, %731), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %769 : Tensor = aten::squeeze(%context.13, %721), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %779 : Tensor = aten::squeeze(%context.13, %731), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %770 : Tensor = aten::squeeze(%embedded.13, %721), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t+   %780 : Tensor = aten::squeeze(%embedded.13, %731), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t-   %771 : Tensor[] = prim::ListConstruct(%768, %769, %770), scope: __module.decoder\n\t\t?     ^                                     ^  ------\n\t\t+   %781 : Tensor[] = prim::ListConstruct(%778, %779, %780), scope: __module.decoder\n\t\t?     ^                                     ^      ++++++\n\t\t-   %input.87 : Tensor = aten::cat(%771, %721), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.87 : Tensor = aten::cat(%781, %731), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.55 : Tensor = prim::GetAttr[name=\"bias\"](%fc.13)\n\t\t    %weight.75 : Tensor = prim::GetAttr[name=\"weight\"](%fc.13)\n\t\t    %output.27 : Tensor = aten::linear(%input.87, %weight.75, %bias.55), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %776 : (Tensor, Tensor) = prim::TupleConstruct(%output.27, %767)\n\t\t?     ^                                                          ^\n\t\t+   %786 : (Tensor, Tensor) = prim::TupleConstruct(%output.27, %777)\n\t\t?     ^                                                          ^\n\t\t-   %146 : Tensor, %147 : Tensor = prim::TupleUnpack(%776)\n\t\t?     ^              ^                                 ^\n\t\t+   %156 : Tensor, %157 : Tensor = prim::TupleUnpack(%786)\n\t\t?     ^              ^                                 ^\n\t\t-   %148 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %158 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %149 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %159 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %150 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %160 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %151 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %161 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %152 : Tensor = aten::slice(%outputs, %148, %149, %150, %151) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                   ------------   ^\n\t\t+   %162 : Tensor = aten::slice(%outputs, %158, %159, %160, %161) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                      ^     ++++++++++++\n\t\t-   %153 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %163 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %154 : int = prim::Constant[value=7]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %164 : int = prim::Constant[value=7]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %155 : Tensor = aten::select(%152, %153, %154) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -                           ^     ^     ^\n\t\t+   %165 : Tensor = aten::select(%162, %163, %164) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +                            ^     ^     ^\n\t\t-   %156 : bool = prim::Constant[value=0]()\n\t\t?     -\n\t\t+   %166 : bool = prim::Constant[value=0]()\n\t\t?      +\n\t\t-   %157 : Tensor = aten::copy_(%155, %146, %156) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^  ------\n\t\t+   %167 : Tensor = aten::copy_(%165, %156, %166) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^       ++++++\n\t\t-   %158 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^                               ^                                                                       ^\n\t\t+   %168 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                               ^                                                                       ^\n\t\t-   %159 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^    ^^^^                                                                                                ^\n\t\t+   %169 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^    ^^^                                                                                                ^\n\t\t+   %170 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %171 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %172 : Tensor = aten::slice(%trg, %168, %169, %170, %171) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %173 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %174 : int = prim::Constant[value=7]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %input_token.15 : Tensor = aten::argmax(%146, %158, %159) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                    ^^^^^^   ^^    ^^    ^^                                                                     ^\n\t\t+   %input_token.15 : Tensor = aten::select(%172, %173, %174) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                    ^^^^^^   ^^    ^^    ^^                                                                     ^\n\t\t-   %777 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %787 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     +\n\t\t-   %778 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     -\n\t\t+   %788 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      +\n\t\t-   %779 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %789 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %780 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %790 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %781 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %791 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %782 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %792 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %783 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %793 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %784 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %794 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %785 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %795 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.17 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.15 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.17 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.89 : Tensor = aten::unsqueeze(%input_token.15, %785), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t+   %input.89 : Tensor = aten::unsqueeze(%input_token.15, %795), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t    %weight.77 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.17)\n\t\t-   %embedded.15 : Tensor = aten::embedding(%weight.77, %input.89, %783, %784, %784), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^     ^     ^\n\t\t+   %embedded.15 : Tensor = aten::embedding(%weight.77, %input.89, %793, %794, %794), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^     ^     ^\n\t\t    %V.15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.15)\n\t\t    %W2.15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.15)\n\t\t    %W1.15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.15)\n\t\t-   %796 : Tensor = aten::select(%147, %780, %783), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?    ^^                            ^     ^     ^\n\t\t+   %806 : Tensor = aten::select(%157, %790, %793), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?    ^^                            ^     ^     ^\n\t\t-   %input.91 : Tensor = aten::unsqueeze(%796, %785), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ------\n\t\t+   %input.91 : Tensor = aten::unsqueeze(%806, %795), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                         ++++++\n\t\t    %bias.57 : Tensor = prim::GetAttr[name=\"bias\"](%W1.15)\n\t\t    %weight.79 : Tensor = prim::GetAttr[name=\"weight\"](%W1.15)\n\t\t-   %800 : Tensor = aten::linear(%30, %weight.79, %bias.57), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t+   %810 : Tensor = aten::linear(%30, %weight.79, %bias.57), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t    %bias.59 : Tensor = prim::GetAttr[name=\"bias\"](%W2.15)\n\t\t    %weight.81 : Tensor = prim::GetAttr[name=\"weight\"](%W2.15)\n\t\t-   %803 : Tensor = aten::linear(%input.91, %weight.81, %bias.59), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %813 : Tensor = aten::linear(%input.91, %weight.81, %bias.59), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t-   %804 : Tensor = aten::add(%800, %803, %785), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %814 : Tensor = aten::add(%810, %813, %795), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.93 : Tensor = aten::tanh(%804), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.93 : Tensor = aten::tanh(%814), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.61 : Tensor = prim::GetAttr[name=\"bias\"](%V.15)\n\t\t    %weight.83 : Tensor = prim::GetAttr[name=\"weight\"](%V.15)\n\t\t    %input.95 : Tensor = aten::linear(%input.93, %weight.83, %bias.61), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %809 : Tensor = aten::softmax(%input.95, %785, %781), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t+   %819 : Tensor = aten::softmax(%input.95, %795, %791), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t-   %attention_weights.15 : Tensor = aten::transpose(%809, %785, %782), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t+   %attention_weights.15 : Tensor = aten::transpose(%819, %795, %792), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t    %context.15 : Tensor = aten::bmm(%attention_weights.15, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %812 : Tensor[] = prim::ListConstruct(%embedded.15, %context.15), scope: __module.decoder\n\t\t?     -\n\t\t+   %822 : Tensor[] = prim::ListConstruct(%embedded.15, %context.15), scope: __module.decoder\n\t\t?      +\n\t\t-   %input.97 : Tensor = aten::cat(%812, %782), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t+   %input.97 : Tensor = aten::cat(%822, %792), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t    %bias_hh_l2.17 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.17)\n\t\t    %bias_ih_l2.17 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.17)\n\t\t    %weight_hh_l2.17 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.17)\n\t\t    %weight_ih_l2.17 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.17)\n\t\t    %bias_hh_l1.17 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.17)\n\t\t    %bias_ih_l1.17 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.17)\n\t\t    %weight_hh_l1.17 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.17)\n\t\t    %weight_ih_l1.17 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.17)\n\t\t    %bias_hh_l0.17 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.17)\n\t\t    %bias_ih_l0.17 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.17)\n\t\t    %weight_hh_l0.17 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.17)\n\t\t    %weight_ih_l0.17 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.17)\n\t\t-   %826 : Tensor[] = prim::ListConstruct(%weight_ih_l0.17, %weight_hh_l0.17, %bias_ih_l0.17, %bias_hh_l0.17, %weight_ih_l1.17, %weight_hh_l1.17, %bias_ih_l1.17, %bias_hh_l1.17, %weight_ih_l2.17, %weight_hh_l2.17, %bias_ih_l2.17, %bias_hh_l2.17), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t+   %836 : Tensor[] = prim::ListConstruct(%weight_ih_l0.17, %weight_hh_l0.17, %bias_ih_l0.17, %bias_hh_l0.17, %weight_ih_l1.17, %weight_hh_l1.17, %bias_ih_l1.17, %bias_hh_l1.17, %weight_ih_l2.17, %weight_hh_l2.17, %bias_ih_l2.17, %bias_hh_l2.17), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t-   %output.29 : Tensor, %decoder_hidden.17 : Tensor = aten::gru(%input.97, %147, %826, %777, %778, %779, %784, %784, %777), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^      ------\n\t\t+   %output.29 : Tensor, %decoder_hidden.17 : Tensor = aten::gru(%input.97, %157, %836, %787, %788, %789, %794, %794, %787), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                             +++++++++++++++++++++++++++++++ ^^^^^\n\t\t-   %829 : (Tensor, Tensor) = prim::TupleConstruct(%output.29, %decoder_hidden.17)\n\t\t?     ^\n\t\t+   %839 : (Tensor, Tensor) = prim::TupleConstruct(%output.29, %decoder_hidden.17)\n\t\t?     ^\n\t\t-   %830 : Tensor, %831 : Tensor = prim::TupleUnpack(%829)\n\t\t?     ^              ^                                 ^\n\t\t+   %840 : Tensor, %841 : Tensor = prim::TupleUnpack(%839)\n\t\t?     ^              ^                                 ^\n\t\t-   %832 : Tensor = aten::squeeze(%830, %785), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %842 : Tensor = aten::squeeze(%840, %795), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %833 : Tensor = aten::squeeze(%context.15, %785), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      -                                         ^\n\t\t+   %843 : Tensor = aten::squeeze(%context.15, %795), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     +                                          ^\n\t\t-   %834 : Tensor = aten::squeeze(%embedded.15, %785), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     -                                           ^\n\t\t+   %844 : Tensor = aten::squeeze(%embedded.15, %795), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      +                                          ^\n\t\t-   %835 : Tensor[] = prim::ListConstruct(%832, %833, %834), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %845 : Tensor[] = prim::ListConstruct(%842, %843, %844), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.99 : Tensor = aten::cat(%835, %785), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.99 : Tensor = aten::cat(%845, %795), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.63 : Tensor = prim::GetAttr[name=\"bias\"](%fc.15)\n\t\t    %weight.85 : Tensor = prim::GetAttr[name=\"weight\"](%fc.15)\n\t\t    %output.31 : Tensor = aten::linear(%input.99, %weight.85, %bias.63), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %840 : (Tensor, Tensor) = prim::TupleConstruct(%output.31, %831)\n\t\t?     ^                                                          ^\n\t\t+   %850 : (Tensor, Tensor) = prim::TupleConstruct(%output.31, %841)\n\t\t?     ^                                                          ^\n\t\t-   %162 : Tensor, %163 : Tensor = prim::TupleUnpack(%840)\n\t\t?     ^^             ^^                                ^\n\t\t+   %177 : Tensor, %178 : Tensor = prim::TupleUnpack(%850)\n\t\t?     ^^             ^^                                ^\n\t\t-   %164 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %179 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %165 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %180 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %166 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %181 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %167 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %182 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %168 : Tensor = aten::slice(%outputs, %164, %165, %166, %167) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -                                     ^^    ^^    ^^    ^^\n\t\t+   %183 : Tensor = aten::slice(%outputs, %179, %180, %181, %182) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +                                    ^^    ^^    ^^    ^^\n\t\t-   %169 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %184 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %170 : int = prim::Constant[value=8]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %185 : int = prim::Constant[value=8]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %171 : Tensor = aten::select(%168, %169, %170) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                           -     ^^    ^^\n\t\t+   %186 : Tensor = aten::select(%183, %184, %185) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                            +    ^^    ^^\n\t\t-   %172 : bool = prim::Constant[value=0]()\n\t\t?      -\n\t\t+   %187 : bool = prim::Constant[value=0]()\n\t\t?     +\n\t\t-   %173 : Tensor = aten::copy_(%171, %162, %172) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                          ^^ ------    ^\n\t\t+   %188 : Tensor = aten::copy_(%186, %177, %187) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                          ^^     ^^^^^^^\n\t\t-   %174 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t+   %189 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t-   %175 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t+   %190 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t-   %176 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t+   %191 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t-   %177 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %178 : Tensor = aten::slice(%trg, %174, %175, %176, %177) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %179 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     -\n\t\t+   %192 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      +\n\t\t+   %193 : Tensor = aten::slice(%trg, %189, %190, %191, %192) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %194 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %180 : int = prim::Constant[value=8]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t+   %195 : int = prim::Constant[value=8]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t-   %input_token.17 : Tensor = aten::select(%178, %179, %180) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^^    -     ^^\n\t\t+   %input_token.17 : Tensor = aten::select(%193, %194, %195) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^^     +    ^^\n\t\t-   %841 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %851 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %842 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %852 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %843 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %853 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %844 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      -\n\t\t+   %854 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     +\n\t\t-   %845 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     -\n\t\t+   %855 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      +\n\t\t-   %846 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %856 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %847 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %857 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %848 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %858 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %849 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %859 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.17 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.19 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.17 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.19 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.101 : Tensor = aten::unsqueeze(%input_token.17, %849), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t+   %input.101 : Tensor = aten::unsqueeze(%input_token.17, %859), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t    %weight.87 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.19)\n\t\t-   %embedded.17 : Tensor = aten::embedding(%weight.87, %input.101, %847, %848, %848), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                     ^     ^     ^\n\t\t+   %embedded.17 : Tensor = aten::embedding(%weight.87, %input.101, %857, %858, %858), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                     ^     ^     ^\n\t\t    %V.17 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.17)\n\t\t    %W2.17 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.17)\n\t\t    %W1.17 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.17)\n\t\t-   %860 : Tensor = aten::select(%163, %844, %847), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^^    ^     ^\n\t\t+   %870 : Tensor = aten::select(%178, %854, %857), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^^    ^     ^\n\t\t-   %input.103 : Tensor = aten::unsqueeze(%860, %849), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t+   %input.103 : Tensor = aten::unsqueeze(%870, %859), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t    %bias.65 : Tensor = prim::GetAttr[name=\"bias\"](%W1.17)\n\t\t    %weight.89 : Tensor = prim::GetAttr[name=\"weight\"](%W1.17)\n\t\t-   %864 : Tensor = aten::linear(%30, %weight.89, %bias.65), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %874 : Tensor = aten::linear(%30, %weight.89, %bias.65), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.67 : Tensor = prim::GetAttr[name=\"bias\"](%W2.17)\n\t\t    %weight.91 : Tensor = prim::GetAttr[name=\"weight\"](%W2.17)\n\t\t-   %867 : Tensor = aten::linear(%input.103, %weight.91, %bias.67), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     - ^^\n\t\t+   %877 : Tensor = aten::linear(%input.103, %weight.91, %bias.67), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^\n\t\t-   %868 : Tensor = aten::add(%864, %867, %849), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %878 : Tensor = aten::add(%874, %877, %859), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.105 : Tensor = aten::tanh(%868), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                      ^\n\t\t+   %input.105 : Tensor = aten::tanh(%878), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                      ^\n\t\t    %bias.69 : Tensor = prim::GetAttr[name=\"bias\"](%V.17)\n\t\t    %weight.93 : Tensor = prim::GetAttr[name=\"weight\"](%V.17)\n\t\t    %input.107 : Tensor = aten::linear(%input.105, %weight.93, %bias.69), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %873 : Tensor = aten::softmax(%input.107, %849, %845), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                         ^     ^\n\t\t+   %883 : Tensor = aten::softmax(%input.107, %859, %855), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                         ^     ^\n\t\t-   %attention_weights.17 : Tensor = aten::transpose(%873, %849, %846), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t+   %attention_weights.17 : Tensor = aten::transpose(%883, %859, %856), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t    %context.17 : Tensor = aten::bmm(%attention_weights.17, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %876 : Tensor[] = prim::ListConstruct(%embedded.17, %context.17), scope: __module.decoder\n\t\t?     ^\n\t\t+   %886 : Tensor[] = prim::ListConstruct(%embedded.17, %context.17), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.109 : Tensor = aten::cat(%876, %846), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^     ^\n\t\t+   %input.109 : Tensor = aten::cat(%886, %856), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^     ^\n\t\t    %bias_hh_l2.19 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.19)\n\t\t    %bias_ih_l2.19 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.19)\n\t\t    %weight_hh_l2.19 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.19)\n\t\t    %weight_ih_l2.19 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.19)\n\t\t    %bias_hh_l1.19 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.19)\n\t\t    %bias_ih_l1.19 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.19)\n\t\t    %weight_hh_l1.19 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.19)\n\t\t    %weight_ih_l1.19 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.19)\n\t\t    %bias_hh_l0.19 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.19)\n\t\t    %bias_ih_l0.19 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.19)\n\t\t    %weight_hh_l0.19 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.19)\n\t\t    %weight_ih_l0.19 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.19)\n\t\t-   %890 : Tensor[] = prim::ListConstruct(%weight_ih_l0.19, %weight_hh_l0.19, %bias_ih_l0.19, %bias_hh_l0.19, %weight_ih_l1.19, %weight_hh_l1.19, %bias_ih_l1.19, %bias_hh_l1.19, %weight_ih_l2.19, %weight_hh_l2.19, %bias_ih_l2.19, %bias_hh_l2.19), scope: __module.decoder/__module.decoder.rnn\n\t\t?    ^^^^^\n\t\t+   %900 : Tensor[] = prim::ListConstruct(%weight_ih_l0.19, %weight_hh_l0.19, %bias_ih_l0.19, %bias_hh_l0.19, %weight_ih_l1.19, %weight_hh_l1.19, %bias_ih_l1.19, %bias_hh_l1.19, %weight_ih_l2.19, %weight_hh_l2.19, %bias_ih_l2.19, %bias_hh_l2.19), scope: __module.decoder/__module.decoder.rnn\n\t\t?    ^^^^^\n\t\t-   %output.33 : Tensor, %decoder_hidden.19 : Tensor = aten::gru(%input.109, %163, %890, %841, %842, %843, %848, %848, %841), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.33 : Tensor, %decoder_hidden.19 : Tensor = aten::gru(%input.109, %178, %900, %851, %852, %853, %858, %858, %851), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^\n\t\t-   %893 : (Tensor, Tensor) = prim::TupleConstruct(%output.33, %decoder_hidden.19)\n\t\t?    -\n\t\t+   %903 : (Tensor, Tensor) = prim::TupleConstruct(%output.33, %decoder_hidden.19)\n\t\t?     +\n\t\t-   %894 : Tensor, %895 : Tensor = prim::TupleUnpack(%893)\n\t\t?    -              -                                 -\n\t\t+   %904 : Tensor, %905 : Tensor = prim::TupleUnpack(%903)\n\t\t?     +              +                                 +\n\t\t-   %896 : Tensor = aten::squeeze(%894, %849), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?    -                             -      ^\n\t\t+   %906 : Tensor = aten::squeeze(%904, %859), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     +                             +     ^\n\t\t-   %897 : Tensor = aten::squeeze(%context.17, %849), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?    -                                           ^\n\t\t+   %907 : Tensor = aten::squeeze(%context.17, %859), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     +                                          ^\n\t\t-   %898 : Tensor = aten::squeeze(%embedded.17, %849), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     --                                          ^\n\t\t+   %908 : Tensor = aten::squeeze(%embedded.17, %859), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?    ++                                           ^\n\t\t-   %899 : Tensor[] = prim::ListConstruct(%896, %897, %898), scope: __module.decoder\n\t\t?    -                                     -     -     -\n\t\t+   %909 : Tensor[] = prim::ListConstruct(%906, %907, %908), scope: __module.decoder\n\t\t?     +                                     +     +     +\n\t\t-   %input.111 : Tensor = aten::cat(%899, %849), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    -      ^\n\t\t+   %input.111 : Tensor = aten::cat(%909, %859), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                     +     ^\n\t\t    %bias.71 : Tensor = prim::GetAttr[name=\"bias\"](%fc.17)\n\t\t    %weight.95 : Tensor = prim::GetAttr[name=\"weight\"](%fc.17)\n\t\t    %output.35 : Tensor = aten::linear(%input.111, %weight.95, %bias.71), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %904 : (Tensor, Tensor) = prim::TupleConstruct(%output.35, %895)\n\t\t?     ^                                                         -\n\t\t+   %914 : (Tensor, Tensor) = prim::TupleConstruct(%output.35, %905)\n\t\t?     ^                                                          +\n\t\t-   %183 : Tensor, %184 : Tensor = prim::TupleUnpack(%904)\n\t\t?      -             ^^                                ^\n\t\t+   %198 : Tensor, %199 : Tensor = prim::TupleUnpack(%914)\n\t\t?     +              ^^                                ^\n\t\t+   %200 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %185 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     --\n\t\t+   %201 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ++\n\t\t-   %186 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %187 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^^\n\t\t+   %202 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^^\n\t\t-   %188 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %189 : Tensor = aten::slice(%outputs, %185, %186, %187, %188) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %190 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^\n\t\t+   %203 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^ +\n\t\t+   %204 : Tensor = aten::slice(%outputs, %200, %201, %202, %203) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %205 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %191 : int = prim::Constant[value=9]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^^\n\t\t+   %206 : int = prim::Constant[value=9]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^^\n\t\t-   %192 : Tensor = aten::select(%189, %190, %191) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    --                           ^^^   ^^    ^^^\n\t\t+   %207 : Tensor = aten::select(%204, %205, %206) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ++                          ^^^   ^ +   ^^^\n\t\t-   %193 : bool = prim::Constant[value=0]()\n\t\t?    ^^^\n\t\t+   %208 : bool = prim::Constant[value=0]()\n\t\t?    ^^^\n\t\t-   %194 : Tensor = aten::copy_(%192, %183, %193) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^ -                         --  ------    ^\n\t\t+   %209 : Tensor = aten::copy_(%207, %198, %208) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                           ++     ^^^^^^^\n\t\t-   %195 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^^\n\t\t+   %210 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?    + ^\n\t\t-   %196 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^^\n\t\t+   %211 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?    + ^\n\t\t-   %input_token.19 : Tensor = aten::argmax(%183, %195, %196) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                              -    ^^    ^^\n\t\t+   %input_token.19 : Tensor = aten::argmax(%198, %210, %211) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                             +    + ^   + ^\n\t\t-   %905 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %915 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %906 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %916 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %907 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %917 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %908 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %918 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %909 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %919 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %910 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %920 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %911 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      -\n\t\t+   %921 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     +\n\t\t-   %912 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     -\n\t\t+   %922 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      +\n\t\t-   %913 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %923 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.21 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.19 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.21 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.113 : Tensor = aten::unsqueeze(%input_token.19, %913), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t+   %input.113 : Tensor = aten::unsqueeze(%input_token.19, %923), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t    %weight.97 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.21)\n\t\t-   %embedded.19 : Tensor = aten::embedding(%weight.97, %input.113, %911, %912, %912), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                     ^     ^     ^\n\t\t+   %embedded.19 : Tensor = aten::embedding(%weight.97, %input.113, %921, %922, %922), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                     ^     ^     ^\n\t\t    %V.19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.19)\n\t\t    %W2.19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.19)\n\t\t    %W1.19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.19)\n\t\t-   %924 : Tensor = aten::select(%184, %908, %911), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^^ ------\n\t\t+   %934 : Tensor = aten::select(%199, %918, %921), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^^     ++++++\n\t\t-   %input.115 : Tensor = aten::unsqueeze(%924, %913), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t+   %input.115 : Tensor = aten::unsqueeze(%934, %923), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t    %bias.73 : Tensor = prim::GetAttr[name=\"bias\"](%W1.19)\n\t\t    %weight.99 : Tensor = prim::GetAttr[name=\"weight\"](%W1.19)\n\t\t-   %928 : Tensor = aten::linear(%30, %weight.99, %bias.73), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %938 : Tensor = aten::linear(%30, %weight.99, %bias.73), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.75 : Tensor = prim::GetAttr[name=\"bias\"](%W2.19)\n\t\t    %weight.101 : Tensor = prim::GetAttr[name=\"weight\"](%W2.19)\n\t\t-   %931 : Tensor = aten::linear(%input.115, %weight.101, %bias.75), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t+   %941 : Tensor = aten::linear(%input.115, %weight.101, %bias.75), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t-   %932 : Tensor = aten::add(%928, %931, %913), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %942 : Tensor = aten::add(%938, %941, %923), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.117 : Tensor = aten::tanh(%932), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                      ^\n\t\t+   %input.117 : Tensor = aten::tanh(%942), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                      ^\n\t\t    %bias.77 : Tensor = prim::GetAttr[name=\"bias\"](%V.19)\n\t\t    %weight.103 : Tensor = prim::GetAttr[name=\"weight\"](%V.19)\n\t\t    %input.119 : Tensor = aten::linear(%input.117, %weight.103, %bias.77), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %937 : Tensor = aten::softmax(%input.119, %913, %909), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                          ------\n\t\t+   %947 : Tensor = aten::softmax(%input.119, %923, %919), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                       ++++++\n\t\t-   %attention_weights.19 : Tensor = aten::transpose(%937, %913, %910), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t+   %attention_weights.19 : Tensor = aten::transpose(%947, %923, %920), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t    %context.19 : Tensor = aten::bmm(%attention_weights.19, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %940 : Tensor[] = prim::ListConstruct(%embedded.19, %context.19), scope: __module.decoder\n\t\t?     ^\n\t\t+   %950 : Tensor[] = prim::ListConstruct(%embedded.19, %context.19), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.121 : Tensor = aten::cat(%940, %910), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^     ^\n\t\t+   %input.121 : Tensor = aten::cat(%950, %920), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^     ^\n\t\t    %bias_hh_l2.21 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.21)\n\t\t    %bias_ih_l2.21 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.21)\n\t\t    %weight_hh_l2.21 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.21)\n\t\t    %weight_ih_l2.21 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.21)\n\t\t    %bias_hh_l1.21 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.21)\n\t\t    %bias_ih_l1.21 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.21)\n\t\t    %weight_hh_l1.21 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.21)\n\t\t    %weight_ih_l1.21 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.21)\n\t\t    %bias_hh_l0.21 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.21)\n\t\t    %bias_ih_l0.21 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.21)\n\t\t    %weight_hh_l0.21 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.21)\n\t\t    %weight_ih_l0.21 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.21)\n\t\t-   %954 : Tensor[] = prim::ListConstruct(%weight_ih_l0.21, %weight_hh_l0.21, %bias_ih_l0.21, %bias_hh_l0.21, %weight_ih_l1.21, %weight_hh_l1.21, %bias_ih_l1.21, %bias_hh_l1.21, %weight_ih_l2.21, %weight_hh_l2.21, %bias_ih_l2.21, %bias_hh_l2.21), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t+   %964 : Tensor[] = prim::ListConstruct(%weight_ih_l0.21, %weight_hh_l0.21, %bias_ih_l0.21, %bias_hh_l0.21, %weight_ih_l1.21, %weight_hh_l1.21, %bias_ih_l1.21, %bias_hh_l1.21, %weight_ih_l2.21, %weight_hh_l2.21, %bias_ih_l2.21, %bias_hh_l2.21), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t-   %output.37 : Tensor, %decoder_hidden.21 : Tensor = aten::gru(%input.121, %184, %954, %905, %906, %907, %912, %912, %905), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^      ^^^^^^^^^^^^     ^     ^^^^^^^^^^^^^\n\t\t+   %output.37 : Tensor, %decoder_hidden.21 : Tensor = aten::gru(%input.121, %199, %964, %915, %916, %917, %922, %922, %915), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^     + ^^^^^     ^     ^^^^^^^^^^^^^\n\t\t-   %957 : (Tensor, Tensor) = prim::TupleConstruct(%output.37, %decoder_hidden.21)\n\t\t?     ^\n\t\t+   %967 : (Tensor, Tensor) = prim::TupleConstruct(%output.37, %decoder_hidden.21)\n\t\t?     ^\n\t\t-   %958 : Tensor, %959 : Tensor = prim::TupleUnpack(%957)\n\t\t?     ^              ^                                 ^\n\t\t+   %968 : Tensor, %969 : Tensor = prim::TupleUnpack(%967)\n\t\t?     ^              ^                                 ^\n\t\t-   %960 : Tensor = aten::squeeze(%958, %913), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %970 : Tensor = aten::squeeze(%968, %923), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %961 : Tensor = aten::squeeze(%context.19, %913), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %971 : Tensor = aten::squeeze(%context.19, %923), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %962 : Tensor = aten::squeeze(%embedded.19, %913), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t+   %972 : Tensor = aten::squeeze(%embedded.19, %923), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t-   %963 : Tensor[] = prim::ListConstruct(%960, %961, %962), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %973 : Tensor[] = prim::ListConstruct(%970, %971, %972), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.123 : Tensor = aten::cat(%963, %913), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                     ^     ^\n\t\t+   %input.123 : Tensor = aten::cat(%973, %923), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                     ^     ^\n\t\t    %bias.79 : Tensor = prim::GetAttr[name=\"bias\"](%fc.19)\n\t\t    %weight.105 : Tensor = prim::GetAttr[name=\"weight\"](%fc.19)\n\t\t    %output.39 : Tensor = aten::linear(%input.123, %weight.105, %bias.79), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %968 : (Tensor, Tensor) = prim::TupleConstruct(%output.39, %959)\n\t\t?     ^                                                          ^\n\t\t+   %978 : (Tensor, Tensor) = prim::TupleConstruct(%output.39, %969)\n\t\t?     ^                                                          ^\n\t\t-   %199 : Tensor, %200 : Tensor = prim::TupleUnpack(%968)\n\t\t?     ^^             ^^                                ^\n\t\t+   %214 : Tensor, %215 : Tensor = prim::TupleUnpack(%978)\n\t\t?    + ^             ^^                                ^\n\t\t-   %201 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %216 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %202 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %203 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %204 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %205 : Tensor = aten::slice(%outputs, %201, %202, %203, %204) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %206 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %207 : int = prim::Constant[value=10]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                               -\n\t\t+   %217 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %208 : Tensor = aten::select(%205, %206, %207) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %209 : bool = prim::Constant[value=0]()\n\t\t-   %210 : Tensor = aten::copy_(%208, %199, %209) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %211 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %212 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %213 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      ^                                                                                                                        ^\n\t\t+   %218 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^                                                                                                                        ^\n\t\t-   %214 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      ^                                                                                                      ^\n\t\t+   %219 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^                                                                                                      ^\n\t\t-   %215 : Tensor = aten::slice(%trg, %211, %212, %213, %214) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^                          ^^     ^     ^     ^     ^                                                                     ^\n\t\t+   %220 : Tensor = aten::slice(%outputs, %216, %217, %218, %219) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                         ++ ^^^^     ^     ^     ^     ^                                                                     ^\n\t\t-   %216 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      -                                                                                                      ^\n\t\t+   %221 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +                                                                                                       ^\n\t\t-   %217 : int = prim::Constant[value=10]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^                                                                                                       ^\n\t\t+   %222 : int = prim::Constant[value=10]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                                                                                                       ^\n\t\t+   %223 : Tensor = aten::select(%220, %221, %222) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %224 : bool = prim::Constant[value=0]()\n\t\t+   %225 : Tensor = aten::copy_(%223, %214, %224) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %226 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t+   %227 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t-   %input_token.21 : Tensor = aten::select(%215, %216, %217) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                    ^^^^^^    ^    ^     ^                                                                      ^\n\t\t+   %input_token.21 : Tensor = aten::argmax(%214, %226, %227) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                    ^^^^^^    ^    ^     ^                                                                      ^\n\t\t-   %969 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %979 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %970 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %980 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %971 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %981 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %972 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %982 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %973 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %983 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %974 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %984 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %975 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %985 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %976 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %986 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %977 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      -\n\t\t+   %987 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     +\n\t\t    %fc.21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.23 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.21 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.23 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.125 : Tensor = aten::unsqueeze(%input_token.21, %977), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t+   %input.125 : Tensor = aten::unsqueeze(%input_token.21, %987), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t    %weight.107 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.23)\n\t\t-   %embedded.21 : Tensor = aten::embedding(%weight.107, %input.125, %975, %976, %976), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                      ^     ^     ^\n\t\t+   %embedded.21 : Tensor = aten::embedding(%weight.107, %input.125, %985, %986, %986), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                      ^     ^     ^\n\t\t    %V.21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.21)\n\t\t    %W2.21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.21)\n\t\t    %W1.21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.21)\n\t\t-   %988 : Tensor = aten::select(%200, %972, %975), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      -                           ^^    ^     ^\n\t\t+   %998 : Tensor = aten::select(%215, %982, %985), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     +                            ^^    ^     ^\n\t\t-   %input.127 : Tensor = aten::unsqueeze(%988, %977), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t+   %input.127 : Tensor = aten::unsqueeze(%998, %987), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t    %bias.81 : Tensor = prim::GetAttr[name=\"bias\"](%W1.21)\n\t\t    %weight.109 : Tensor = prim::GetAttr[name=\"weight\"](%W1.21)\n\t\t-   %992 : Tensor = aten::linear(%30, %weight.109, %bias.81), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?    ^^\n\t\t+   %1002 : Tensor = aten::linear(%30, %weight.109, %bias.81), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?    ^^^\n\t\t    %bias.83 : Tensor = prim::GetAttr[name=\"bias\"](%W2.21)\n\t\t    %weight.111 : Tensor = prim::GetAttr[name=\"weight\"](%W2.21)\n\t\t-   %995 : Tensor = aten::linear(%input.127, %weight.111, %bias.83), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?    ^^\n\t\t+   %1005 : Tensor = aten::linear(%input.127, %weight.111, %bias.83), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?    ^^^\n\t\t-   %996 : Tensor = aten::add(%992, %995, %977), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?    ^^                        ^^     ^^^^^^^\n\t\t+   %1006 : Tensor = aten::add(%1002, %1005, %987), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?    ^^^                        ^^^   +++++++  ^\n\t\t-   %input.129 : Tensor = aten::tanh(%996), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^^\n\t\t+   %input.129 : Tensor = aten::tanh(%1006), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^^^\n\t\t    %bias.85 : Tensor = prim::GetAttr[name=\"bias\"](%V.21)\n\t\t    %weight.113 : Tensor = prim::GetAttr[name=\"weight\"](%V.21)\n\t\t    %input.131 : Tensor = aten::linear(%input.129, %weight.113, %bias.85), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1001 : Tensor = aten::softmax(%input.131, %977, %973), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      -                                         ^     ^\n\t\t+   %1011 : Tensor = aten::softmax(%input.131, %987, %983), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?       +                                        ^     ^\n\t\t-   %attention_weights.21 : Tensor = aten::transpose(%1001, %977, %974), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^     ^     ^\n\t\t+   %attention_weights.21 : Tensor = aten::transpose(%1011, %987, %984), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^     ^     ^\n\t\t    %context.21 : Tensor = aten::bmm(%attention_weights.21, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %1004 : Tensor[] = prim::ListConstruct(%embedded.21, %context.21), scope: __module.decoder\n\t\t?      ^\n\t\t+   %1014 : Tensor[] = prim::ListConstruct(%embedded.21, %context.21), scope: __module.decoder\n\t\t?      ^\n\t\t-   %input.133 : Tensor = aten::cat(%1004, %974), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^     ^\n\t\t+   %input.133 : Tensor = aten::cat(%1014, %984), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^     ^\n\t\t    %bias_hh_l2.23 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.23)\n\t\t    %bias_ih_l2.23 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.23)\n\t\t    %weight_hh_l2.23 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.23)\n\t\t    %weight_ih_l2.23 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.23)\n\t\t    %bias_hh_l1.23 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.23)\n\t\t    %bias_ih_l1.23 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.23)\n\t\t    %weight_hh_l1.23 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.23)\n\t\t    %weight_ih_l1.23 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.23)\n\t\t    %bias_hh_l0.23 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.23)\n\t\t    %bias_ih_l0.23 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.23)\n\t\t    %weight_hh_l0.23 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.23)\n\t\t    %weight_ih_l0.23 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.23)\n\t\t-   %1018 : Tensor[] = prim::ListConstruct(%weight_ih_l0.23, %weight_hh_l0.23, %bias_ih_l0.23, %bias_hh_l0.23, %weight_ih_l1.23, %weight_hh_l1.23, %bias_ih_l1.23, %bias_hh_l1.23, %weight_ih_l2.23, %weight_hh_l2.23, %bias_ih_l2.23, %bias_hh_l2.23), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^\n\t\t+   %1028 : Tensor[] = prim::ListConstruct(%weight_ih_l0.23, %weight_hh_l0.23, %bias_ih_l0.23, %bias_hh_l0.23, %weight_ih_l1.23, %weight_hh_l1.23, %bias_ih_l1.23, %bias_hh_l1.23, %weight_ih_l2.23, %weight_hh_l2.23, %bias_ih_l2.23, %bias_hh_l2.23), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^\n\t\t-   %output.41 : Tensor, %decoder_hidden.23 : Tensor = aten::gru(%input.133, %200, %1018, %969, %970, %971, %976, %976, %969), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^^^^^^^ ^^    ------------------------\n\t\t+   %output.41 : Tensor, %decoder_hidden.23 : Tensor = aten::gru(%input.133, %215, %1028, %979, %980, %981, %986, %986, %979), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^\n\t\t-   %1021 : (Tensor, Tensor) = prim::TupleConstruct(%output.41, %decoder_hidden.23)\n\t\t?      ^\n\t\t+   %1031 : (Tensor, Tensor) = prim::TupleConstruct(%output.41, %decoder_hidden.23)\n\t\t?      ^\n\t\t-   %1022 : Tensor, %1023 : Tensor = prim::TupleUnpack(%1021)\n\t\t?       -              -                                  ^\n\t\t+   %1032 : Tensor, %1033 : Tensor = prim::TupleUnpack(%1031)\n\t\t?      +                +                                 ^\n\t\t-   %1024 : Tensor = aten::squeeze(%1022, %977), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                              ^     ^\n\t\t+   %1034 : Tensor = aten::squeeze(%1032, %987), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                              ^     ^\n\t\t-   %1025 : Tensor = aten::squeeze(%context.21, %977), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                          ^\n\t\t+   %1035 : Tensor = aten::squeeze(%context.21, %987), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                          ^\n\t\t-   %1026 : Tensor = aten::squeeze(%embedded.21, %977), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                           ^\n\t\t+   %1036 : Tensor = aten::squeeze(%embedded.21, %987), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                           ^\n\t\t-   %1027 : Tensor[] = prim::ListConstruct(%1024, %1025, %1026), scope: __module.decoder\n\t\t?      ^                                      ^      ^      ^\n\t\t+   %1037 : Tensor[] = prim::ListConstruct(%1034, %1035, %1036), scope: __module.decoder\n\t\t?      ^                                      ^      ^      ^\n\t\t-   %input.135 : Tensor = aten::cat(%1027, %977), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                      ^     ^\n\t\t+   %input.135 : Tensor = aten::cat(%1037, %987), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                      ^     ^\n\t\t    %bias.87 : Tensor = prim::GetAttr[name=\"bias\"](%fc.21)\n\t\t    %weight.115 : Tensor = prim::GetAttr[name=\"weight\"](%fc.21)\n\t\t    %output.43 : Tensor = aten::linear(%input.135, %weight.115, %bias.87), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1032 : (Tensor, Tensor) = prim::TupleConstruct(%output.43, %1023)\n\t\t?      ^                                                           ^\n\t\t+   %1042 : (Tensor, Tensor) = prim::TupleConstruct(%output.43, %1033)\n\t\t?      ^                                                           ^\n\t\t-   %220 : Tensor, %221 : Tensor = prim::TupleUnpack(%1032)\n\t\t?     ^              ^                                  ^\n\t\t+   %230 : Tensor, %231 : Tensor = prim::TupleUnpack(%1042)\n\t\t?     ^              ^                                  ^\n\t\t-   %222 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -\n\t\t+   %232 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +\n\t\t-   %223 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %233 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %224 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %234 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %225 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %235 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %226 : Tensor = aten::slice(%outputs, %222, %223, %224, %225) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^           ^^^^^^^\n\t\t+   %236 : Tensor = aten::slice(%outputs, %232, %233, %234, %235) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     +++++  +    ^\n\t\t-   %227 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %237 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %228 : int = prim::Constant[value=11]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %238 : int = prim::Constant[value=11]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %229 : Tensor = aten::select(%226, %227, %228) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t+   %239 : Tensor = aten::select(%236, %237, %238) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t-   %230 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t+   %240 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t-   %231 : Tensor = aten::copy_(%229, %220, %230) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^  ------\n\t\t+   %241 : Tensor = aten::copy_(%239, %230, %240) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^       ++++++\n\t\t-   %232 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %242 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %233 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      -\n\t\t+   %243 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     +\n\t\t-   %234 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     -\n\t\t+   %244 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      +\n\t\t-   %235 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %245 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %236 : Tensor = aten::slice(%trg, %232, %233, %234, %235) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                                 ^     ^     ^     ^\n\t\t+   %246 : Tensor = aten::slice(%trg, %242, %243, %244, %245) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                                 ^     ^     ^     ^\n\t\t-   %237 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %247 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %238 : int = prim::Constant[value=11]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %248 : int = prim::Constant[value=11]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %input_token.23 : Tensor = aten::select(%236, %237, %238) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^     ^     ^\n\t\t+   %input_token.23 : Tensor = aten::select(%246, %247, %248) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^     ^     ^\n\t\t-   %1033 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?       -\n\t\t+   %1043 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      +\n\t\t-   %1034 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %1044 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?       +\n\t\t-   %1035 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t+   %1045 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t-   %1036 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^\n\t\t+   %1046 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^\n\t\t-   %1037 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      ^\n\t\t+   %1047 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      ^\n\t\t-   %1038 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      ^\n\t\t+   %1048 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      ^\n\t\t-   %1039 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t+   %1049 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t-   %1040 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t+   %1050 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t-   %1041 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t+   %1051 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t    %fc.23 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.25 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.23 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.25 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.137 : Tensor = aten::unsqueeze(%input_token.23, %1041), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                             ^\n\t\t+   %input.137 : Tensor = aten::unsqueeze(%input_token.23, %1051), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                             ^\n\t\t    %weight.117 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.25)\n\t\t-   %embedded.23 : Tensor = aten::embedding(%weight.117, %input.137, %1039, %1040, %1040), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                       ^      ^^^^^^^^\n\t\t+   %embedded.23 : Tensor = aten::embedding(%weight.117, %input.137, %1049, %1050, %1050), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                       ^      ^^^^^^^^\n\t\t    %V.23 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.23)\n\t\t    %W2.23 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.23)\n\t\t    %W1.23 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.23)\n\t\t-   %1052 : Tensor = aten::select(%221, %1036, %1039), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t+   %1062 : Tensor = aten::select(%231, %1046, %1049), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t-   %input.139 : Tensor = aten::unsqueeze(%1052, %1041), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t+   %input.139 : Tensor = aten::unsqueeze(%1062, %1051), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t    %bias.89 : Tensor = prim::GetAttr[name=\"bias\"](%W1.23)\n\t\t    %weight.119 : Tensor = prim::GetAttr[name=\"weight\"](%W1.23)\n\t\t-   %1056 : Tensor = aten::linear(%30, %weight.119, %bias.89), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      - ^^\n\t\t+   %1066 : Tensor = aten::linear(%30, %weight.119, %bias.89), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?       ^^^\n\t\t    %bias.91 : Tensor = prim::GetAttr[name=\"bias\"](%W2.23)\n\t\t    %weight.121 : Tensor = prim::GetAttr[name=\"weight\"](%W2.23)\n\t\t-   %1059 : Tensor = aten::linear(%input.139, %weight.121, %bias.91), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t+   %1069 : Tensor = aten::linear(%input.139, %weight.121, %bias.91), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t-   %1060 : Tensor = aten::add(%1056, %1059, %1041), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      ^                          ^       -------\n\t\t+   %1070 : Tensor = aten::add(%1066, %1069, %1051), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      ^                          ^  +++++++\n\t\t-   %input.141 : Tensor = aten::tanh(%1060), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t+   %input.141 : Tensor = aten::tanh(%1070), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t    %bias.93 : Tensor = prim::GetAttr[name=\"bias\"](%V.23)\n\t\t    %weight.123 : Tensor = prim::GetAttr[name=\"weight\"](%V.23)\n\t\t    %input.143 : Tensor = aten::linear(%input.141, %weight.123, %bias.93), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1065 : Tensor = aten::softmax(%input.143, %1041, %1037), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      ^                                           -------\n\t\t+   %1075 : Tensor = aten::softmax(%input.143, %1051, %1047), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      ^                                       +++++++\n\t\t-   %attention_weights.23 : Tensor = aten::transpose(%1065, %1041, %1038), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^       -------\n\t\t+   %attention_weights.23 : Tensor = aten::transpose(%1075, %1051, %1048), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^  +++++++\n\t\t    %context.23 : Tensor = aten::bmm(%attention_weights.23, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %1068 : Tensor[] = prim::ListConstruct(%embedded.23, %context.23), scope: __module.decoder\n\t\t?      ^\n\t\t+   %1078 : Tensor[] = prim::ListConstruct(%embedded.23, %context.23), scope: __module.decoder\n\t\t?      ^\n\t\t-   %input.145 : Tensor = aten::cat(%1068, %1038), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^      ^\n\t\t+   %input.145 : Tensor = aten::cat(%1078, %1048), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^      ^\n\t\t    %bias_hh_l2.25 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.25)\n\t\t    %bias_ih_l2.25 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.25)\n\t\t    %weight_hh_l2.25 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.25)\n\t\t    %weight_ih_l2.25 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.25)\n\t\t    %bias_hh_l1.25 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.25)\n\t\t    %bias_ih_l1.25 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.25)\n\t\t    %weight_hh_l1.25 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.25)\n\t\t    %weight_ih_l1.25 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.25)\n\t\t    %bias_hh_l0.25 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.25)\n\t\t    %bias_ih_l0.25 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.25)\n\t\t    %weight_hh_l0.25 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.25)\n\t\t    %weight_ih_l0.25 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.25)\n\t\t-   %1082 : Tensor[] = prim::ListConstruct(%weight_ih_l0.25, %weight_hh_l0.25, %bias_ih_l0.25, %bias_hh_l0.25, %weight_ih_l1.25, %weight_hh_l1.25, %bias_ih_l1.25, %bias_hh_l1.25, %weight_ih_l2.25, %weight_hh_l2.25, %bias_ih_l2.25, %bias_hh_l2.25), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^^\n\t\t+   %1092 : Tensor[] = prim::ListConstruct(%weight_ih_l0.25, %weight_hh_l0.25, %bias_ih_l0.25, %bias_hh_l0.25, %weight_ih_l1.25, %weight_hh_l1.25, %bias_ih_l1.25, %bias_hh_l1.25, %weight_ih_l2.25, %weight_hh_l2.25, %bias_ih_l2.25, %bias_hh_l2.25), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^^\n\t\t-   %output.45 : Tensor, %decoder_hidden.25 : Tensor = aten::gru(%input.145, %221, %1082, %1033, %1034, %1035, %1040, %1040, %1033), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.45 : Tensor, %decoder_hidden.25 : Tensor = aten::gru(%input.145, %231, %1092, %1043, %1044, %1045, %1050, %1050, %1043), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ++++++++ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1085 : (Tensor, Tensor) = prim::TupleConstruct(%output.45, %decoder_hidden.25)\n\t\t?      ^\n\t\t+   %1095 : (Tensor, Tensor) = prim::TupleConstruct(%output.45, %decoder_hidden.25)\n\t\t?      ^\n\t\t-   %1086 : Tensor, %1087 : Tensor = prim::TupleUnpack(%1085)\n\t\t?      ^               ^                                  ^\n\t\t+   %1096 : Tensor, %1097 : Tensor = prim::TupleUnpack(%1095)\n\t\t?      ^               ^                                  ^\n\t\t-   %1088 : Tensor = aten::squeeze(%1086, %1041), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?       -                             ^      ^\n\t\t+   %1098 : Tensor = aten::squeeze(%1096, %1051), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      +                              ^      ^\n\t\t-   %1089 : Tensor = aten::squeeze(%context.23, %1041), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      -                                           ^\n\t\t+   %1099 : Tensor = aten::squeeze(%context.23, %1051), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?       +                                          ^\n\t\t-   %1090 : Tensor = aten::squeeze(%embedded.23, %1041), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      -                                            ^\n\t\t+   %1100 : Tensor = aten::squeeze(%embedded.23, %1051), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     +                                             ^\n\t\t-   %1091 : Tensor[] = prim::ListConstruct(%1088, %1089, %1090), scope: __module.decoder\n\t\t?      -                                      ^  -------\n\t\t+   %1101 : Tensor[] = prim::ListConstruct(%1098, %1099, %1100), scope: __module.decoder\n\t\t?     +                                       ^       +++++++\n\t\t-   %input.147 : Tensor = aten::cat(%1091, %1041), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                      -      ^\n\t\t+   %input.147 : Tensor = aten::cat(%1101, %1051), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                     +       ^\n\t\t    %bias.95 : Tensor = prim::GetAttr[name=\"bias\"](%fc.23)\n\t\t    %weight.125 : Tensor = prim::GetAttr[name=\"weight\"](%fc.23)\n\t\t    %output.47 : Tensor = aten::linear(%input.147, %weight.125, %bias.95), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1096 : (Tensor, Tensor) = prim::TupleConstruct(%output.47, %1087)\n\t\t?      -                                                           ^\n\t\t+   %1106 : (Tensor, Tensor) = prim::TupleConstruct(%output.47, %1097)\n\t\t?     +                                                            ^\n\t\t-   %241 : Tensor, %242 : Tensor = prim::TupleUnpack(%1096)\n\t\t?     ^              ^                                  -\n\t\t+   %251 : Tensor, %252 : Tensor = prim::TupleUnpack(%1106)\n\t\t?     ^              ^                                 +\n\t\t-   %243 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %253 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %244 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -\n\t\t+   %254 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +\n\t\t-   %245 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %255 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %246 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %256 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %247 : Tensor = aten::slice(%outputs, %243, %244, %245, %246) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t+   %257 : Tensor = aten::slice(%outputs, %253, %254, %255, %256) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t-   %248 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %258 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %249 : int = prim::Constant[value=12]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %259 : int = prim::Constant[value=12]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %250 : Tensor = aten::select(%247, %248, %249) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t+   %260 : Tensor = aten::select(%257, %258, %259) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t-   %251 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t+   %261 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t-   %252 : Tensor = aten::copy_(%250, %241, %251) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^  ------\n\t\t+   %262 : Tensor = aten::copy_(%260, %251, %261) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^       ++++++\n\t\t-   %253 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %263 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %254 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %264 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %255 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      -\n\t\t+   %265 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     +\n\t\t-   %256 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     -\n\t\t+   %266 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      +\n\t\t-   %257 : Tensor = aten::slice(%trg, %253, %254, %255, %256) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                                 ^     ^     ^     ^\n\t\t+   %267 : Tensor = aten::slice(%trg, %263, %264, %265, %266) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                                 ^     ^     ^     ^\n\t\t-   %258 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %268 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %259 : int = prim::Constant[value=12]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %269 : int = prim::Constant[value=12]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %input_token.25 : Tensor = aten::select(%257, %258, %259) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^     ^     ^\n\t\t+   %input_token.25 : Tensor = aten::select(%267, %268, %269) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^     ^     ^\n\t\t-   %1097 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %1107 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     +\n\t\t-   %1098 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %1108 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     +\n\t\t-   %1099 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?       -\n\t\t+   %1109 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    +\n\t\t-   %1100 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?       -\n\t\t+   %1110 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      +\n\t\t-   %1101 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      -\n\t\t+   %1111 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?       +\n\t\t-   %1102 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      ^\n\t\t+   %1112 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      ^\n\t\t-   %1103 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t+   %1113 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t-   %1104 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t+   %1114 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t-   %1105 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t+   %1115 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t    %fc.25 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.27 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.25 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.27 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.149 : Tensor = aten::unsqueeze(%input_token.25, %1105), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                             ^\n\t\t+   %input.149 : Tensor = aten::unsqueeze(%input_token.25, %1115), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                             ^\n\t\t    %weight.127 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.27)\n\t\t-   %embedded.25 : Tensor = aten::embedding(%weight.127, %input.149, %1103, %1104, %1104), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                       ^      ^^^^^^^^\n\t\t+   %embedded.25 : Tensor = aten::embedding(%weight.127, %input.149, %1113, %1114, %1114), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                       ^      ^^^^^^^^\n\t\t    %V.25 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.25)\n\t\t    %W2.25 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.25)\n\t\t    %W1.25 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.25)\n\t\t-   %1116 : Tensor = aten::select(%242, %1100, %1103), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t+   %1126 : Tensor = aten::select(%252, %1110, %1113), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t-   %input.151 : Tensor = aten::unsqueeze(%1116, %1105), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t+   %input.151 : Tensor = aten::unsqueeze(%1126, %1115), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t    %bias.97 : Tensor = prim::GetAttr[name=\"bias\"](%W1.25)\n\t\t    %weight.129 : Tensor = prim::GetAttr[name=\"weight\"](%W1.25)\n\t\t-   %1120 : Tensor = aten::linear(%30, %weight.129, %bias.97), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^^\n\t\t+   %1130 : Tensor = aten::linear(%30, %weight.129, %bias.97), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^^\n\t\t    %bias.99 : Tensor = prim::GetAttr[name=\"bias\"](%W2.25)\n\t\t    %weight.131 : Tensor = prim::GetAttr[name=\"weight\"](%W2.25)\n\t\t-   %1123 : Tensor = aten::linear(%input.151, %weight.131, %bias.99), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^^\n\t\t+   %1133 : Tensor = aten::linear(%input.151, %weight.131, %bias.99), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^^\n\t\t-   %1124 : Tensor = aten::add(%1120, %1123, %1105), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      ^                          ^      ^      ^\n\t\t+   %1134 : Tensor = aten::add(%1130, %1133, %1115), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      ^                          ^      ^      ^\n\t\t-   %input.153 : Tensor = aten::tanh(%1124), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t+   %input.153 : Tensor = aten::tanh(%1134), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t    %bias.101 : Tensor = prim::GetAttr[name=\"bias\"](%V.25)\n\t\t    %weight.133 : Tensor = prim::GetAttr[name=\"weight\"](%V.25)\n\t\t    %input.155 : Tensor = aten::linear(%input.153, %weight.133, %bias.101), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1129 : Tensor = aten::softmax(%input.155, %1105, %1101), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      ^                                          ^      ^\n\t\t+   %1139 : Tensor = aten::softmax(%input.155, %1115, %1111), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      ^                                          ^      ^\n\t\t-   %attention_weights.25 : Tensor = aten::transpose(%1129, %1105, %1102), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^      ^      ^\n\t\t+   %attention_weights.25 : Tensor = aten::transpose(%1139, %1115, %1112), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^      ^      ^\n\t\t    %context.25 : Tensor = aten::bmm(%attention_weights.25, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %1132 : Tensor[] = prim::ListConstruct(%embedded.25, %context.25), scope: __module.decoder\n\t\t?      ^\n\t\t+   %1142 : Tensor[] = prim::ListConstruct(%embedded.25, %context.25), scope: __module.decoder\n\t\t?      ^\n\t\t-   %input.157 : Tensor = aten::cat(%1132, %1102), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^      ^\n\t\t+   %input.157 : Tensor = aten::cat(%1142, %1112), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^      ^\n\t\t    %bias_hh_l2.27 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.27)\n\t\t    %bias_ih_l2.27 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.27)\n\t\t    %weight_hh_l2.27 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.27)\n\t\t    %weight_ih_l2.27 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.27)\n\t\t    %bias_hh_l1.27 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.27)\n\t\t    %bias_ih_l1.27 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.27)\n\t\t    %weight_hh_l1.27 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.27)\n\t\t    %weight_ih_l1.27 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.27)\n\t\t    %bias_hh_l0.27 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.27)\n\t\t    %bias_ih_l0.27 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.27)\n\t\t    %weight_hh_l0.27 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.27)\n\t\t    %weight_ih_l0.27 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.27)\n\t\t-   %1146 : Tensor[] = prim::ListConstruct(%weight_ih_l0.27, %weight_hh_l0.27, %bias_ih_l0.27, %bias_hh_l0.27, %weight_ih_l1.27, %weight_hh_l1.27, %bias_ih_l1.27, %bias_hh_l1.27, %weight_ih_l2.27, %weight_hh_l2.27, %bias_ih_l2.27, %bias_hh_l2.27), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^\n\t\t+   %1156 : Tensor[] = prim::ListConstruct(%weight_ih_l0.27, %weight_hh_l0.27, %bias_ih_l0.27, %bias_hh_l0.27, %weight_ih_l1.27, %weight_hh_l1.27, %bias_ih_l1.27, %bias_hh_l1.27, %weight_ih_l2.27, %weight_hh_l2.27, %bias_ih_l2.27, %bias_hh_l2.27), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^\n\t\t-   %output.49 : Tensor, %decoder_hidden : Tensor = aten::gru(%input.157, %242, %1146, %1097, %1098, %1099, %1104, %1104, %1097), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                           ^      ^       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.49 : Tensor, %decoder_hidden : Tensor = aten::gru(%input.157, %252, %1156, %1107, %1108, %1109, %1114, %1114, %1107), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                           ^      ^    +++++++++++++++   ^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1149 : (Tensor, Tensor) = prim::TupleConstruct(%output.49, %decoder_hidden)\n\t\t?      ^\n\t\t+   %1159 : (Tensor, Tensor) = prim::TupleConstruct(%output.49, %decoder_hidden)\n\t\t?      ^\n\t\t-   %1150 : Tensor, %1151 : Tensor = prim::TupleUnpack(%1149)\n\t\t?      ^               ^                                  ^\n\t\t+   %1160 : Tensor, %1161 : Tensor = prim::TupleUnpack(%1159)\n\t\t?      ^               ^                                  ^\n\t\t-   %1152 : Tensor = aten::squeeze(%1150, %1105), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                              ^      ^\n\t\t+   %1162 : Tensor = aten::squeeze(%1160, %1115), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                              ^      ^\n\t\t-   %1153 : Tensor = aten::squeeze(%context.25, %1105), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                           ^\n\t\t+   %1163 : Tensor = aten::squeeze(%context.25, %1115), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                           ^\n\t\t-   %1154 : Tensor = aten::squeeze(%embedded.25, %1105), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                            ^\n\t\t+   %1164 : Tensor = aten::squeeze(%embedded.25, %1115), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                            ^\n\t\t-   %1155 : Tensor[] = prim::ListConstruct(%1152, %1153, %1154), scope: __module.decoder\n\t\t?       -                                     ^      ^      ^\n\t\t+   %1165 : Tensor[] = prim::ListConstruct(%1162, %1163, %1164), scope: __module.decoder\n\t\t?      +                                      ^      ^      ^\n\t\t-   %input.159 : Tensor = aten::cat(%1155, %1105), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                      ^      ^\n\t\t+   %input.159 : Tensor = aten::cat(%1165, %1115), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                      ^      ^\n\t\t    %bias.103 : Tensor = prim::GetAttr[name=\"bias\"](%fc.25)\n\t\t    %weight.135 : Tensor = prim::GetAttr[name=\"weight\"](%fc.25)\n\t\t    %output.51 : Tensor = aten::linear(%input.159, %weight.135, %bias.103), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1160 : (Tensor, Tensor) = prim::TupleConstruct(%output.51, %1151)\n\t\t?      ^                                                           ^\n\t\t+   %1170 : (Tensor, Tensor) = prim::TupleConstruct(%output.51, %1161)\n\t\t?      ^                                                           ^\n\t\t-   %262 : Tensor, %263 : Tensor = prim::TupleUnpack(%1160)\n\t\t?     ^              ^                                  ^\n\t\t+   %272 : Tensor, %273 : Tensor = prim::TupleUnpack(%1170)\n\t\t?     ^              ^                                  ^\n\t\t-   %264 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %274 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %265 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %275 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %266 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -\n\t\t+   %276 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +\n\t\t-   %267 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %277 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %268 : Tensor = aten::slice(%outputs, %264, %265, %266, %267) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t+   %278 : Tensor = aten::slice(%outputs, %274, %275, %276, %277) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t-   %269 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %279 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %270 : int = prim::Constant[value=13]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %280 : int = prim::Constant[value=13]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %271 : Tensor = aten::select(%268, %269, %270) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^  ------\n\t\t+   %281 : Tensor = aten::select(%278, %279, %280) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^      ++++++\n\t\t-   %272 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t+   %282 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t-   %273 : Tensor = aten::copy_(%271, %262, %272) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^  ------\n\t\t+   %283 : Tensor = aten::copy_(%281, %272, %282) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^       ++++++\n\t\t-   %274 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %284 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %275 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %285 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %276 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %286 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %277 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      -\n\t\t+   %287 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     +\n\t\t-   %278 : Tensor = aten::slice(%trg, %274, %275, %276, %277) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     -                                 ^     ^     ^     ^\n\t\t+   %288 : Tensor = aten::slice(%trg, %284, %285, %286, %287) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      +                                ^     ^     ^     ^\n\t\t-   %279 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %289 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %280 : int = prim::Constant[value=13]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %290 : int = prim::Constant[value=13]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %input_token : Tensor = aten::select(%278, %279, %280) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                          ^  ------\n\t\t+   %input_token : Tensor = aten::select(%288, %289, %290) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                          ^      ++++++\n\t\t-   %1161 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t+   %1171 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t-   %1162 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t+   %1172 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t-   %1163 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t+   %1173 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t-   %1164 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^\n\t\t+   %1174 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^\n\t\t-   %1165 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      ^\n\t\t+   %1175 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      ^\n\t\t-   %1166 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?       -\n\t\t+   %1176 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      +\n\t\t-   %1167 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      -\n\t\t+   %1177 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?       +\n\t\t-   %1168 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t+   %1178 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t-   %1169 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t+   %1179 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t    %fc : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.161 : Tensor = aten::unsqueeze(%input_token, %1169), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t+   %input.161 : Tensor = aten::unsqueeze(%input_token, %1179), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t    %weight.137 : Tensor = prim::GetAttr[name=\"weight\"](%embedding)\n\t\t-   %embedded : Tensor = aten::embedding(%weight.137, %input.161, %1167, %1168, %1168), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^^^^^^^^      ^\n\t\t+   %embedded : Tensor = aten::embedding(%weight.137, %input.161, %1177, %1178, %1178), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^^^^^^^^      ^\n\t\t    %V : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention)\n\t\t    %W2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention)\n\t\t    %W1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention)\n\t\t-   %1180 : Tensor = aten::select(%263, %1164, %1167), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t+   %1190 : Tensor = aten::select(%273, %1174, %1177), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t-   %input.163 : Tensor = aten::unsqueeze(%1180, %1169), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t+   %input.163 : Tensor = aten::unsqueeze(%1190, %1179), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t    %bias.105 : Tensor = prim::GetAttr[name=\"bias\"](%W1)\n\t\t    %weight.139 : Tensor = prim::GetAttr[name=\"weight\"](%W1)\n\t\t-   %1184 : Tensor = aten::linear(%30, %weight.139, %bias.105), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t+   %1194 : Tensor = aten::linear(%30, %weight.139, %bias.105), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t    %bias.107 : Tensor = prim::GetAttr[name=\"bias\"](%W2)\n\t\t    %weight.141 : Tensor = prim::GetAttr[name=\"weight\"](%W2)\n\t\t-   %1187 : Tensor = aten::linear(%input.163, %weight.141, %bias.107), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t+   %1197 : Tensor = aten::linear(%input.163, %weight.141, %bias.107), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t-   %1188 : Tensor = aten::add(%1184, %1187, %1169), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?       -                         ^      ^      ^\n\t\t+   %1198 : Tensor = aten::add(%1194, %1197, %1179), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      +                          ^      ^      ^\n\t\t-   %input.165 : Tensor = aten::tanh(%1188), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t+   %input.165 : Tensor = aten::tanh(%1198), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t    %bias.109 : Tensor = prim::GetAttr[name=\"bias\"](%V)\n\t\t    %weight.143 : Tensor = prim::GetAttr[name=\"weight\"](%V)\n\t\t    %input.167 : Tensor = aten::linear(%input.165, %weight.143, %bias.109), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1193 : Tensor = aten::softmax(%input.167, %1169, %1165), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^^                                          ^      ^\n\t\t+   %1203 : Tensor = aten::softmax(%input.167, %1179, %1175), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^^                                          ^      ^\n\t\t-   %attention_weights : Tensor = aten::transpose(%1193, %1169, %1166), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                   ^^      ^      ^\n\t\t+   %attention_weights : Tensor = aten::transpose(%1203, %1179, %1176), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                   ^^      ^      ^\n\t\t    %context : Tensor = aten::bmm(%attention_weights, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %1196 : Tensor[] = prim::ListConstruct(%embedded, %context), scope: __module.decoder\n\t\t?     ^^\n\t\t+   %1206 : Tensor[] = prim::ListConstruct(%embedded, %context), scope: __module.decoder\n\t\t?     ^^\n\t\t-   %input.169 : Tensor = aten::cat(%1196, %1166), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^^      ^\n\t\t+   %input.169 : Tensor = aten::cat(%1206, %1176), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^^      ^\n\t\t    %bias_hh_l2 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn)\n\t\t    %bias_ih_l2 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn)\n\t\t    %weight_hh_l2 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn)\n\t\t    %weight_ih_l2 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn)\n\t\t    %bias_hh_l1 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn)\n\t\t    %bias_ih_l1 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn)\n\t\t    %weight_hh_l1 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn)\n\t\t    %weight_ih_l1 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn)\n\t\t    %bias_hh_l0 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn)\n\t\t    %bias_ih_l0 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn)\n\t\t    %weight_hh_l0 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn)\n\t\t    %weight_ih_l0 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn)\n\t\t-   %1210 : Tensor[] = prim::ListConstruct(%weight_ih_l0, %weight_hh_l0, %bias_ih_l0, %bias_hh_l0, %weight_ih_l1, %weight_hh_l1, %bias_ih_l1, %bias_hh_l1, %weight_ih_l2, %weight_hh_l2, %bias_ih_l2, %bias_hh_l2), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^^\n\t\t+   %1220 : Tensor[] = prim::ListConstruct(%weight_ih_l0, %weight_hh_l0, %bias_ih_l0, %bias_hh_l0, %weight_ih_l1, %weight_hh_l1, %bias_ih_l1, %bias_hh_l1, %weight_ih_l2, %weight_hh_l2, %bias_ih_l2, %bias_hh_l2), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^^\n\t\t-   %output.53 : Tensor, %1212 : Tensor = aten::gru(%input.169, %263, %1210, %1161, %1162, %1163, %1168, %1168, %1161), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                           ^^^^                                  ^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^      ^      ^\n\t\t+   %output.53 : Tensor, %1222 : Tensor = aten::gru(%input.169, %273, %1220, %1171, %1172, %1173, %1178, %1178, %1171), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                           ^^^^                                  ^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^      ^      ^\n\t\t-   %1213 : Tensor = aten::squeeze(%output.53, %1169), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                          ^\n\t\t+   %1223 : Tensor = aten::squeeze(%output.53, %1179), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                          ^\n\t\t-   %1214 : Tensor = aten::squeeze(%context, %1169), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                        ^\n\t\t+   %1224 : Tensor = aten::squeeze(%context, %1179), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                        ^\n\t\t-   %1215 : Tensor = aten::squeeze(%embedded, %1169), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                         ^\n\t\t+   %1225 : Tensor = aten::squeeze(%embedded, %1179), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                         ^\n\t\t-   %1216 : Tensor[] = prim::ListConstruct(%1213, %1214, %1215), scope: __module.decoder\n\t\t?      ^                                      ^      ^      ^\n\t\t+   %1226 : Tensor[] = prim::ListConstruct(%1223, %1224, %1225), scope: __module.decoder\n\t\t?      ^                                      ^      ^      ^\n\t\t-   %input : Tensor = aten::cat(%1216, %1169), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                  ^      ^\n\t\t+   %input : Tensor = aten::cat(%1226, %1179), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                  ^      ^\n\t\t    %bias : Tensor = prim::GetAttr[name=\"bias\"](%fc)\n\t\t    %weight : Tensor = prim::GetAttr[name=\"weight\"](%fc)\n\t\t    %output : Tensor = aten::linear(%input, %weight, %bias), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %283 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %293 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %284 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %294 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %285 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %295 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %286 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %296 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %287 : Tensor = aten::slice(%outputs, %283, %284, %285, %286) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t+   %297 : Tensor = aten::slice(%outputs, %293, %294, %295, %296) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t-   %288 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -\n\t\t+   %298 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +\n\t\t-   %289 : int = prim::Constant[value=14]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %299 : int = prim::Constant[value=14]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %290 : Tensor = aten::select(%287, %288, %289) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                            ^     ^     ^\n\t\t+   %300 : Tensor = aten::select(%297, %298, %299) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^ +                           ^     ^     ^\n\t\t-   %291 : bool = prim::Constant[value=0]()\n\t\t?    ^^\n\t\t+   %301 : bool = prim::Constant[value=0]()\n\t\t?    ^^\n\t\t-   %292 : Tensor = aten::copy_(%290, %output, %291) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     --                         ^^             ^^\n\t\t+   %302 : Tensor = aten::copy_(%300, %output, %301) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ++                          ^^             ^^\n\t\t    return (%outputs)\n\tFirst diverging operator:\n\tNode diff:\n\t\t- %decoder : __torch__.___torch_mangle_67.Decoder = prim::GetAttr[name=\"decoder\"](%self.1)\n\t\t?                                      -\n\t\t+ %decoder : __torch__.___torch_mangle_79.Decoder = prim::GetAttr[name=\"decoder\"](%self.1)\n\t\t?                                       +\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTracingCheckError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m X_sample \u001b[38;5;241m=\u001b[39m sample_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meng_input\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m y_sample \u001b[38;5;241m=\u001b[39m sample_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhin_target\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sample\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:841\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[1;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    838\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    839\u001b[0m \u001b[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_graph(\n\u001b[1;32m--> 841\u001b[0m     \u001b[43mgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\utils\\tensorboard\\_pytorch_graph.py:326\u001b[0m, in \u001b[0;36mgraph\u001b[1;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _set_model_to_eval(model):\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 326\u001b[0m         trace \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m         graph \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mgraph\n\u001b[0;32m    328\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_inline(graph)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\jit\\_trace.py:998\u001b[0m, in \u001b[0;36mtrace\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    989\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`optimize` is deprecated and has no effect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `with torch.jit.optimized_execution()` instead\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    993\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    994\u001b[0m     )\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m log_torchscript_usage\n\u001b[1;32m--> 998\u001b[0m traced_func \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1012\u001b[0m log_torchscript_usage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_id\u001b[38;5;241m=\u001b[39m_get_model_id(traced_func))\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m traced_func\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\jit\\_trace.py:696\u001b[0m, in \u001b[0;36m_trace_impl\u001b[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    713\u001b[0m ):\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\jit\\_trace.py:1209\u001b[0m, in \u001b[0;36mtrace_module\u001b[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[0;32m   1197\u001b[0m                 _check_trace(\n\u001b[0;32m   1198\u001b[0m                     check_inputs,\n\u001b[0;32m   1199\u001b[0m                     func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1206\u001b[0m                     example_inputs_is_kwarg\u001b[38;5;241m=\u001b[39mexample_inputs_is_kwarg,\n\u001b[0;32m   1207\u001b[0m                 )\n\u001b[0;32m   1208\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m                 \u001b[43m_check_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcheck_trace_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_trace\u001b[38;5;241m.\u001b[39m_trace_module_map \u001b[38;5;241m=\u001b[39m old_module_map\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\jit\\_trace.py:590\u001b[0m, in \u001b[0;36m_check_trace\u001b[1;34m(check_inputs, func, traced_func, check_tolerance, strict, force_outplace, is_trace_module, _module_class, example_inputs_is_kwarg)\u001b[0m\n\u001b[0;32m    588\u001b[0m diag_info \u001b[38;5;241m=\u001b[39m graph_diagnostic_info()\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m diag_info):\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TracingCheckError(\u001b[38;5;241m*\u001b[39mdiag_info)\n",
      "\u001b[1;31mTracingCheckError\u001b[0m: Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%self.1 : __torch__.Seq2Seq,\n\t\t        %src : Tensor,\n\t\t        %trg : Tensor):\n\t\t    %decoder : __torch__.Decoder = prim::GetAttr[name=\"decoder\"](%self.1)\n\t\t    %encoder : __torch__.Encoder = prim::GetAttr[name=\"encoder\"](%self.1)\n\t\t    %5 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:9:0\n\t\t    %6 : int = aten::size(%src, %5) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:9:0\n\t\t    %batch_size : Tensor = prim::NumToTensor(%6)\n\t\t    %8 : int = aten::Int(%batch_size)\n\t\t    %9 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:10:0\n\t\t    %10 : int = aten::size(%trg, %9) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:10:0\n\t\t    %trg_len : Tensor = prim::NumToTensor(%10)\n\t\t    %12 : int = aten::Int(%trg_len)\n\t\t    %13 : int = prim::Constant[value=43015]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %14 : int[] = prim::ListConstruct(%8, %12, %13)\n\t\t    %15 : NoneType = prim::Constant()\n\t\t    %16 : NoneType = prim::Constant()\n\t\t    %17 : Device = prim::Constant[value=\"cpu\"]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %18 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %19 : Tensor = aten::zeros(%14, %15, %16, %17, %18) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %20 : int = prim::Constant[value=6]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %21 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %22 : Device = prim::Constant[value=\"cuda\"]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %23 : NoneType = prim::Constant()\n\t\t    %24 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %25 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t    %26 : NoneType = prim::Constant()\n\t\t    %outputs : Tensor = aten::to(%19, %20, %21, %22, %23, %24, %25, %26) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:13:0\n\t\t-   %293 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1375:0\n\t\t?    --\n\t\t+   %303 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1375:0\n\t\t?     ++\n\t\t-   %294 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t+   %304 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t-   %295 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t+   %305 : int = prim::Constant[value=256](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t-   %296 : int = prim::Constant[value=6](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t+   %306 : int = prim::Constant[value=6](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t-   %297 : NoneType = prim::Constant(), scope: __module.encoder/__module.encoder.rnn\n\t\t?    ^^\n\t\t+   %307 : NoneType = prim::Constant(), scope: __module.encoder/__module.encoder.rnn\n\t\t?    ^^\n\t\t-   %298 : Device = prim::Constant[value=\"cuda:0\"](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t+   %308 : Device = prim::Constant[value=\"cuda:0\"](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?    ^^\n\t\t-   %299 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    ^ -\n\t\t+   %309 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    ^^\n\t\t-   %300 : float = prim::Constant[value=0.](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %310 : float = prim::Constant[value=0.](), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     +\n\t\t-   %301 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     -\n\t\t+   %311 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      +\n\t\t-   %302 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %312 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t    %rnn.1 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%encoder)\n\t\t    %embedding.1 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%encoder)\n\t\t    %weight.5 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.1)\n\t\t-   %input.1 : Tensor = aten::embedding(%weight.5, %src, %301, %302, %302), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                          ^     ^     ^\n\t\t+   %input.1 : Tensor = aten::embedding(%weight.5, %src, %311, %312, %312), scope: __module.encoder/__module.encoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                          ^     ^     ^\n\t\t    %bias_hh_l2.1 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.1)\n\t\t    %bias_ih_l2.1 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.1)\n\t\t    %weight_hh_l2.1 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.1)\n\t\t    %weight_ih_l2.1 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.1)\n\t\t    %bias_hh_l1.1 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.1)\n\t\t    %bias_ih_l1.1 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.1)\n\t\t    %weight_hh_l1.1 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.1)\n\t\t    %weight_ih_l1.1 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.1)\n\t\t    %bias_hh_l0.1 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.1)\n\t\t    %bias_ih_l0.1 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.1)\n\t\t    %weight_hh_l0.1 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.1)\n\t\t    %weight_ih_l0.1 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.1)\n\t\t-   %319 : int = aten::size(%input.1, %293), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1375:0\n\t\t?     ^                                ^^\n\t\t+   %329 : int = aten::size(%input.1, %303), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1375:0\n\t\t?     ^                                ^^\n\t\t-   %320 : int[] = prim::ListConstruct(%294, %319, %295), scope: __module.encoder/__module.encoder.rnn\n\t\t?     ^                                   -    ^^^^^^^\n\t\t+   %330 : int[] = prim::ListConstruct(%304, %329, %305), scope: __module.encoder/__module.encoder.rnn\n\t\t?     ^                                 +++++++      ^\n\t\t-   %hx : Tensor = aten::zeros(%320, %296, %297, %298, %302), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?                                ^  ------------------\n\t\t+   %hx : Tensor = aten::zeros(%330, %306, %307, %308, %312), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1380:0\n\t\t?                                ^      ++++++++++++++++++\n\t\t-   %322 : Tensor[] = prim::ListConstruct(%weight_ih_l0.1, %weight_hh_l0.1, %bias_ih_l0.1, %bias_hh_l0.1, %weight_ih_l1.1, %weight_hh_l1.1, %bias_ih_l1.1, %bias_hh_l1.1, %weight_ih_l2.1, %weight_hh_l2.1, %bias_ih_l2.1, %bias_hh_l2.1), scope: __module.encoder/__module.encoder.rnn\n\t\t?     ^^^^\n\t\t+   %332 : Tensor[] = prim::ListConstruct(%weight_ih_l0.1, %weight_hh_l0.1, %bias_ih_l0.1, %bias_hh_l0.1, %weight_ih_l1.1, %weight_hh_l1.1, %bias_ih_l1.1, %bias_hh_l1.1, %weight_ih_l2.1, %weight_hh_l2.1, %bias_ih_l2.1, %bias_hh_l2.1), scope: __module.encoder/__module.encoder.rnn\n\t\t?     ^^^^\n\t\t-   %input.5 : Tensor, %decoder_hidden.1 : Tensor = aten::gru(%input.1, %hx, %322, %299, %294, %300, %302, %302, %299), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.5 : Tensor, %decoder_hidden.1 : Tensor = aten::gru(%input.1, %hx, %332, %309, %304, %310, %312, %312, %309), scope: __module.encoder/__module.encoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                             +  +++++++++++++++++++++++    ++ ^^^^^\n\t\t-   %325 : (Tensor, Tensor) = prim::TupleConstruct(%decoder_hidden.1, %input.5)\n\t\t?     ^\n\t\t+   %335 : (Tensor, Tensor) = prim::TupleConstruct(%decoder_hidden.1, %input.5)\n\t\t?     ^\n\t\t-   %326 : Tensor, %327 : Tensor = prim::TupleUnpack(%325)\n\t\t?     ^              ^                                 ^\n\t\t+   %336 : Tensor, %337 : Tensor = prim::TupleUnpack(%335)\n\t\t?     ^              ^                                 ^\n\t\t-   %328 : (Tensor, Tensor) = prim::TupleConstruct(%326, %327)\n\t\t?     ^                                              ^     ^\n\t\t+   %338 : (Tensor, Tensor) = prim::TupleConstruct(%336, %337)\n\t\t?     ^                                              ^     ^\n\t\t-   %29 : Tensor, %30 : Tensor = prim::TupleUnpack(%328)\n\t\t?                                                    ^\n\t\t+   %29 : Tensor, %30 : Tensor = prim::TupleUnpack(%338)\n\t\t?                                                    ^\n\t\t    %31 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %32 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %33 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %34 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %35 : Tensor = aten::slice(%trg, %31, %32, %33, %34) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %36 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %37 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t    %input_token.1 : Tensor = aten::select(%35, %36, %37) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:18:0\n\t\t-   %329 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %339 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %330 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %340 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %331 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %341 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %332 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %342 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %333 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      -\n\t\t+   %343 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     +\n\t\t-   %334 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     -\n\t\t+   %344 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      +\n\t\t-   %335 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %345 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %336 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %346 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %337 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %347 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.3 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.1 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.3 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.3 : Tensor = aten::unsqueeze(%input_token.1, %337), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                         ^\n\t\t+   %input.3 : Tensor = aten::unsqueeze(%input_token.1, %347), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                         ^\n\t\t    %weight.7 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.3)\n\t\t-   %embedded.1 : Tensor = aten::embedding(%weight.7, %input.3, %335, %336, %336), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                 ^     ^     ^\n\t\t+   %embedded.1 : Tensor = aten::embedding(%weight.7, %input.3, %345, %346, %346), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                 ^     ^     ^\n\t\t    %V.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.1)\n\t\t    %W2.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.1)\n\t\t    %W1.1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.1)\n\t\t-   %348 : Tensor = aten::select(%29, %332, %335), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                                 ^     ^\n\t\t+   %358 : Tensor = aten::select(%29, %342, %345), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                                 ^     ^\n\t\t-   %input.7 : Tensor = aten::unsqueeze(%348, %337), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                         ^     ^\n\t\t+   %input.7 : Tensor = aten::unsqueeze(%358, %347), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                         ^     ^\n\t\t    %bias.1 : Tensor = prim::GetAttr[name=\"bias\"](%W1.1)\n\t\t    %weight.9 : Tensor = prim::GetAttr[name=\"weight\"](%W1.1)\n\t\t-   %352 : Tensor = aten::linear(%30, %weight.9, %bias.1), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %362 : Tensor = aten::linear(%30, %weight.9, %bias.1), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.3 : Tensor = prim::GetAttr[name=\"bias\"](%W2.1)\n\t\t    %weight.11 : Tensor = prim::GetAttr[name=\"weight\"](%W2.1)\n\t\t-   %355 : Tensor = aten::linear(%input.7, %weight.11, %bias.3), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^\n\t\t+   %365 : Tensor = aten::linear(%input.7, %weight.11, %bias.3), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     + ^^\n\t\t-   %356 : Tensor = aten::add(%352, %355, %337), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     -                         ^     ^     ^\n\t\t+   %366 : Tensor = aten::add(%362, %365, %347), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      +                        ^     ^     ^\n\t\t-   %input.9 : Tensor = aten::tanh(%356), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                    ^\n\t\t+   %input.9 : Tensor = aten::tanh(%366), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                    ^\n\t\t    %bias.5 : Tensor = prim::GetAttr[name=\"bias\"](%V.1)\n\t\t    %weight.13 : Tensor = prim::GetAttr[name=\"weight\"](%V.1)\n\t\t    %input.11 : Tensor = aten::linear(%input.9, %weight.13, %bias.5), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %361 : Tensor = aten::softmax(%input.11, %337, %333), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t+   %371 : Tensor = aten::softmax(%input.11, %347, %343), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t-   %attention_weights.1 : Tensor = aten::transpose(%361, %337, %334), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^     ^     ^\n\t\t+   %attention_weights.1 : Tensor = aten::transpose(%371, %347, %344), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^     ^     ^\n\t\t    %context.1 : Tensor = aten::bmm(%attention_weights.1, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %364 : Tensor[] = prim::ListConstruct(%embedded.1, %context.1), scope: __module.decoder\n\t\t?     ^\n\t\t+   %374 : Tensor[] = prim::ListConstruct(%embedded.1, %context.1), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.13 : Tensor = aten::cat(%364, %334), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t+   %input.13 : Tensor = aten::cat(%374, %344), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t    %bias_hh_l2.3 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.3)\n\t\t    %bias_ih_l2.3 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.3)\n\t\t    %weight_hh_l2.3 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.3)\n\t\t    %weight_ih_l2.3 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.3)\n\t\t    %bias_hh_l1.3 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.3)\n\t\t    %bias_ih_l1.3 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.3)\n\t\t    %weight_hh_l1.3 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.3)\n\t\t    %weight_ih_l1.3 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.3)\n\t\t    %bias_hh_l0.3 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.3)\n\t\t    %bias_ih_l0.3 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.3)\n\t\t    %weight_hh_l0.3 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.3)\n\t\t    %weight_ih_l0.3 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.3)\n\t\t-   %378 : Tensor[] = prim::ListConstruct(%weight_ih_l0.3, %weight_hh_l0.3, %bias_ih_l0.3, %bias_hh_l0.3, %weight_ih_l1.3, %weight_hh_l1.3, %bias_ih_l1.3, %bias_hh_l1.3, %weight_ih_l2.3, %weight_hh_l2.3, %bias_ih_l2.3, %bias_hh_l2.3), scope: __module.decoder/__module.decoder.rnn\n\t\t?     - ^^\n\t\t+   %388 : Tensor[] = prim::ListConstruct(%weight_ih_l0.3, %weight_hh_l0.3, %bias_ih_l0.3, %bias_hh_l0.3, %weight_ih_l1.3, %weight_hh_l1.3, %bias_ih_l1.3, %bias_hh_l1.3, %weight_ih_l2.3, %weight_hh_l2.3, %bias_ih_l2.3, %bias_hh_l2.3), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^\n\t\t-   %output.1 : Tensor, %decoder_hidden.3 : Tensor = aten::gru(%input.13, %29, %378, %329, %330, %331, %336, %336, %329), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                - ^^^^^^^^^^^     ^^^^^^^     ^     ^\n\t\t+   %output.1 : Tensor, %decoder_hidden.3 : Tensor = aten::gru(%input.13, %29, %388, %339, %340, %341, %346, %346, %339), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                 ^^^^^^^^^^^^     ^^^^^^^     ^     ^\n\t\t-   %381 : (Tensor, Tensor) = prim::TupleConstruct(%output.1, %decoder_hidden.3)\n\t\t?     ^\n\t\t+   %391 : (Tensor, Tensor) = prim::TupleConstruct(%output.1, %decoder_hidden.3)\n\t\t?     ^\n\t\t-   %382 : Tensor, %383 : Tensor = prim::TupleUnpack(%381)\n\t\t?     ^              ^                                 ^\n\t\t+   %392 : Tensor, %393 : Tensor = prim::TupleUnpack(%391)\n\t\t?     ^              ^                                 ^\n\t\t-   %384 : Tensor = aten::squeeze(%382, %337), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %394 : Tensor = aten::squeeze(%392, %347), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %385 : Tensor = aten::squeeze(%context.1, %337), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t+   %395 : Tensor = aten::squeeze(%context.1, %347), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t-   %386 : Tensor = aten::squeeze(%embedded.1, %337), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %396 : Tensor = aten::squeeze(%embedded.1, %347), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %387 : Tensor[] = prim::ListConstruct(%384, %385, %386), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %397 : Tensor[] = prim::ListConstruct(%394, %395, %396), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.15 : Tensor = aten::cat(%387, %337), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.15 : Tensor = aten::cat(%397, %347), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.7 : Tensor = prim::GetAttr[name=\"bias\"](%fc.1)\n\t\t    %weight.15 : Tensor = prim::GetAttr[name=\"weight\"](%fc.1)\n\t\t    %output.3 : Tensor = aten::linear(%input.15, %weight.15, %bias.7), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %392 : (Tensor, Tensor) = prim::TupleConstruct(%output.3, %383)\n\t\t?    ^^                                                         ^\n\t\t+   %402 : (Tensor, Tensor) = prim::TupleConstruct(%output.3, %393)\n\t\t?    ^^                                                         ^\n\t\t-   %40 : Tensor, %41 : Tensor = prim::TupleUnpack(%392)\n\t\t?                                                   ^^\n\t\t+   %40 : Tensor, %41 : Tensor = prim::TupleUnpack(%402)\n\t\t?                                                   ^^\n\t\t    %42 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %43 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %44 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %45 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %46 : Tensor = aten::slice(%outputs, %42, %43, %44, %45) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %47 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %48 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %49 : Tensor = aten::select(%46, %47, %48) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %50 : bool = prim::Constant[value=0]()\n\t\t    %51 : Tensor = aten::copy_(%49, %40, %50) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %52 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %53 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %54 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %55 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %56 : Tensor = aten::slice(%trg, %52, %53, %54, %55) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %57 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %58 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t    %input_token.3 : Tensor = aten::select(%56, %57, %58) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %393 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     --\n\t\t+   %403 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    ++\n\t\t-   %394 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    --\n\t\t+   %404 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ++\n\t\t-   %395 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    ^^\n\t\t+   %405 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    ^^\n\t\t-   %396 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?    ^^\n\t\t+   %406 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?    ^^\n\t\t-   %397 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?    ^^\n\t\t+   %407 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?    ^^\n\t\t-   %398 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?    ^^\n\t\t+   %408 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?    ^^\n\t\t-   %399 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^ -\n\t\t+   %409 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^^\n\t\t-   %400 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      -\n\t\t+   %410 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     +\n\t\t-   %401 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     -\n\t\t+   %411 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      +\n\t\t    %fc.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.5 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.3 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.5 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.17 : Tensor = aten::unsqueeze(%input_token.3, %401), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t+   %input.17 : Tensor = aten::unsqueeze(%input_token.3, %411), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t    %weight.17 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.5)\n\t\t-   %embedded.3 : Tensor = aten::embedding(%weight.17, %input.17, %399, %400, %400), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                 ------        ^\n\t\t+   %embedded.3 : Tensor = aten::embedding(%weight.17, %input.17, %409, %410, %410), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ++++++     ^\n\t\t    %V.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.3)\n\t\t    %W2.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.3)\n\t\t    %W1.3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.3)\n\t\t-   %412 : Tensor = aten::select(%41, %396, %399), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     -                                ^^    ^^\n\t\t+   %422 : Tensor = aten::select(%41, %406, %409), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      +                               ^^    ^^\n\t\t-   %input.19 : Tensor = aten::unsqueeze(%412, %401), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t+   %input.19 : Tensor = aten::unsqueeze(%422, %411), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t    %bias.9 : Tensor = prim::GetAttr[name=\"bias\"](%W1.3)\n\t\t    %weight.19 : Tensor = prim::GetAttr[name=\"weight\"](%W1.3)\n\t\t-   %416 : Tensor = aten::linear(%30, %weight.19, %bias.9), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %426 : Tensor = aten::linear(%30, %weight.19, %bias.9), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.11 : Tensor = prim::GetAttr[name=\"bias\"](%W2.3)\n\t\t    %weight.21 : Tensor = prim::GetAttr[name=\"weight\"](%W2.3)\n\t\t-   %419 : Tensor = aten::linear(%input.19, %weight.21, %bias.11), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %429 : Tensor = aten::linear(%input.19, %weight.21, %bias.11), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t-   %420 : Tensor = aten::add(%416, %419, %401), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^      ------\n\t\t+   %430 : Tensor = aten::add(%426, %429, %411), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^  ++++++\n\t\t-   %input.21 : Tensor = aten::tanh(%420), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.21 : Tensor = aten::tanh(%430), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.13 : Tensor = prim::GetAttr[name=\"bias\"](%V.3)\n\t\t    %weight.23 : Tensor = prim::GetAttr[name=\"weight\"](%V.3)\n\t\t    %input.23 : Tensor = aten::linear(%input.21, %weight.23, %bias.13), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %425 : Tensor = aten::softmax(%input.23, %401, %397), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                         ------\n\t\t+   %435 : Tensor = aten::softmax(%input.23, %411, %407), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                      ++++++\n\t\t-   %attention_weights.3 : Tensor = aten::transpose(%425, %401, %398), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^      ------\n\t\t+   %attention_weights.3 : Tensor = aten::transpose(%435, %411, %408), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^  ++++++\n\t\t    %context.3 : Tensor = aten::bmm(%attention_weights.3, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %428 : Tensor[] = prim::ListConstruct(%embedded.3, %context.3), scope: __module.decoder\n\t\t?     ^\n\t\t+   %438 : Tensor[] = prim::ListConstruct(%embedded.3, %context.3), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.25 : Tensor = aten::cat(%428, %398), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^    ^^\n\t\t+   %input.25 : Tensor = aten::cat(%438, %408), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^    ^^\n\t\t    %bias_hh_l2.5 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.5)\n\t\t    %bias_ih_l2.5 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.5)\n\t\t    %weight_hh_l2.5 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.5)\n\t\t    %weight_ih_l2.5 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.5)\n\t\t    %bias_hh_l1.5 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.5)\n\t\t    %bias_ih_l1.5 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.5)\n\t\t    %weight_hh_l1.5 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.5)\n\t\t    %weight_ih_l1.5 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.5)\n\t\t    %bias_hh_l0.5 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.5)\n\t\t    %bias_ih_l0.5 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.5)\n\t\t    %weight_hh_l0.5 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.5)\n\t\t    %weight_ih_l0.5 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.5)\n\t\t-   %442 : Tensor[] = prim::ListConstruct(%weight_ih_l0.5, %weight_hh_l0.5, %bias_ih_l0.5, %bias_hh_l0.5, %weight_ih_l1.5, %weight_hh_l1.5, %bias_ih_l1.5, %bias_hh_l1.5, %weight_ih_l2.5, %weight_hh_l2.5, %bias_ih_l2.5, %bias_hh_l2.5), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t+   %452 : Tensor[] = prim::ListConstruct(%weight_ih_l0.5, %weight_hh_l0.5, %bias_ih_l0.5, %bias_hh_l0.5, %weight_ih_l1.5, %weight_hh_l1.5, %bias_ih_l1.5, %bias_hh_l1.5, %weight_ih_l2.5, %weight_hh_l2.5, %bias_ih_l2.5, %bias_hh_l2.5), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t-   %output.5 : Tensor, %decoder_hidden.5 : Tensor = aten::gru(%input.25, %41, %442, %393, %394, %395, %400, %400, %393), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                ^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.5 : Tensor, %decoder_hidden.5 : Tensor = aten::gru(%input.25, %41, %452, %403, %404, %405, %410, %410, %403), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                ^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %445 : (Tensor, Tensor) = prim::TupleConstruct(%output.5, %decoder_hidden.5)\n\t\t?     -\n\t\t+   %455 : (Tensor, Tensor) = prim::TupleConstruct(%output.5, %decoder_hidden.5)\n\t\t?      +\n\t\t-   %446 : Tensor, %447 : Tensor = prim::TupleUnpack(%445)\n\t\t?     ^              ^                                 ^\n\t\t+   %456 : Tensor, %457 : Tensor = prim::TupleUnpack(%455)\n\t\t?     ^              ^                                 ^\n\t\t-   %448 : Tensor = aten::squeeze(%446, %401), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %458 : Tensor = aten::squeeze(%456, %411), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %449 : Tensor = aten::squeeze(%context.3, %401), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t+   %459 : Tensor = aten::squeeze(%context.3, %411), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t-   %450 : Tensor = aten::squeeze(%embedded.3, %401), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %460 : Tensor = aten::squeeze(%embedded.3, %411), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %451 : Tensor[] = prim::ListConstruct(%448, %449, %450), scope: __module.decoder\n\t\t?     ^                                     ^  ------\n\t\t+   %461 : Tensor[] = prim::ListConstruct(%458, %459, %460), scope: __module.decoder\n\t\t?     ^                                     ^      ++++++\n\t\t-   %input.27 : Tensor = aten::cat(%451, %401), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.27 : Tensor = aten::cat(%461, %411), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.15 : Tensor = prim::GetAttr[name=\"bias\"](%fc.3)\n\t\t    %weight.25 : Tensor = prim::GetAttr[name=\"weight\"](%fc.3)\n\t\t    %output.7 : Tensor = aten::linear(%input.27, %weight.25, %bias.15), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %456 : (Tensor, Tensor) = prim::TupleConstruct(%output.7, %447)\n\t\t?     -                                                         ^\n\t\t+   %466 : (Tensor, Tensor) = prim::TupleConstruct(%output.7, %457)\n\t\t?      +                                                        ^\n\t\t-   %61 : Tensor, %62 : Tensor = prim::TupleUnpack(%456)\n\t\t?                                                    ^\n\t\t+   %61 : Tensor, %62 : Tensor = prim::TupleUnpack(%466)\n\t\t?                                                    ^\n\t\t    %63 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %64 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %65 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %66 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %67 : Tensor = aten::slice(%outputs, %63, %64, %65, %66) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %68 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %69 : int = prim::Constant[value=2]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %70 : Tensor = aten::select(%67, %68, %69) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t    %71 : bool = prim::Constant[value=0]()\n\t\t    %72 : Tensor = aten::copy_(%70, %61, %71) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %73 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                    ^                                                                       ^\n\t\t+   %73 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                    ^                                                                       ^\n\t\t-   %74 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?         ^^^^                                                                                                ^\n\t\t+   %74 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?         ^^^                                                                                                ^\n\t\t+   %75 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %76 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %77 : Tensor = aten::slice(%trg, %73, %74, %75, %76) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %78 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %79 : int = prim::Constant[value=2]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %input_token.5 : Tensor = aten::argmax(%61, %73, %74) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                   ^^^^^^  ^^    ^    ^                                                                     ^\n\t\t+   %input_token.5 : Tensor = aten::select(%77, %78, %79) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                   ^^^^^^  ^^    ^    ^                                                                     ^\n\t\t-   %457 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %467 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %458 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %468 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %459 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %469 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %460 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %470 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %461 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %471 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %462 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %472 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %463 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %473 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %464 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %474 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %465 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %475 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.7 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.5 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.7 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.29 : Tensor = aten::unsqueeze(%input_token.5, %465), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t+   %input.29 : Tensor = aten::unsqueeze(%input_token.5, %475), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t    %weight.27 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.7)\n\t\t-   %embedded.5 : Tensor = aten::embedding(%weight.27, %input.29, %463, %464, %464), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                   ^     ^     ^\n\t\t+   %embedded.5 : Tensor = aten::embedding(%weight.27, %input.29, %473, %474, %474), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                   ^     ^     ^\n\t\t    %V.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.5)\n\t\t    %W2.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.5)\n\t\t    %W1.5 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.5)\n\t\t-   %476 : Tensor = aten::select(%62, %460, %463), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                                 ^     ^\n\t\t+   %486 : Tensor = aten::select(%62, %470, %473), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                                 ^     ^\n\t\t-   %input.31 : Tensor = aten::unsqueeze(%476, %465), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t+   %input.31 : Tensor = aten::unsqueeze(%486, %475), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t    %bias.17 : Tensor = prim::GetAttr[name=\"bias\"](%W1.5)\n\t\t    %weight.29 : Tensor = prim::GetAttr[name=\"weight\"](%W1.5)\n\t\t-   %480 : Tensor = aten::linear(%30, %weight.29, %bias.17), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t+   %490 : Tensor = aten::linear(%30, %weight.29, %bias.17), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t    %bias.19 : Tensor = prim::GetAttr[name=\"bias\"](%W2.5)\n\t\t    %weight.31 : Tensor = prim::GetAttr[name=\"weight\"](%W2.5)\n\t\t-   %483 : Tensor = aten::linear(%input.31, %weight.31, %bias.19), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t+   %493 : Tensor = aten::linear(%input.31, %weight.31, %bias.19), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t-   %484 : Tensor = aten::add(%480, %483, %465), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %494 : Tensor = aten::add(%490, %493, %475), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.33 : Tensor = aten::tanh(%484), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.33 : Tensor = aten::tanh(%494), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.21 : Tensor = prim::GetAttr[name=\"bias\"](%V.5)\n\t\t    %weight.33 : Tensor = prim::GetAttr[name=\"weight\"](%V.5)\n\t\t    %input.35 : Tensor = aten::linear(%input.33, %weight.33, %bias.21), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %489 : Tensor = aten::softmax(%input.35, %465, %461), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     -                                        ^     ^\n\t\t+   %499 : Tensor = aten::softmax(%input.35, %475, %471), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      +                                       ^     ^\n\t\t-   %attention_weights.5 : Tensor = aten::transpose(%489, %465, %462), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^     ^     ^\n\t\t+   %attention_weights.5 : Tensor = aten::transpose(%499, %475, %472), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^     ^     ^\n\t\t    %context.5 : Tensor = aten::bmm(%attention_weights.5, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %492 : Tensor[] = prim::ListConstruct(%embedded.5, %context.5), scope: __module.decoder\n\t\t?    ^^\n\t\t+   %502 : Tensor[] = prim::ListConstruct(%embedded.5, %context.5), scope: __module.decoder\n\t\t?    ^^\n\t\t-   %input.37 : Tensor = aten::cat(%492, %462), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                   ^^     ^\n\t\t+   %input.37 : Tensor = aten::cat(%502, %472), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                   ^^     ^\n\t\t    %bias_hh_l2.7 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.7)\n\t\t    %bias_ih_l2.7 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.7)\n\t\t    %weight_hh_l2.7 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.7)\n\t\t    %weight_ih_l2.7 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.7)\n\t\t    %bias_hh_l1.7 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.7)\n\t\t    %bias_ih_l1.7 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.7)\n\t\t    %weight_hh_l1.7 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.7)\n\t\t    %weight_ih_l1.7 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.7)\n\t\t    %bias_hh_l0.7 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.7)\n\t\t    %bias_ih_l0.7 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.7)\n\t\t    %weight_hh_l0.7 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.7)\n\t\t    %weight_ih_l0.7 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.7)\n\t\t-   %506 : Tensor[] = prim::ListConstruct(%weight_ih_l0.7, %weight_hh_l0.7, %bias_ih_l0.7, %bias_hh_l0.7, %weight_ih_l1.7, %weight_hh_l1.7, %bias_ih_l1.7, %bias_hh_l1.7, %weight_ih_l2.7, %weight_hh_l2.7, %bias_ih_l2.7, %bias_hh_l2.7), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t+   %516 : Tensor[] = prim::ListConstruct(%weight_ih_l0.7, %weight_hh_l0.7, %bias_ih_l0.7, %bias_hh_l0.7, %weight_ih_l1.7, %weight_hh_l1.7, %bias_ih_l1.7, %bias_hh_l1.7, %weight_ih_l2.7, %weight_hh_l2.7, %bias_ih_l2.7, %bias_hh_l2.7), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t-   %output.9 : Tensor, %decoder_hidden.7 : Tensor = aten::gru(%input.37, %62, %506, %457, %458, %459, %464, %464, %457), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                ^^^^^^^^^^^^^     ^     ^^^^^^^^^^^^^\n\t\t+   %output.9 : Tensor, %decoder_hidden.7 : Tensor = aten::gru(%input.37, %62, %516, %467, %468, %469, %474, %474, %467), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                                ^^^^^^^^^^^^^     ^     ^^^^^^^^^^^^^\n\t\t-   %509 : (Tensor, Tensor) = prim::TupleConstruct(%output.9, %decoder_hidden.7)\n\t\t?     ^\n\t\t+   %519 : (Tensor, Tensor) = prim::TupleConstruct(%output.9, %decoder_hidden.7)\n\t\t?     ^\n\t\t-   %510 : Tensor, %511 : Tensor = prim::TupleUnpack(%509)\n\t\t?     ^               -                                ^\n\t\t+   %520 : Tensor, %521 : Tensor = prim::TupleUnpack(%519)\n\t\t?     ^              +                                 ^\n\t\t-   %512 : Tensor = aten::squeeze(%510, %465), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     -                             ^     ^\n\t\t+   %522 : Tensor = aten::squeeze(%520, %475), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      +                            ^     ^\n\t\t-   %513 : Tensor = aten::squeeze(%context.5, %465), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t+   %523 : Tensor = aten::squeeze(%context.5, %475), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^\n\t\t-   %514 : Tensor = aten::squeeze(%embedded.5, %465), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %524 : Tensor = aten::squeeze(%embedded.5, %475), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %515 : Tensor[] = prim::ListConstruct(%512, %513, %514), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %525 : Tensor[] = prim::ListConstruct(%522, %523, %524), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.39 : Tensor = aten::cat(%515, %465), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.39 : Tensor = aten::cat(%525, %475), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.23 : Tensor = prim::GetAttr[name=\"bias\"](%fc.5)\n\t\t    %weight.35 : Tensor = prim::GetAttr[name=\"weight\"](%fc.5)\n\t\t    %output.11 : Tensor = aten::linear(%input.39, %weight.35, %bias.23), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %520 : (Tensor, Tensor) = prim::TupleConstruct(%output.11, %511)\n\t\t?     ^                                                          ^\n\t\t+   %530 : (Tensor, Tensor) = prim::TupleConstruct(%output.11, %521)\n\t\t?     ^                                                          ^\n\t\t-   %77 : Tensor, %78 : Tensor = prim::TupleUnpack(%520)\n\t\t?    ^^            -                                 ^\n\t\t+   %82 : Tensor, %83 : Tensor = prim::TupleUnpack(%530)\n\t\t?    ^^             +                                ^\n\t\t-   %79 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %80 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %84 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %85 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %81 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %86 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %82 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %87 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %83 : Tensor = aten::slice(%outputs, %79, %80, %81, %82) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                  -----  ^    ^    ^\n\t\t+   %88 : Tensor = aten::slice(%outputs, %84, %85, %86, %87) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                    ^    ^    ^^^^^^\n\t\t-   %84 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %89 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %85 : int = prim::Constant[value=3]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^\n\t\t+   %90 : int = prim::Constant[value=3]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^\n\t\t-   %86 : Tensor = aten::select(%83, %84, %85) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                           ^    ^   ^^\n\t\t+   %91 : Tensor = aten::select(%88, %89, %90) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                           ^    ^   ^^\n\t\t-   %87 : bool = prim::Constant[value=0]()\n\t\t?    ^^\n\t\t+   %92 : bool = prim::Constant[value=0]()\n\t\t?    ^^\n\t\t-   %88 : Tensor = aten::copy_(%86, %77, %87) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                         ^^ -----   ^\n\t\t+   %93 : Tensor = aten::copy_(%91, %82, %92) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                         ^^    ^^^^^^\n\t\t-   %89 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?    -\n\t\t+   %94 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     +\n\t\t-   %90 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^\n\t\t+   %95 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^\n\t\t-   %input_token.7 : Tensor = aten::argmax(%77, %89, %90) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                           ^^ -----   ^\n\t\t+   %input_token.7 : Tensor = aten::argmax(%82, %94, %95) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                           ^^    ^^^^^^\n\t\t-   %521 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %531 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %522 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %532 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     +\n\t\t-   %523 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     -\n\t\t+   %533 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      +\n\t\t-   %524 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %534 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %525 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %535 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %526 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %536 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %527 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %537 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %528 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %538 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %529 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %539 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.9 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.7 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.9 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.41 : Tensor = aten::unsqueeze(%input_token.7, %529), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t+   %input.41 : Tensor = aten::unsqueeze(%input_token.7, %539), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t    %weight.37 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.9)\n\t\t-   %embedded.7 : Tensor = aten::embedding(%weight.37, %input.41, %527, %528, %528), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                   ^     ^     ^\n\t\t+   %embedded.7 : Tensor = aten::embedding(%weight.37, %input.41, %537, %538, %538), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                   ^     ^     ^\n\t\t    %V.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.7)\n\t\t    %W2.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.7)\n\t\t    %W1.7 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.7)\n\t\t-   %540 : Tensor = aten::select(%78, %524, %527), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                           -     ^     ^\n\t\t+   %550 : Tensor = aten::select(%83, %534, %537), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            +    ^     ^\n\t\t-   %input.43 : Tensor = aten::unsqueeze(%540, %529), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t+   %input.43 : Tensor = aten::unsqueeze(%550, %539), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t    %bias.25 : Tensor = prim::GetAttr[name=\"bias\"](%W1.7)\n\t\t    %weight.39 : Tensor = prim::GetAttr[name=\"weight\"](%W1.7)\n\t\t-   %544 : Tensor = aten::linear(%30, %weight.39, %bias.25), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^\n\t\t+   %554 : Tensor = aten::linear(%30, %weight.39, %bias.25), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?    +  ^^\n\t\t    %bias.27 : Tensor = prim::GetAttr[name=\"bias\"](%W2.7)\n\t\t    %weight.41 : Tensor = prim::GetAttr[name=\"weight\"](%W2.7)\n\t\t-   %547 : Tensor = aten::linear(%input.43, %weight.41, %bias.27), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %557 : Tensor = aten::linear(%input.43, %weight.41, %bias.27), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t-   %548 : Tensor = aten::add(%544, %547, %529), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %558 : Tensor = aten::add(%554, %557, %539), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.45 : Tensor = aten::tanh(%548), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.45 : Tensor = aten::tanh(%558), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.29 : Tensor = prim::GetAttr[name=\"bias\"](%V.7)\n\t\t    %weight.43 : Tensor = prim::GetAttr[name=\"weight\"](%V.7)\n\t\t    %input.47 : Tensor = aten::linear(%input.45, %weight.43, %bias.29), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %553 : Tensor = aten::softmax(%input.47, %529, %525), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t+   %563 : Tensor = aten::softmax(%input.47, %539, %535), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t-   %attention_weights.7 : Tensor = aten::transpose(%553, %529, %526), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                           ^^^^^^^\n\t\t+   %attention_weights.7 : Tensor = aten::transpose(%563, %539, %536), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     +++++  +    ^\n\t\t    %context.7 : Tensor = aten::bmm(%attention_weights.7, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %556 : Tensor[] = prim::ListConstruct(%embedded.7, %context.7), scope: __module.decoder\n\t\t?     -\n\t\t+   %566 : Tensor[] = prim::ListConstruct(%embedded.7, %context.7), scope: __module.decoder\n\t\t?      +\n\t\t-   %input.49 : Tensor = aten::cat(%556, %526), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t+   %input.49 : Tensor = aten::cat(%566, %536), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t    %bias_hh_l2.9 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.9)\n\t\t    %bias_ih_l2.9 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.9)\n\t\t    %weight_hh_l2.9 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.9)\n\t\t    %weight_ih_l2.9 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.9)\n\t\t    %bias_hh_l1.9 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.9)\n\t\t    %bias_ih_l1.9 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.9)\n\t\t    %weight_hh_l1.9 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.9)\n\t\t    %weight_ih_l1.9 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.9)\n\t\t    %bias_hh_l0.9 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.9)\n\t\t    %bias_ih_l0.9 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.9)\n\t\t    %weight_hh_l0.9 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.9)\n\t\t    %weight_ih_l0.9 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.9)\n\t\t-   %570 : Tensor[] = prim::ListConstruct(%weight_ih_l0.9, %weight_hh_l0.9, %bias_ih_l0.9, %bias_hh_l0.9, %weight_ih_l1.9, %weight_hh_l1.9, %bias_ih_l1.9, %bias_hh_l1.9, %weight_ih_l2.9, %weight_hh_l2.9, %bias_ih_l2.9, %bias_hh_l2.9), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t+   %580 : Tensor[] = prim::ListConstruct(%weight_ih_l0.9, %weight_hh_l0.9, %bias_ih_l0.9, %bias_hh_l0.9, %weight_ih_l1.9, %weight_hh_l1.9, %bias_ih_l1.9, %bias_hh_l1.9, %weight_ih_l2.9, %weight_hh_l2.9, %bias_ih_l2.9, %bias_hh_l2.9), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t-   %output.13 : Tensor, %decoder_hidden.9 : Tensor = aten::gru(%input.49, %78, %570, %521, %522, %523, %528, %528, %521), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                           ^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.13 : Tensor, %decoder_hidden.9 : Tensor = aten::gru(%input.49, %83, %580, %531, %532, %533, %538, %538, %531), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                           ^^^^^^^     +++++++ ^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %573 : (Tensor, Tensor) = prim::TupleConstruct(%output.13, %decoder_hidden.9)\n\t\t?     ^\n\t\t+   %583 : (Tensor, Tensor) = prim::TupleConstruct(%output.13, %decoder_hidden.9)\n\t\t?     ^\n\t\t-   %574 : Tensor, %575 : Tensor = prim::TupleUnpack(%573)\n\t\t?     ^              ^                                 ^\n\t\t+   %584 : Tensor, %585 : Tensor = prim::TupleUnpack(%583)\n\t\t?     ^              ^                                 ^\n\t\t-   %576 : Tensor = aten::squeeze(%574, %529), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %586 : Tensor = aten::squeeze(%584, %539), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %577 : Tensor = aten::squeeze(%context.7, %529), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      -                                        ^\n\t\t+   %587 : Tensor = aten::squeeze(%context.7, %539), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     +                                         ^\n\t\t-   %578 : Tensor = aten::squeeze(%embedded.7, %529), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     -                                          ^\n\t\t+   %588 : Tensor = aten::squeeze(%embedded.7, %539), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      +                                         ^\n\t\t-   %579 : Tensor[] = prim::ListConstruct(%576, %577, %578), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %589 : Tensor[] = prim::ListConstruct(%586, %587, %588), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.51 : Tensor = aten::cat(%579, %529), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.51 : Tensor = aten::cat(%589, %539), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.31 : Tensor = prim::GetAttr[name=\"bias\"](%fc.7)\n\t\t    %weight.45 : Tensor = prim::GetAttr[name=\"weight\"](%fc.7)\n\t\t    %output.15 : Tensor = aten::linear(%input.51, %weight.45, %bias.31), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %584 : (Tensor, Tensor) = prim::TupleConstruct(%output.15, %575)\n\t\t?     ^                                                          ^\n\t\t+   %594 : (Tensor, Tensor) = prim::TupleConstruct(%output.15, %585)\n\t\t?     ^                                                          ^\n\t\t-   %93 : Tensor, %94 : Tensor = prim::TupleUnpack(%584)\n\t\t?     ^             ^                                ^\n\t\t+   %98 : Tensor, %99 : Tensor = prim::TupleUnpack(%594)\n\t\t?     ^             ^                                ^\n\t\t-   %95 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %96 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %97 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %98 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %99 : Tensor = aten::slice(%outputs, %95, %96, %97, %98) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %100 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                     ^\n\t\t+   %100 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                     ^\n\t\t-   %101 : int = prim::Constant[value=4]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                     ^\n\t\t+   %101 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                     ^\n\t\t+   %102 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %103 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %102 : Tensor = aten::select(%99, %100, %101) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^                    ----  ^^\n\t\t+   %104 : Tensor = aten::slice(%outputs, %100, %101, %102, %103) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^                   +++   ^^^^^^^            ++++++++++++\n\t\t-   %103 : bool = prim::Constant[value=0]()\n\t\t-   %104 : Tensor = aten::copy_(%102, %93, %103) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %105 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                                                                                             ^\n\t\t+   %105 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                                                                                             ^\n\t\t-   %106 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?          ^^^^                        ^                                                                       ^\n\t\t+   %106 : int = prim::Constant[value=4]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?          ^^^                        ^                                                                       ^\n\t\t+   %107 : Tensor = aten::select(%104, %105, %106) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %108 : bool = prim::Constant[value=0]()\n\t\t+   %109 : Tensor = aten::copy_(%107, %98, %108) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %110 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %111 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %112 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %113 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %114 : Tensor = aten::slice(%trg, %110, %111, %112, %113) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %115 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %116 : int = prim::Constant[value=4]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %input_token.9 : Tensor = aten::argmax(%93, %105, %106) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                   ^^^^^^  ^^    ^     ^                                                                      ^\n\t\t+   %input_token.9 : Tensor = aten::select(%114, %115, %116) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                   ^^^^^^  ^^^    ^     ^                                                                      ^\n\t\t-   %585 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %595 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %586 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %596 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %587 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %597 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %588 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      -\n\t\t+   %598 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     +\n\t\t-   %589 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     -\n\t\t+   %599 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      +\n\t\t-   %590 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?    ^^\n\t\t+   %600 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?    ^ +\n\t\t-   %591 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^^\n\t\t+   %601 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^^\n\t\t-   %592 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^^\n\t\t+   %602 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?    ^^\n\t\t-   %593 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?    ^^\n\t\t+   %603 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?    ^^\n\t\t    %fc.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.11 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.9 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.11 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.53 : Tensor = aten::unsqueeze(%input_token.9, %593), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                         ^^\n\t\t+   %input.53 : Tensor = aten::unsqueeze(%input_token.9, %603), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                         ^^\n\t\t    %weight.47 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.11)\n\t\t-   %embedded.9 : Tensor = aten::embedding(%weight.47, %input.53, %591, %592, %592), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                  ^^    ^^    ^^\n\t\t+   %embedded.9 : Tensor = aten::embedding(%weight.47, %input.53, %601, %602, %602), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                  ^^    ^^    ^^\n\t\t    %V.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.9)\n\t\t    %W2.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.9)\n\t\t    %W1.9 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.9)\n\t\t-   %604 : Tensor = aten::select(%94, %588, %591), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^ ------\n\t\t+   %614 : Tensor = aten::select(%99, %598, %601), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^     ++++++\n\t\t-   %input.55 : Tensor = aten::unsqueeze(%604, %593), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^    ^^\n\t\t+   %input.55 : Tensor = aten::unsqueeze(%614, %603), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^    ^^\n\t\t    %bias.33 : Tensor = prim::GetAttr[name=\"bias\"](%W1.9)\n\t\t    %weight.49 : Tensor = prim::GetAttr[name=\"weight\"](%W1.9)\n\t\t-   %608 : Tensor = aten::linear(%30, %weight.49, %bias.33), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %618 : Tensor = aten::linear(%30, %weight.49, %bias.33), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.35 : Tensor = prim::GetAttr[name=\"bias\"](%W2.9)\n\t\t    %weight.51 : Tensor = prim::GetAttr[name=\"weight\"](%W2.9)\n\t\t-   %611 : Tensor = aten::linear(%input.55, %weight.51, %bias.35), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t+   %621 : Tensor = aten::linear(%input.55, %weight.51, %bias.35), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t-   %612 : Tensor = aten::add(%608, %611, %593), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     -                         ^     ^    ^^\n\t\t+   %622 : Tensor = aten::add(%618, %621, %603), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      +                        ^     ^    ^^\n\t\t-   %input.57 : Tensor = aten::tanh(%612), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.57 : Tensor = aten::tanh(%622), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.37 : Tensor = prim::GetAttr[name=\"bias\"](%V.9)\n\t\t    %weight.53 : Tensor = prim::GetAttr[name=\"weight\"](%V.9)\n\t\t    %input.59 : Tensor = aten::linear(%input.57, %weight.53, %bias.37), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %617 : Tensor = aten::softmax(%input.59, %593, %589), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                         ------\n\t\t+   %627 : Tensor = aten::softmax(%input.59, %603, %599), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                      ++++++\n\t\t-   %attention_weights.9 : Tensor = aten::transpose(%617, %593, %590), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^    ^^    ^^\n\t\t+   %attention_weights.9 : Tensor = aten::transpose(%627, %603, %600), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                     ^    ^^    ^^\n\t\t    %context.9 : Tensor = aten::bmm(%attention_weights.9, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %620 : Tensor[] = prim::ListConstruct(%embedded.9, %context.9), scope: __module.decoder\n\t\t?     ^\n\t\t+   %630 : Tensor[] = prim::ListConstruct(%embedded.9, %context.9), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.61 : Tensor = aten::cat(%620, %590), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^    ^^\n\t\t+   %input.61 : Tensor = aten::cat(%630, %600), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^    ^^\n\t\t    %bias_hh_l2.11 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.11)\n\t\t    %bias_ih_l2.11 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.11)\n\t\t    %weight_hh_l2.11 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.11)\n\t\t    %weight_ih_l2.11 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.11)\n\t\t    %bias_hh_l1.11 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.11)\n\t\t    %bias_ih_l1.11 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.11)\n\t\t    %weight_hh_l1.11 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.11)\n\t\t    %weight_ih_l1.11 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.11)\n\t\t    %bias_hh_l0.11 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.11)\n\t\t    %bias_ih_l0.11 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.11)\n\t\t    %weight_hh_l0.11 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.11)\n\t\t    %weight_ih_l0.11 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.11)\n\t\t-   %634 : Tensor[] = prim::ListConstruct(%weight_ih_l0.11, %weight_hh_l0.11, %bias_ih_l0.11, %bias_hh_l0.11, %weight_ih_l1.11, %weight_hh_l1.11, %bias_ih_l1.11, %bias_hh_l1.11, %weight_ih_l2.11, %weight_hh_l2.11, %bias_ih_l2.11, %bias_hh_l2.11), scope: __module.decoder/__module.decoder.rnn\n\t\t?     - ^^\n\t\t+   %644 : Tensor[] = prim::ListConstruct(%weight_ih_l0.11, %weight_hh_l0.11, %bias_ih_l0.11, %bias_hh_l0.11, %weight_ih_l1.11, %weight_hh_l1.11, %bias_ih_l1.11, %bias_hh_l1.11, %weight_ih_l2.11, %weight_hh_l2.11, %bias_ih_l2.11, %bias_hh_l2.11), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^\n\t\t-   %output.17 : Tensor, %decoder_hidden.11 : Tensor = aten::gru(%input.61, %94, %634, %585, %586, %587, %592, %592, %585), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              -----     ^^^^^^^^^^^^^    ^^    ^^     ^\n\t\t+   %output.17 : Tensor, %decoder_hidden.11 : Tensor = aten::gru(%input.61, %99, %644, %595, %596, %597, %602, %602, %595), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                             +++++      ^^^^^^^^^^^^^    ^^    ^^     ^\n\t\t-   %637 : (Tensor, Tensor) = prim::TupleConstruct(%output.17, %decoder_hidden.11)\n\t\t?     ^\n\t\t+   %647 : (Tensor, Tensor) = prim::TupleConstruct(%output.17, %decoder_hidden.11)\n\t\t?     ^\n\t\t-   %638 : Tensor, %639 : Tensor = prim::TupleUnpack(%637)\n\t\t?     ^              ^                                 ^\n\t\t+   %648 : Tensor, %649 : Tensor = prim::TupleUnpack(%647)\n\t\t?     ^              ^                                 ^\n\t\t-   %640 : Tensor = aten::squeeze(%638, %593), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^    ^^\n\t\t+   %650 : Tensor = aten::squeeze(%648, %603), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^    ^^\n\t\t-   %641 : Tensor = aten::squeeze(%context.9, %593), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                        ^^\n\t\t+   %651 : Tensor = aten::squeeze(%context.9, %603), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                        ^^\n\t\t-   %642 : Tensor = aten::squeeze(%embedded.9, %593), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^^\n\t\t+   %652 : Tensor = aten::squeeze(%embedded.9, %603), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                         ^^\n\t\t-   %643 : Tensor[] = prim::ListConstruct(%640, %641, %642), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %653 : Tensor[] = prim::ListConstruct(%650, %651, %652), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.63 : Tensor = aten::cat(%643, %593), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^    ^^\n\t\t+   %input.63 : Tensor = aten::cat(%653, %603), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^    ^^\n\t\t    %bias.39 : Tensor = prim::GetAttr[name=\"bias\"](%fc.9)\n\t\t    %weight.55 : Tensor = prim::GetAttr[name=\"weight\"](%fc.9)\n\t\t    %output.19 : Tensor = aten::linear(%input.63, %weight.55, %bias.39), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %648 : (Tensor, Tensor) = prim::TupleConstruct(%output.19, %639)\n\t\t?     ^                                                          ^\n\t\t+   %658 : (Tensor, Tensor) = prim::TupleConstruct(%output.19, %649)\n\t\t?     ^                                                          ^\n\t\t-   %109 : Tensor, %110 : Tensor = prim::TupleUnpack(%648)\n\t\t?     ^              ^                                 ^\n\t\t+   %119 : Tensor, %120 : Tensor = prim::TupleUnpack(%658)\n\t\t?     ^              ^                                 ^\n\t\t-   %111 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -\n\t\t+   %121 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +\n\t\t-   %112 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %122 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %113 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %123 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %114 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %124 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %115 : Tensor = aten::slice(%outputs, %111, %112, %113, %114) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^           ^^^^^^^\n\t\t+   %125 : Tensor = aten::slice(%outputs, %121, %122, %123, %124) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     +++++  +    ^\n\t\t-   %116 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %126 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %117 : int = prim::Constant[value=5]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %127 : int = prim::Constant[value=5]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %118 : Tensor = aten::select(%115, %116, %117) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t+   %128 : Tensor = aten::select(%125, %126, %127) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t-   %119 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t+   %129 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t-   %120 : Tensor = aten::copy_(%118, %109, %119) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^  ------\n\t\t+   %130 : Tensor = aten::copy_(%128, %119, %129) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^       ++++++\n\t\t-   %121 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                               ^                                                                       ^\n\t\t+   %131 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^                               ^                                                                       ^\n\t\t-   %122 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      -   ^^^                                                                                                ^\n\t\t+   %132 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     +    ^^^^                                                                                                ^\n\t\t-   %123 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %124 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %125 : Tensor = aten::slice(%trg, %121, %122, %123, %124) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %126 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %127 : int = prim::Constant[value=5]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %input_token.11 : Tensor = aten::select(%125, %126, %127) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                    ^^^^^^   ^^    ^^     -                                                                     ^\n\t\t+   %input_token.11 : Tensor = aten::argmax(%119, %131, %132) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                    ^^^^^^   ^^    ^^    +                                                                      ^\n\t\t-   %649 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %659 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %650 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %660 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %651 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %661 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %652 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %662 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %653 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %663 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %654 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %664 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %655 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      -\n\t\t+   %665 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     +\n\t\t-   %656 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     -\n\t\t+   %666 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      +\n\t\t-   %657 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %667 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.13 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.11 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.13 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.65 : Tensor = aten::unsqueeze(%input_token.11, %657), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t+   %input.65 : Tensor = aten::unsqueeze(%input_token.11, %667), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t    %weight.57 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.13)\n\t\t-   %embedded.11 : Tensor = aten::embedding(%weight.57, %input.65, %655, %656, %656), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^     ^     ^\n\t\t+   %embedded.11 : Tensor = aten::embedding(%weight.57, %input.65, %665, %666, %666), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^     ^     ^\n\t\t    %V.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.11)\n\t\t    %W2.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.11)\n\t\t    %W1.11 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.11)\n\t\t-   %668 : Tensor = aten::select(%110, %652, %655), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^     ^     ^\n\t\t+   %678 : Tensor = aten::select(%120, %662, %665), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^     ^     ^\n\t\t-   %input.67 : Tensor = aten::unsqueeze(%668, %657), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t+   %input.67 : Tensor = aten::unsqueeze(%678, %667), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t    %bias.41 : Tensor = prim::GetAttr[name=\"bias\"](%W1.11)\n\t\t    %weight.59 : Tensor = prim::GetAttr[name=\"weight\"](%W1.11)\n\t\t-   %672 : Tensor = aten::linear(%30, %weight.59, %bias.41), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %682 : Tensor = aten::linear(%30, %weight.59, %bias.41), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.43 : Tensor = prim::GetAttr[name=\"bias\"](%W2.11)\n\t\t    %weight.61 : Tensor = prim::GetAttr[name=\"weight\"](%W2.11)\n\t\t-   %675 : Tensor = aten::linear(%input.67, %weight.61, %bias.43), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %685 : Tensor = aten::linear(%input.67, %weight.61, %bias.43), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t-   %676 : Tensor = aten::add(%672, %675, %657), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %686 : Tensor = aten::add(%682, %685, %667), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.69 : Tensor = aten::tanh(%676), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.69 : Tensor = aten::tanh(%686), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.45 : Tensor = prim::GetAttr[name=\"bias\"](%V.11)\n\t\t    %weight.63 : Tensor = prim::GetAttr[name=\"weight\"](%V.11)\n\t\t    %input.71 : Tensor = aten::linear(%input.69, %weight.63, %bias.45), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %681 : Tensor = aten::softmax(%input.71, %657, %653), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t+   %691 : Tensor = aten::softmax(%input.71, %667, %663), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t-   %attention_weights.11 : Tensor = aten::transpose(%681, %657, %654), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t+   %attention_weights.11 : Tensor = aten::transpose(%691, %667, %664), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t    %context.11 : Tensor = aten::bmm(%attention_weights.11, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %684 : Tensor[] = prim::ListConstruct(%embedded.11, %context.11), scope: __module.decoder\n\t\t?     ^\n\t\t+   %694 : Tensor[] = prim::ListConstruct(%embedded.11, %context.11), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.73 : Tensor = aten::cat(%684, %654), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t+   %input.73 : Tensor = aten::cat(%694, %664), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t    %bias_hh_l2.13 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.13)\n\t\t    %bias_ih_l2.13 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.13)\n\t\t    %weight_hh_l2.13 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.13)\n\t\t    %weight_ih_l2.13 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.13)\n\t\t    %bias_hh_l1.13 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.13)\n\t\t    %bias_ih_l1.13 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.13)\n\t\t    %weight_hh_l1.13 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.13)\n\t\t    %weight_ih_l1.13 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.13)\n\t\t    %bias_hh_l0.13 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.13)\n\t\t    %bias_ih_l0.13 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.13)\n\t\t    %weight_hh_l0.13 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.13)\n\t\t    %weight_ih_l0.13 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.13)\n\t\t-   %698 : Tensor[] = prim::ListConstruct(%weight_ih_l0.13, %weight_hh_l0.13, %bias_ih_l0.13, %bias_hh_l0.13, %weight_ih_l1.13, %weight_hh_l1.13, %bias_ih_l1.13, %bias_hh_l1.13, %weight_ih_l2.13, %weight_hh_l2.13, %bias_ih_l2.13, %bias_hh_l2.13), scope: __module.decoder/__module.decoder.rnn\n\t\t?    ^^\n\t\t+   %708 : Tensor[] = prim::ListConstruct(%weight_ih_l0.13, %weight_hh_l0.13, %bias_ih_l0.13, %bias_hh_l0.13, %weight_ih_l1.13, %weight_hh_l1.13, %bias_ih_l1.13, %bias_hh_l1.13, %weight_ih_l2.13, %weight_hh_l2.13, %bias_ih_l2.13, %bias_hh_l2.13), scope: __module.decoder/__module.decoder.rnn\n\t\t?    ^^\n\t\t-   %output.21 : Tensor, %decoder_hidden.13 : Tensor = aten::gru(%input.73, %110, %698, %649, %650, %651, %656, %656, %649), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                             ^^^^^^ ^^^^^^^^    ------------------------\n\t\t+   %output.21 : Tensor, %decoder_hidden.13 : Tensor = aten::gru(%input.73, %120, %708, %659, %660, %661, %666, %666, %659), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                             ^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %701 : (Tensor, Tensor) = prim::TupleConstruct(%output.21, %decoder_hidden.13)\n\t\t?     -\n\t\t+   %711 : (Tensor, Tensor) = prim::TupleConstruct(%output.21, %decoder_hidden.13)\n\t\t?      +\n\t\t-   %702 : Tensor, %703 : Tensor = prim::TupleUnpack(%701)\n\t\t?     ^              ^                                 ^\n\t\t+   %712 : Tensor, %713 : Tensor = prim::TupleUnpack(%711)\n\t\t?     ^              ^                                 ^\n\t\t-   %704 : Tensor = aten::squeeze(%702, %657), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %714 : Tensor = aten::squeeze(%712, %667), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %705 : Tensor = aten::squeeze(%context.11, %657), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %715 : Tensor = aten::squeeze(%context.11, %667), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %706 : Tensor = aten::squeeze(%embedded.11, %657), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t+   %716 : Tensor = aten::squeeze(%embedded.11, %667), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t-   %707 : Tensor[] = prim::ListConstruct(%704, %705, %706), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %717 : Tensor[] = prim::ListConstruct(%714, %715, %716), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.75 : Tensor = aten::cat(%707, %657), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.75 : Tensor = aten::cat(%717, %667), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.47 : Tensor = prim::GetAttr[name=\"bias\"](%fc.11)\n\t\t    %weight.65 : Tensor = prim::GetAttr[name=\"weight\"](%fc.11)\n\t\t    %output.23 : Tensor = aten::linear(%input.75, %weight.65, %bias.47), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %712 : (Tensor, Tensor) = prim::TupleConstruct(%output.23, %703)\n\t\t?     -                                                          ^\n\t\t+   %722 : (Tensor, Tensor) = prim::TupleConstruct(%output.23, %713)\n\t\t?      +                                                         ^\n\t\t-   %130 : Tensor, %131 : Tensor = prim::TupleUnpack(%712)\n\t\t?      ^              ^                                ^\n\t\t+   %135 : Tensor, %136 : Tensor = prim::TupleUnpack(%722)\n\t\t?      ^              ^                                ^\n\t\t-   %132 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t+   %137 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t-   %133 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t+   %138 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t-   %134 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t+   %139 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^\n\t\t-   %135 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %140 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %136 : Tensor = aten::slice(%outputs, %132, %133, %134, %135) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                                     ^     ^     ^    ^^\n\t\t+   %141 : Tensor = aten::slice(%outputs, %137, %138, %139, %140) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                                     ^     ^     ^    ^^\n\t\t-   %137 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %138 : int = prim::Constant[value=6]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %139 : Tensor = aten::select(%136, %137, %138) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %140 : bool = prim::Constant[value=0]()\n\t\t-   %141 : Tensor = aten::copy_(%139, %130, %140) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %142 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                                                                                             ^\n\t\t+   %142 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?                                                                                                             ^\n\t\t-   %143 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?          ^^^^                        ^                                                                       ^\n\t\t+   %143 : int = prim::Constant[value=6]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?          ^^^                        ^                                                                       ^\n\t\t+   %144 : Tensor = aten::select(%141, %142, %143) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %145 : bool = prim::Constant[value=0]()\n\t\t+   %146 : Tensor = aten::copy_(%144, %135, %145) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %147 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %148 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %149 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %150 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %151 : Tensor = aten::slice(%trg, %147, %148, %149, %150) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %152 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %153 : int = prim::Constant[value=6]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %input_token.13 : Tensor = aten::argmax(%130, %142, %143) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                    ^^^^^^   ^^    ^     ^                                                                      ^\n\t\t+   %input_token.13 : Tensor = aten::select(%151, %152, %153) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                    ^^^^^^   ^^    ^     ^                                                                      ^\n\t\t-   %713 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %723 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %714 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %724 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %715 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %725 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %716 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %726 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %717 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %727 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %718 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %728 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %719 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %729 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %720 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %730 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %721 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %731 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.15 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.13 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.15 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.77 : Tensor = aten::unsqueeze(%input_token.13, %721), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t+   %input.77 : Tensor = aten::unsqueeze(%input_token.13, %731), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t    %weight.67 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.15)\n\t\t-   %embedded.13 : Tensor = aten::embedding(%weight.67, %input.77, %719, %720, %720), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                  ------        ^\n\t\t+   %embedded.13 : Tensor = aten::embedding(%weight.67, %input.77, %729, %730, %730), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                     ++++++     ^\n\t\t    %V.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.13)\n\t\t    %W2.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.13)\n\t\t    %W1.13 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.13)\n\t\t-   %732 : Tensor = aten::select(%131, %716, %719), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                             ^    ^     ^\n\t\t+   %742 : Tensor = aten::select(%136, %726, %729), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                             ^    ^     ^\n\t\t-   %input.79 : Tensor = aten::unsqueeze(%732, %721), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t+   %input.79 : Tensor = aten::unsqueeze(%742, %731), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                          ^     ^\n\t\t    %bias.49 : Tensor = prim::GetAttr[name=\"bias\"](%W1.13)\n\t\t    %weight.69 : Tensor = prim::GetAttr[name=\"weight\"](%W1.13)\n\t\t-   %736 : Tensor = aten::linear(%30, %weight.69, %bias.49), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %746 : Tensor = aten::linear(%30, %weight.69, %bias.49), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.51 : Tensor = prim::GetAttr[name=\"bias\"](%W2.13)\n\t\t    %weight.71 : Tensor = prim::GetAttr[name=\"weight\"](%W2.13)\n\t\t-   %739 : Tensor = aten::linear(%input.79, %weight.71, %bias.51), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %749 : Tensor = aten::linear(%input.79, %weight.71, %bias.51), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t-   %740 : Tensor = aten::add(%736, %739, %721), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^      ------\n\t\t+   %750 : Tensor = aten::add(%746, %749, %731), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^  ++++++\n\t\t-   %input.81 : Tensor = aten::tanh(%740), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.81 : Tensor = aten::tanh(%750), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.53 : Tensor = prim::GetAttr[name=\"bias\"](%V.13)\n\t\t    %weight.73 : Tensor = prim::GetAttr[name=\"weight\"](%V.13)\n\t\t    %input.83 : Tensor = aten::linear(%input.81, %weight.73, %bias.53), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %745 : Tensor = aten::softmax(%input.83, %721, %717), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     -                                         ------\n\t\t+   %755 : Tensor = aten::softmax(%input.83, %731, %727), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      +                                     ++++++\n\t\t-   %attention_weights.13 : Tensor = aten::transpose(%745, %721, %718), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^      ------\n\t\t+   %attention_weights.13 : Tensor = aten::transpose(%755, %731, %728), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^  ++++++\n\t\t    %context.13 : Tensor = aten::bmm(%attention_weights.13, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %748 : Tensor[] = prim::ListConstruct(%embedded.13, %context.13), scope: __module.decoder\n\t\t?     ^\n\t\t+   %758 : Tensor[] = prim::ListConstruct(%embedded.13, %context.13), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.85 : Tensor = aten::cat(%748, %718), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t+   %input.85 : Tensor = aten::cat(%758, %728), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t    %bias_hh_l2.15 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.15)\n\t\t    %bias_ih_l2.15 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.15)\n\t\t    %weight_hh_l2.15 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.15)\n\t\t    %weight_ih_l2.15 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.15)\n\t\t    %bias_hh_l1.15 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.15)\n\t\t    %bias_ih_l1.15 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.15)\n\t\t    %weight_hh_l1.15 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.15)\n\t\t    %weight_ih_l1.15 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.15)\n\t\t    %bias_hh_l0.15 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.15)\n\t\t    %bias_ih_l0.15 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.15)\n\t\t    %weight_hh_l0.15 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.15)\n\t\t    %weight_ih_l0.15 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.15)\n\t\t-   %762 : Tensor[] = prim::ListConstruct(%weight_ih_l0.15, %weight_hh_l0.15, %bias_ih_l0.15, %bias_hh_l0.15, %weight_ih_l1.15, %weight_hh_l1.15, %bias_ih_l1.15, %bias_hh_l1.15, %weight_ih_l2.15, %weight_hh_l2.15, %bias_ih_l2.15, %bias_hh_l2.15), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t+   %772 : Tensor[] = prim::ListConstruct(%weight_ih_l0.15, %weight_hh_l0.15, %bias_ih_l0.15, %bias_hh_l0.15, %weight_ih_l1.15, %weight_hh_l1.15, %bias_ih_l1.15, %bias_hh_l1.15, %weight_ih_l2.15, %weight_hh_l2.15, %bias_ih_l2.15, %bias_hh_l2.15), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^^^^\n\t\t-   %output.25 : Tensor, %decoder_hidden.15 : Tensor = aten::gru(%input.85, %131, %762, %713, %714, %715, %720, %720, %713), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ----- ^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.25 : Tensor, %decoder_hidden.15 : Tensor = aten::gru(%input.85, %136, %772, %723, %724, %725, %730, %730, %723), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                               ^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^\n\t\t-   %765 : (Tensor, Tensor) = prim::TupleConstruct(%output.25, %decoder_hidden.15)\n\t\t?     ^\n\t\t+   %775 : (Tensor, Tensor) = prim::TupleConstruct(%output.25, %decoder_hidden.15)\n\t\t?     ^\n\t\t-   %766 : Tensor, %767 : Tensor = prim::TupleUnpack(%765)\n\t\t?      -             -                                 ^\n\t\t+   %776 : Tensor, %777 : Tensor = prim::TupleUnpack(%775)\n\t\t?     +               +                                ^\n\t\t-   %768 : Tensor = aten::squeeze(%766, %721), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %778 : Tensor = aten::squeeze(%776, %731), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %769 : Tensor = aten::squeeze(%context.13, %721), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %779 : Tensor = aten::squeeze(%context.13, %731), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %770 : Tensor = aten::squeeze(%embedded.13, %721), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t+   %780 : Tensor = aten::squeeze(%embedded.13, %731), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t-   %771 : Tensor[] = prim::ListConstruct(%768, %769, %770), scope: __module.decoder\n\t\t?     ^                                     ^  ------\n\t\t+   %781 : Tensor[] = prim::ListConstruct(%778, %779, %780), scope: __module.decoder\n\t\t?     ^                                     ^      ++++++\n\t\t-   %input.87 : Tensor = aten::cat(%771, %721), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.87 : Tensor = aten::cat(%781, %731), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.55 : Tensor = prim::GetAttr[name=\"bias\"](%fc.13)\n\t\t    %weight.75 : Tensor = prim::GetAttr[name=\"weight\"](%fc.13)\n\t\t    %output.27 : Tensor = aten::linear(%input.87, %weight.75, %bias.55), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %776 : (Tensor, Tensor) = prim::TupleConstruct(%output.27, %767)\n\t\t?     ^                                                          ^\n\t\t+   %786 : (Tensor, Tensor) = prim::TupleConstruct(%output.27, %777)\n\t\t?     ^                                                          ^\n\t\t-   %146 : Tensor, %147 : Tensor = prim::TupleUnpack(%776)\n\t\t?     ^              ^                                 ^\n\t\t+   %156 : Tensor, %157 : Tensor = prim::TupleUnpack(%786)\n\t\t?     ^              ^                                 ^\n\t\t-   %148 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %158 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %149 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %159 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %150 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %160 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %151 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %161 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %152 : Tensor = aten::slice(%outputs, %148, %149, %150, %151) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                   ------------   ^\n\t\t+   %162 : Tensor = aten::slice(%outputs, %158, %159, %160, %161) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                      ^     ++++++++++++\n\t\t-   %153 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %163 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %154 : int = prim::Constant[value=7]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %164 : int = prim::Constant[value=7]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %155 : Tensor = aten::select(%152, %153, %154) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -                           ^     ^     ^\n\t\t+   %165 : Tensor = aten::select(%162, %163, %164) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +                            ^     ^     ^\n\t\t-   %156 : bool = prim::Constant[value=0]()\n\t\t?     -\n\t\t+   %166 : bool = prim::Constant[value=0]()\n\t\t?      +\n\t\t-   %157 : Tensor = aten::copy_(%155, %146, %156) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^  ------\n\t\t+   %167 : Tensor = aten::copy_(%165, %156, %166) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^       ++++++\n\t\t-   %158 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^                               ^                                                                       ^\n\t\t+   %168 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                               ^                                                                       ^\n\t\t-   %159 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^    ^^^^                                                                                                ^\n\t\t+   %169 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^    ^^^                                                                                                ^\n\t\t+   %170 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %171 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %172 : Tensor = aten::slice(%trg, %168, %169, %170, %171) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %173 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %174 : int = prim::Constant[value=7]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %input_token.15 : Tensor = aten::argmax(%146, %158, %159) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                    ^^^^^^   ^^    ^^    ^^                                                                     ^\n\t\t+   %input_token.15 : Tensor = aten::select(%172, %173, %174) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                    ^^^^^^   ^^    ^^    ^^                                                                     ^\n\t\t-   %777 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %787 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     +\n\t\t-   %778 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     -\n\t\t+   %788 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      +\n\t\t-   %779 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %789 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %780 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %790 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %781 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %791 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %782 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %792 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %783 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %793 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %784 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %794 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %785 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %795 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.17 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.15 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.17 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.89 : Tensor = aten::unsqueeze(%input_token.15, %785), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t+   %input.89 : Tensor = aten::unsqueeze(%input_token.15, %795), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                           ^\n\t\t    %weight.77 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.17)\n\t\t-   %embedded.15 : Tensor = aten::embedding(%weight.77, %input.89, %783, %784, %784), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^     ^     ^\n\t\t+   %embedded.15 : Tensor = aten::embedding(%weight.77, %input.89, %793, %794, %794), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^     ^     ^\n\t\t    %V.15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.15)\n\t\t    %W2.15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.15)\n\t\t    %W1.15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.15)\n\t\t-   %796 : Tensor = aten::select(%147, %780, %783), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?    ^^                            ^     ^     ^\n\t\t+   %806 : Tensor = aten::select(%157, %790, %793), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?    ^^                            ^     ^     ^\n\t\t-   %input.91 : Tensor = aten::unsqueeze(%796, %785), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ------\n\t\t+   %input.91 : Tensor = aten::unsqueeze(%806, %795), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                         ++++++\n\t\t    %bias.57 : Tensor = prim::GetAttr[name=\"bias\"](%W1.15)\n\t\t    %weight.79 : Tensor = prim::GetAttr[name=\"weight\"](%W1.15)\n\t\t-   %800 : Tensor = aten::linear(%30, %weight.79, %bias.57), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t+   %810 : Tensor = aten::linear(%30, %weight.79, %bias.57), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t    %bias.59 : Tensor = prim::GetAttr[name=\"bias\"](%W2.15)\n\t\t    %weight.81 : Tensor = prim::GetAttr[name=\"weight\"](%W2.15)\n\t\t-   %803 : Tensor = aten::linear(%input.91, %weight.81, %bias.59), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %813 : Tensor = aten::linear(%input.91, %weight.81, %bias.59), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t-   %804 : Tensor = aten::add(%800, %803, %785), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %814 : Tensor = aten::add(%810, %813, %795), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.93 : Tensor = aten::tanh(%804), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t+   %input.93 : Tensor = aten::tanh(%814), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^\n\t\t    %bias.61 : Tensor = prim::GetAttr[name=\"bias\"](%V.15)\n\t\t    %weight.83 : Tensor = prim::GetAttr[name=\"weight\"](%V.15)\n\t\t    %input.95 : Tensor = aten::linear(%input.93, %weight.83, %bias.61), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %809 : Tensor = aten::softmax(%input.95, %785, %781), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t+   %819 : Tensor = aten::softmax(%input.95, %795, %791), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                        ^     ^\n\t\t-   %attention_weights.15 : Tensor = aten::transpose(%809, %785, %782), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t+   %attention_weights.15 : Tensor = aten::transpose(%819, %795, %792), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t    %context.15 : Tensor = aten::bmm(%attention_weights.15, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %812 : Tensor[] = prim::ListConstruct(%embedded.15, %context.15), scope: __module.decoder\n\t\t?     -\n\t\t+   %822 : Tensor[] = prim::ListConstruct(%embedded.15, %context.15), scope: __module.decoder\n\t\t?      +\n\t\t-   %input.97 : Tensor = aten::cat(%812, %782), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t+   %input.97 : Tensor = aten::cat(%822, %792), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                    ^     ^\n\t\t    %bias_hh_l2.17 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.17)\n\t\t    %bias_ih_l2.17 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.17)\n\t\t    %weight_hh_l2.17 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.17)\n\t\t    %weight_ih_l2.17 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.17)\n\t\t    %bias_hh_l1.17 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.17)\n\t\t    %bias_ih_l1.17 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.17)\n\t\t    %weight_hh_l1.17 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.17)\n\t\t    %weight_ih_l1.17 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.17)\n\t\t    %bias_hh_l0.17 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.17)\n\t\t    %bias_ih_l0.17 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.17)\n\t\t    %weight_hh_l0.17 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.17)\n\t\t    %weight_ih_l0.17 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.17)\n\t\t-   %826 : Tensor[] = prim::ListConstruct(%weight_ih_l0.17, %weight_hh_l0.17, %bias_ih_l0.17, %bias_hh_l0.17, %weight_ih_l1.17, %weight_hh_l1.17, %bias_ih_l1.17, %bias_hh_l1.17, %weight_ih_l2.17, %weight_hh_l2.17, %bias_ih_l2.17, %bias_hh_l2.17), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t+   %836 : Tensor[] = prim::ListConstruct(%weight_ih_l0.17, %weight_hh_l0.17, %bias_ih_l0.17, %bias_hh_l0.17, %weight_ih_l1.17, %weight_hh_l1.17, %bias_ih_l1.17, %bias_hh_l1.17, %weight_ih_l2.17, %weight_hh_l2.17, %bias_ih_l2.17, %bias_hh_l2.17), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t-   %output.29 : Tensor, %decoder_hidden.17 : Tensor = aten::gru(%input.97, %147, %826, %777, %778, %779, %784, %784, %777), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^      ------\n\t\t+   %output.29 : Tensor, %decoder_hidden.17 : Tensor = aten::gru(%input.97, %157, %836, %787, %788, %789, %794, %794, %787), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                             +++++++++++++++++++++++++++++++ ^^^^^\n\t\t-   %829 : (Tensor, Tensor) = prim::TupleConstruct(%output.29, %decoder_hidden.17)\n\t\t?     ^\n\t\t+   %839 : (Tensor, Tensor) = prim::TupleConstruct(%output.29, %decoder_hidden.17)\n\t\t?     ^\n\t\t-   %830 : Tensor, %831 : Tensor = prim::TupleUnpack(%829)\n\t\t?     ^              ^                                 ^\n\t\t+   %840 : Tensor, %841 : Tensor = prim::TupleUnpack(%839)\n\t\t?     ^              ^                                 ^\n\t\t-   %832 : Tensor = aten::squeeze(%830, %785), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %842 : Tensor = aten::squeeze(%840, %795), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %833 : Tensor = aten::squeeze(%context.15, %785), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      -                                         ^\n\t\t+   %843 : Tensor = aten::squeeze(%context.15, %795), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     +                                          ^\n\t\t-   %834 : Tensor = aten::squeeze(%embedded.15, %785), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     -                                           ^\n\t\t+   %844 : Tensor = aten::squeeze(%embedded.15, %795), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      +                                          ^\n\t\t-   %835 : Tensor[] = prim::ListConstruct(%832, %833, %834), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %845 : Tensor[] = prim::ListConstruct(%842, %843, %844), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.99 : Tensor = aten::cat(%835, %785), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t+   %input.99 : Tensor = aten::cat(%845, %795), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    ^     ^\n\t\t    %bias.63 : Tensor = prim::GetAttr[name=\"bias\"](%fc.15)\n\t\t    %weight.85 : Tensor = prim::GetAttr[name=\"weight\"](%fc.15)\n\t\t    %output.31 : Tensor = aten::linear(%input.99, %weight.85, %bias.63), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %840 : (Tensor, Tensor) = prim::TupleConstruct(%output.31, %831)\n\t\t?     ^                                                          ^\n\t\t+   %850 : (Tensor, Tensor) = prim::TupleConstruct(%output.31, %841)\n\t\t?     ^                                                          ^\n\t\t-   %162 : Tensor, %163 : Tensor = prim::TupleUnpack(%840)\n\t\t?     ^^             ^^                                ^\n\t\t+   %177 : Tensor, %178 : Tensor = prim::TupleUnpack(%850)\n\t\t?     ^^             ^^                                ^\n\t\t-   %164 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %179 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %165 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %180 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %166 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %181 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %167 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %182 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %168 : Tensor = aten::slice(%outputs, %164, %165, %166, %167) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -                                     ^^    ^^    ^^    ^^\n\t\t+   %183 : Tensor = aten::slice(%outputs, %179, %180, %181, %182) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +                                    ^^    ^^    ^^    ^^\n\t\t-   %169 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %184 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %170 : int = prim::Constant[value=8]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t+   %185 : int = prim::Constant[value=8]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^\n\t\t-   %171 : Tensor = aten::select(%168, %169, %170) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                           -     ^^    ^^\n\t\t+   %186 : Tensor = aten::select(%183, %184, %185) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                            +    ^^    ^^\n\t\t-   %172 : bool = prim::Constant[value=0]()\n\t\t?      -\n\t\t+   %187 : bool = prim::Constant[value=0]()\n\t\t?     +\n\t\t-   %173 : Tensor = aten::copy_(%171, %162, %172) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                          ^^ ------    ^\n\t\t+   %188 : Tensor = aten::copy_(%186, %177, %187) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                          ^^     ^^^^^^^\n\t\t-   %174 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t+   %189 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t-   %175 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t+   %190 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t-   %176 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t+   %191 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t-   %177 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %178 : Tensor = aten::slice(%trg, %174, %175, %176, %177) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %179 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     -\n\t\t+   %192 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      +\n\t\t+   %193 : Tensor = aten::slice(%trg, %189, %190, %191, %192) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t+   %194 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %180 : int = prim::Constant[value=8]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t+   %195 : int = prim::Constant[value=8]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^\n\t\t-   %input_token.17 : Tensor = aten::select(%178, %179, %180) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^^    -     ^^\n\t\t+   %input_token.17 : Tensor = aten::select(%193, %194, %195) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^^     +    ^^\n\t\t-   %841 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %851 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %842 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %852 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %843 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %853 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %844 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      -\n\t\t+   %854 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     +\n\t\t-   %845 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     -\n\t\t+   %855 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      +\n\t\t-   %846 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %856 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %847 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %857 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %848 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %858 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %849 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %859 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.17 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.19 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.17 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.19 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.101 : Tensor = aten::unsqueeze(%input_token.17, %849), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t+   %input.101 : Tensor = aten::unsqueeze(%input_token.17, %859), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t    %weight.87 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.19)\n\t\t-   %embedded.17 : Tensor = aten::embedding(%weight.87, %input.101, %847, %848, %848), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                     ^     ^     ^\n\t\t+   %embedded.17 : Tensor = aten::embedding(%weight.87, %input.101, %857, %858, %858), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                     ^     ^     ^\n\t\t    %V.17 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.17)\n\t\t    %W2.17 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.17)\n\t\t    %W1.17 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.17)\n\t\t-   %860 : Tensor = aten::select(%163, %844, %847), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^^    ^     ^\n\t\t+   %870 : Tensor = aten::select(%178, %854, %857), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^^    ^     ^\n\t\t-   %input.103 : Tensor = aten::unsqueeze(%860, %849), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t+   %input.103 : Tensor = aten::unsqueeze(%870, %859), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t    %bias.65 : Tensor = prim::GetAttr[name=\"bias\"](%W1.17)\n\t\t    %weight.89 : Tensor = prim::GetAttr[name=\"weight\"](%W1.17)\n\t\t-   %864 : Tensor = aten::linear(%30, %weight.89, %bias.65), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %874 : Tensor = aten::linear(%30, %weight.89, %bias.65), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.67 : Tensor = prim::GetAttr[name=\"bias\"](%W2.17)\n\t\t    %weight.91 : Tensor = prim::GetAttr[name=\"weight\"](%W2.17)\n\t\t-   %867 : Tensor = aten::linear(%input.103, %weight.91, %bias.67), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     - ^^\n\t\t+   %877 : Tensor = aten::linear(%input.103, %weight.91, %bias.67), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^\n\t\t-   %868 : Tensor = aten::add(%864, %867, %849), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %878 : Tensor = aten::add(%874, %877, %859), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.105 : Tensor = aten::tanh(%868), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                      ^\n\t\t+   %input.105 : Tensor = aten::tanh(%878), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                      ^\n\t\t    %bias.69 : Tensor = prim::GetAttr[name=\"bias\"](%V.17)\n\t\t    %weight.93 : Tensor = prim::GetAttr[name=\"weight\"](%V.17)\n\t\t    %input.107 : Tensor = aten::linear(%input.105, %weight.93, %bias.69), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %873 : Tensor = aten::softmax(%input.107, %849, %845), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                         ^     ^\n\t\t+   %883 : Tensor = aten::softmax(%input.107, %859, %855), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                         ^     ^\n\t\t-   %attention_weights.17 : Tensor = aten::transpose(%873, %849, %846), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t+   %attention_weights.17 : Tensor = aten::transpose(%883, %859, %856), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t    %context.17 : Tensor = aten::bmm(%attention_weights.17, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %876 : Tensor[] = prim::ListConstruct(%embedded.17, %context.17), scope: __module.decoder\n\t\t?     ^\n\t\t+   %886 : Tensor[] = prim::ListConstruct(%embedded.17, %context.17), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.109 : Tensor = aten::cat(%876, %846), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^     ^\n\t\t+   %input.109 : Tensor = aten::cat(%886, %856), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^     ^\n\t\t    %bias_hh_l2.19 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.19)\n\t\t    %bias_ih_l2.19 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.19)\n\t\t    %weight_hh_l2.19 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.19)\n\t\t    %weight_ih_l2.19 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.19)\n\t\t    %bias_hh_l1.19 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.19)\n\t\t    %bias_ih_l1.19 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.19)\n\t\t    %weight_hh_l1.19 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.19)\n\t\t    %weight_ih_l1.19 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.19)\n\t\t    %bias_hh_l0.19 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.19)\n\t\t    %bias_ih_l0.19 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.19)\n\t\t    %weight_hh_l0.19 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.19)\n\t\t    %weight_ih_l0.19 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.19)\n\t\t-   %890 : Tensor[] = prim::ListConstruct(%weight_ih_l0.19, %weight_hh_l0.19, %bias_ih_l0.19, %bias_hh_l0.19, %weight_ih_l1.19, %weight_hh_l1.19, %bias_ih_l1.19, %bias_hh_l1.19, %weight_ih_l2.19, %weight_hh_l2.19, %bias_ih_l2.19, %bias_hh_l2.19), scope: __module.decoder/__module.decoder.rnn\n\t\t?    ^^^^^\n\t\t+   %900 : Tensor[] = prim::ListConstruct(%weight_ih_l0.19, %weight_hh_l0.19, %bias_ih_l0.19, %bias_hh_l0.19, %weight_ih_l1.19, %weight_hh_l1.19, %bias_ih_l1.19, %bias_hh_l1.19, %weight_ih_l2.19, %weight_hh_l2.19, %bias_ih_l2.19, %bias_hh_l2.19), scope: __module.decoder/__module.decoder.rnn\n\t\t?    ^^^^^\n\t\t-   %output.33 : Tensor, %decoder_hidden.19 : Tensor = aten::gru(%input.109, %163, %890, %841, %842, %843, %848, %848, %841), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.33 : Tensor, %decoder_hidden.19 : Tensor = aten::gru(%input.109, %178, %900, %851, %852, %853, %858, %858, %851), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^\n\t\t-   %893 : (Tensor, Tensor) = prim::TupleConstruct(%output.33, %decoder_hidden.19)\n\t\t?    -\n\t\t+   %903 : (Tensor, Tensor) = prim::TupleConstruct(%output.33, %decoder_hidden.19)\n\t\t?     +\n\t\t-   %894 : Tensor, %895 : Tensor = prim::TupleUnpack(%893)\n\t\t?    -              -                                 -\n\t\t+   %904 : Tensor, %905 : Tensor = prim::TupleUnpack(%903)\n\t\t?     +              +                                 +\n\t\t-   %896 : Tensor = aten::squeeze(%894, %849), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?    -                             -      ^\n\t\t+   %906 : Tensor = aten::squeeze(%904, %859), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     +                             +     ^\n\t\t-   %897 : Tensor = aten::squeeze(%context.17, %849), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?    -                                           ^\n\t\t+   %907 : Tensor = aten::squeeze(%context.17, %859), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     +                                          ^\n\t\t-   %898 : Tensor = aten::squeeze(%embedded.17, %849), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     --                                          ^\n\t\t+   %908 : Tensor = aten::squeeze(%embedded.17, %859), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?    ++                                           ^\n\t\t-   %899 : Tensor[] = prim::ListConstruct(%896, %897, %898), scope: __module.decoder\n\t\t?    -                                     -     -     -\n\t\t+   %909 : Tensor[] = prim::ListConstruct(%906, %907, %908), scope: __module.decoder\n\t\t?     +                                     +     +     +\n\t\t-   %input.111 : Tensor = aten::cat(%899, %849), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                    -      ^\n\t\t+   %input.111 : Tensor = aten::cat(%909, %859), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                     +     ^\n\t\t    %bias.71 : Tensor = prim::GetAttr[name=\"bias\"](%fc.17)\n\t\t    %weight.95 : Tensor = prim::GetAttr[name=\"weight\"](%fc.17)\n\t\t    %output.35 : Tensor = aten::linear(%input.111, %weight.95, %bias.71), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %904 : (Tensor, Tensor) = prim::TupleConstruct(%output.35, %895)\n\t\t?     ^                                                         -\n\t\t+   %914 : (Tensor, Tensor) = prim::TupleConstruct(%output.35, %905)\n\t\t?     ^                                                          +\n\t\t-   %183 : Tensor, %184 : Tensor = prim::TupleUnpack(%904)\n\t\t?      -             ^^                                ^\n\t\t+   %198 : Tensor, %199 : Tensor = prim::TupleUnpack(%914)\n\t\t?     +              ^^                                ^\n\t\t+   %200 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %185 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     --\n\t\t+   %201 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ++\n\t\t-   %186 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %187 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^^\n\t\t+   %202 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^^\n\t\t-   %188 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %189 : Tensor = aten::slice(%outputs, %185, %186, %187, %188) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %190 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^\n\t\t+   %203 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^ +\n\t\t+   %204 : Tensor = aten::slice(%outputs, %200, %201, %202, %203) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %205 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %191 : int = prim::Constant[value=9]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^^\n\t\t+   %206 : int = prim::Constant[value=9]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^^\n\t\t-   %192 : Tensor = aten::select(%189, %190, %191) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    --                           ^^^   ^^    ^^^\n\t\t+   %207 : Tensor = aten::select(%204, %205, %206) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ++                          ^^^   ^ +   ^^^\n\t\t-   %193 : bool = prim::Constant[value=0]()\n\t\t?    ^^^\n\t\t+   %208 : bool = prim::Constant[value=0]()\n\t\t?    ^^^\n\t\t-   %194 : Tensor = aten::copy_(%192, %183, %193) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^ -                         --  ------    ^\n\t\t+   %209 : Tensor = aten::copy_(%207, %198, %208) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                           ++     ^^^^^^^\n\t\t-   %195 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^^\n\t\t+   %210 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?    + ^\n\t\t-   %196 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?     ^^\n\t\t+   %211 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?    + ^\n\t\t-   %input_token.19 : Tensor = aten::argmax(%183, %195, %196) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                              -    ^^    ^^\n\t\t+   %input_token.19 : Tensor = aten::argmax(%198, %210, %211) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                             +    + ^   + ^\n\t\t-   %905 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %915 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %906 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %916 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %907 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %917 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %908 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %918 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %909 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %919 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %910 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %920 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %911 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      -\n\t\t+   %921 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     +\n\t\t-   %912 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     -\n\t\t+   %922 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      +\n\t\t-   %913 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t+   %923 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     ^\n\t\t    %fc.19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.21 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.19 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.21 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.113 : Tensor = aten::unsqueeze(%input_token.19, %913), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t+   %input.113 : Tensor = aten::unsqueeze(%input_token.19, %923), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t    %weight.97 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.21)\n\t\t-   %embedded.19 : Tensor = aten::embedding(%weight.97, %input.113, %911, %912, %912), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                     ^     ^     ^\n\t\t+   %embedded.19 : Tensor = aten::embedding(%weight.97, %input.113, %921, %922, %922), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                     ^     ^     ^\n\t\t    %V.19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.19)\n\t\t    %W2.19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.19)\n\t\t    %W1.19 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.19)\n\t\t-   %924 : Tensor = aten::select(%184, %908, %911), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^^ ------\n\t\t+   %934 : Tensor = aten::select(%199, %918, %921), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^                            ^^     ++++++\n\t\t-   %input.115 : Tensor = aten::unsqueeze(%924, %913), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t+   %input.115 : Tensor = aten::unsqueeze(%934, %923), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t    %bias.73 : Tensor = prim::GetAttr[name=\"bias\"](%W1.19)\n\t\t    %weight.99 : Tensor = prim::GetAttr[name=\"weight\"](%W1.19)\n\t\t-   %928 : Tensor = aten::linear(%30, %weight.99, %bias.73), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t+   %938 : Tensor = aten::linear(%30, %weight.99, %bias.73), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^\n\t\t    %bias.75 : Tensor = prim::GetAttr[name=\"bias\"](%W2.19)\n\t\t    %weight.101 : Tensor = prim::GetAttr[name=\"weight\"](%W2.19)\n\t\t-   %931 : Tensor = aten::linear(%input.115, %weight.101, %bias.75), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t+   %941 : Tensor = aten::linear(%input.115, %weight.101, %bias.75), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?     ^^^^\n\t\t-   %932 : Tensor = aten::add(%928, %931, %913), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t+   %942 : Tensor = aten::add(%938, %941, %923), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?     ^                         ^     ^     ^\n\t\t-   %input.117 : Tensor = aten::tanh(%932), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                      ^\n\t\t+   %input.117 : Tensor = aten::tanh(%942), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                      ^\n\t\t    %bias.77 : Tensor = prim::GetAttr[name=\"bias\"](%V.19)\n\t\t    %weight.103 : Tensor = prim::GetAttr[name=\"weight\"](%V.19)\n\t\t    %input.119 : Tensor = aten::linear(%input.117, %weight.103, %bias.77), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %937 : Tensor = aten::softmax(%input.119, %913, %909), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                          ------\n\t\t+   %947 : Tensor = aten::softmax(%input.119, %923, %919), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^                                       ++++++\n\t\t-   %attention_weights.19 : Tensor = aten::transpose(%937, %913, %910), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t+   %attention_weights.19 : Tensor = aten::transpose(%947, %923, %920), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                      ^     ^     ^\n\t\t    %context.19 : Tensor = aten::bmm(%attention_weights.19, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %940 : Tensor[] = prim::ListConstruct(%embedded.19, %context.19), scope: __module.decoder\n\t\t?     ^\n\t\t+   %950 : Tensor[] = prim::ListConstruct(%embedded.19, %context.19), scope: __module.decoder\n\t\t?     ^\n\t\t-   %input.121 : Tensor = aten::cat(%940, %910), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^     ^\n\t\t+   %input.121 : Tensor = aten::cat(%950, %920), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^     ^\n\t\t    %bias_hh_l2.21 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.21)\n\t\t    %bias_ih_l2.21 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.21)\n\t\t    %weight_hh_l2.21 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.21)\n\t\t    %weight_ih_l2.21 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.21)\n\t\t    %bias_hh_l1.21 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.21)\n\t\t    %bias_ih_l1.21 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.21)\n\t\t    %weight_hh_l1.21 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.21)\n\t\t    %weight_ih_l1.21 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.21)\n\t\t    %bias_hh_l0.21 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.21)\n\t\t    %bias_ih_l0.21 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.21)\n\t\t    %weight_hh_l0.21 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.21)\n\t\t    %weight_ih_l0.21 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.21)\n\t\t-   %954 : Tensor[] = prim::ListConstruct(%weight_ih_l0.21, %weight_hh_l0.21, %bias_ih_l0.21, %bias_hh_l0.21, %weight_ih_l1.21, %weight_hh_l1.21, %bias_ih_l1.21, %bias_hh_l1.21, %weight_ih_l2.21, %weight_hh_l2.21, %bias_ih_l2.21, %bias_hh_l2.21), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t+   %964 : Tensor[] = prim::ListConstruct(%weight_ih_l0.21, %weight_hh_l0.21, %bias_ih_l0.21, %bias_hh_l0.21, %weight_ih_l1.21, %weight_hh_l1.21, %bias_ih_l1.21, %bias_hh_l1.21, %weight_ih_l2.21, %weight_hh_l2.21, %bias_ih_l2.21, %bias_hh_l2.21), scope: __module.decoder/__module.decoder.rnn\n\t\t?     ^\n\t\t-   %output.37 : Tensor, %decoder_hidden.21 : Tensor = aten::gru(%input.121, %184, %954, %905, %906, %907, %912, %912, %905), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^      ^^^^^^^^^^^^     ^     ^^^^^^^^^^^^^\n\t\t+   %output.37 : Tensor, %decoder_hidden.21 : Tensor = aten::gru(%input.121, %199, %964, %915, %916, %917, %922, %922, %915), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^     + ^^^^^     ^     ^^^^^^^^^^^^^\n\t\t-   %957 : (Tensor, Tensor) = prim::TupleConstruct(%output.37, %decoder_hidden.21)\n\t\t?     ^\n\t\t+   %967 : (Tensor, Tensor) = prim::TupleConstruct(%output.37, %decoder_hidden.21)\n\t\t?     ^\n\t\t-   %958 : Tensor, %959 : Tensor = prim::TupleUnpack(%957)\n\t\t?     ^              ^                                 ^\n\t\t+   %968 : Tensor, %969 : Tensor = prim::TupleUnpack(%967)\n\t\t?     ^              ^                                 ^\n\t\t-   %960 : Tensor = aten::squeeze(%958, %913), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t+   %970 : Tensor = aten::squeeze(%968, %923), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                             ^     ^\n\t\t-   %961 : Tensor = aten::squeeze(%context.19, %913), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t+   %971 : Tensor = aten::squeeze(%context.19, %923), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                          ^\n\t\t-   %962 : Tensor = aten::squeeze(%embedded.19, %913), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t+   %972 : Tensor = aten::squeeze(%embedded.19, %923), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     ^                                           ^\n\t\t-   %963 : Tensor[] = prim::ListConstruct(%960, %961, %962), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t+   %973 : Tensor[] = prim::ListConstruct(%970, %971, %972), scope: __module.decoder\n\t\t?     ^                                     ^     ^     ^\n\t\t-   %input.123 : Tensor = aten::cat(%963, %913), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                     ^     ^\n\t\t+   %input.123 : Tensor = aten::cat(%973, %923), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                     ^     ^\n\t\t    %bias.79 : Tensor = prim::GetAttr[name=\"bias\"](%fc.19)\n\t\t    %weight.105 : Tensor = prim::GetAttr[name=\"weight\"](%fc.19)\n\t\t    %output.39 : Tensor = aten::linear(%input.123, %weight.105, %bias.79), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %968 : (Tensor, Tensor) = prim::TupleConstruct(%output.39, %959)\n\t\t?     ^                                                          ^\n\t\t+   %978 : (Tensor, Tensor) = prim::TupleConstruct(%output.39, %969)\n\t\t?     ^                                                          ^\n\t\t-   %199 : Tensor, %200 : Tensor = prim::TupleUnpack(%968)\n\t\t?     ^^             ^^                                ^\n\t\t+   %214 : Tensor, %215 : Tensor = prim::TupleUnpack(%978)\n\t\t?    + ^             ^^                                ^\n\t\t-   %201 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %216 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %202 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %203 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %204 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %205 : Tensor = aten::slice(%outputs, %201, %202, %203, %204) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %206 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %207 : int = prim::Constant[value=10]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                               -\n\t\t+   %217 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %208 : Tensor = aten::select(%205, %206, %207) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %209 : bool = prim::Constant[value=0]()\n\t\t-   %210 : Tensor = aten::copy_(%208, %199, %209) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t-   %211 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %212 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t-   %213 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      ^                                                                                                                        ^\n\t\t+   %218 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^                                                                                                                        ^\n\t\t-   %214 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      ^                                                                                                      ^\n\t\t+   %219 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      ^                                                                                                      ^\n\t\t-   %215 : Tensor = aten::slice(%trg, %211, %212, %213, %214) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^                          ^^     ^     ^     ^     ^                                                                     ^\n\t\t+   %220 : Tensor = aten::slice(%outputs, %216, %217, %218, %219) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                         ++ ^^^^     ^     ^     ^     ^                                                                     ^\n\t\t-   %216 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      -                                                                                                      ^\n\t\t+   %221 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +                                                                                                       ^\n\t\t-   %217 : int = prim::Constant[value=10]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^^                                                                                                       ^\n\t\t+   %222 : int = prim::Constant[value=10]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^^                                                                                                       ^\n\t\t+   %223 : Tensor = aten::select(%220, %221, %222) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %224 : bool = prim::Constant[value=0]()\n\t\t+   %225 : Tensor = aten::copy_(%223, %214, %224) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t+   %226 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t+   %227 : bool = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t-   %input_token.21 : Tensor = aten::select(%215, %216, %217) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                    ^^^^^^    ^    ^     ^                                                                      ^\n\t\t+   %input_token.21 : Tensor = aten::argmax(%214, %226, %227) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:25:0\n\t\t?                                    ^^^^^^    ^    ^     ^                                                                      ^\n\t\t-   %969 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %979 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %970 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %980 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %971 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t+   %981 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     ^\n\t\t-   %972 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t+   %982 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     ^\n\t\t-   %973 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t+   %983 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?     ^\n\t\t-   %974 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t+   %984 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?     ^\n\t\t-   %975 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %985 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %976 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t+   %986 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?     ^\n\t\t-   %977 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      -\n\t\t+   %987 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?     +\n\t\t    %fc.21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.23 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.21 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.23 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.125 : Tensor = aten::unsqueeze(%input_token.21, %977), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t+   %input.125 : Tensor = aten::unsqueeze(%input_token.21, %987), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                            ^\n\t\t    %weight.107 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.23)\n\t\t-   %embedded.21 : Tensor = aten::embedding(%weight.107, %input.125, %975, %976, %976), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                      ^     ^     ^\n\t\t+   %embedded.21 : Tensor = aten::embedding(%weight.107, %input.125, %985, %986, %986), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                      ^     ^     ^\n\t\t    %V.21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.21)\n\t\t    %W2.21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.21)\n\t\t    %W1.21 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.21)\n\t\t-   %988 : Tensor = aten::select(%200, %972, %975), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      -                           ^^    ^     ^\n\t\t+   %998 : Tensor = aten::select(%215, %982, %985), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?     +                            ^^    ^     ^\n\t\t-   %input.127 : Tensor = aten::unsqueeze(%988, %977), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t+   %input.127 : Tensor = aten::unsqueeze(%998, %987), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                           ^     ^\n\t\t    %bias.81 : Tensor = prim::GetAttr[name=\"bias\"](%W1.21)\n\t\t    %weight.109 : Tensor = prim::GetAttr[name=\"weight\"](%W1.21)\n\t\t-   %992 : Tensor = aten::linear(%30, %weight.109, %bias.81), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?    ^^\n\t\t+   %1002 : Tensor = aten::linear(%30, %weight.109, %bias.81), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?    ^^^\n\t\t    %bias.83 : Tensor = prim::GetAttr[name=\"bias\"](%W2.21)\n\t\t    %weight.111 : Tensor = prim::GetAttr[name=\"weight\"](%W2.21)\n\t\t-   %995 : Tensor = aten::linear(%input.127, %weight.111, %bias.83), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?    ^^\n\t\t+   %1005 : Tensor = aten::linear(%input.127, %weight.111, %bias.83), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?    ^^^\n\t\t-   %996 : Tensor = aten::add(%992, %995, %977), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?    ^^                        ^^     ^^^^^^^\n\t\t+   %1006 : Tensor = aten::add(%1002, %1005, %987), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?    ^^^                        ^^^   +++++++  ^\n\t\t-   %input.129 : Tensor = aten::tanh(%996), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^^\n\t\t+   %input.129 : Tensor = aten::tanh(%1006), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                     ^^^\n\t\t    %bias.85 : Tensor = prim::GetAttr[name=\"bias\"](%V.21)\n\t\t    %weight.113 : Tensor = prim::GetAttr[name=\"weight\"](%V.21)\n\t\t    %input.131 : Tensor = aten::linear(%input.129, %weight.113, %bias.85), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1001 : Tensor = aten::softmax(%input.131, %977, %973), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      -                                         ^     ^\n\t\t+   %1011 : Tensor = aten::softmax(%input.131, %987, %983), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?       +                                        ^     ^\n\t\t-   %attention_weights.21 : Tensor = aten::transpose(%1001, %977, %974), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^     ^     ^\n\t\t+   %attention_weights.21 : Tensor = aten::transpose(%1011, %987, %984), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^     ^     ^\n\t\t    %context.21 : Tensor = aten::bmm(%attention_weights.21, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %1004 : Tensor[] = prim::ListConstruct(%embedded.21, %context.21), scope: __module.decoder\n\t\t?      ^\n\t\t+   %1014 : Tensor[] = prim::ListConstruct(%embedded.21, %context.21), scope: __module.decoder\n\t\t?      ^\n\t\t-   %input.133 : Tensor = aten::cat(%1004, %974), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^     ^\n\t\t+   %input.133 : Tensor = aten::cat(%1014, %984), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^     ^\n\t\t    %bias_hh_l2.23 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.23)\n\t\t    %bias_ih_l2.23 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.23)\n\t\t    %weight_hh_l2.23 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.23)\n\t\t    %weight_ih_l2.23 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.23)\n\t\t    %bias_hh_l1.23 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.23)\n\t\t    %bias_ih_l1.23 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.23)\n\t\t    %weight_hh_l1.23 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.23)\n\t\t    %weight_ih_l1.23 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.23)\n\t\t    %bias_hh_l0.23 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.23)\n\t\t    %bias_ih_l0.23 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.23)\n\t\t    %weight_hh_l0.23 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.23)\n\t\t    %weight_ih_l0.23 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.23)\n\t\t-   %1018 : Tensor[] = prim::ListConstruct(%weight_ih_l0.23, %weight_hh_l0.23, %bias_ih_l0.23, %bias_hh_l0.23, %weight_ih_l1.23, %weight_hh_l1.23, %bias_ih_l1.23, %bias_hh_l1.23, %weight_ih_l2.23, %weight_hh_l2.23, %bias_ih_l2.23, %bias_hh_l2.23), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^\n\t\t+   %1028 : Tensor[] = prim::ListConstruct(%weight_ih_l0.23, %weight_hh_l0.23, %bias_ih_l0.23, %bias_hh_l0.23, %weight_ih_l1.23, %weight_hh_l1.23, %bias_ih_l1.23, %bias_hh_l1.23, %weight_ih_l2.23, %weight_hh_l2.23, %bias_ih_l2.23, %bias_hh_l2.23), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^\n\t\t-   %output.41 : Tensor, %decoder_hidden.23 : Tensor = aten::gru(%input.133, %200, %1018, %969, %970, %971, %976, %976, %969), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^^^^^^^ ^^    ------------------------\n\t\t+   %output.41 : Tensor, %decoder_hidden.23 : Tensor = aten::gru(%input.133, %215, %1028, %979, %980, %981, %986, %986, %979), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^\n\t\t-   %1021 : (Tensor, Tensor) = prim::TupleConstruct(%output.41, %decoder_hidden.23)\n\t\t?      ^\n\t\t+   %1031 : (Tensor, Tensor) = prim::TupleConstruct(%output.41, %decoder_hidden.23)\n\t\t?      ^\n\t\t-   %1022 : Tensor, %1023 : Tensor = prim::TupleUnpack(%1021)\n\t\t?       -              -                                  ^\n\t\t+   %1032 : Tensor, %1033 : Tensor = prim::TupleUnpack(%1031)\n\t\t?      +                +                                 ^\n\t\t-   %1024 : Tensor = aten::squeeze(%1022, %977), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                              ^     ^\n\t\t+   %1034 : Tensor = aten::squeeze(%1032, %987), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                              ^     ^\n\t\t-   %1025 : Tensor = aten::squeeze(%context.21, %977), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                          ^\n\t\t+   %1035 : Tensor = aten::squeeze(%context.21, %987), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                          ^\n\t\t-   %1026 : Tensor = aten::squeeze(%embedded.21, %977), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                           ^\n\t\t+   %1036 : Tensor = aten::squeeze(%embedded.21, %987), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                           ^\n\t\t-   %1027 : Tensor[] = prim::ListConstruct(%1024, %1025, %1026), scope: __module.decoder\n\t\t?      ^                                      ^      ^      ^\n\t\t+   %1037 : Tensor[] = prim::ListConstruct(%1034, %1035, %1036), scope: __module.decoder\n\t\t?      ^                                      ^      ^      ^\n\t\t-   %input.135 : Tensor = aten::cat(%1027, %977), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                      ^     ^\n\t\t+   %input.135 : Tensor = aten::cat(%1037, %987), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                      ^     ^\n\t\t    %bias.87 : Tensor = prim::GetAttr[name=\"bias\"](%fc.21)\n\t\t    %weight.115 : Tensor = prim::GetAttr[name=\"weight\"](%fc.21)\n\t\t    %output.43 : Tensor = aten::linear(%input.135, %weight.115, %bias.87), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1032 : (Tensor, Tensor) = prim::TupleConstruct(%output.43, %1023)\n\t\t?      ^                                                           ^\n\t\t+   %1042 : (Tensor, Tensor) = prim::TupleConstruct(%output.43, %1033)\n\t\t?      ^                                                           ^\n\t\t-   %220 : Tensor, %221 : Tensor = prim::TupleUnpack(%1032)\n\t\t?     ^              ^                                  ^\n\t\t+   %230 : Tensor, %231 : Tensor = prim::TupleUnpack(%1042)\n\t\t?     ^              ^                                  ^\n\t\t-   %222 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -\n\t\t+   %232 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +\n\t\t-   %223 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %233 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %224 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %234 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %225 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %235 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %226 : Tensor = aten::slice(%outputs, %222, %223, %224, %225) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^           ^^^^^^^\n\t\t+   %236 : Tensor = aten::slice(%outputs, %232, %233, %234, %235) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     +++++  +    ^\n\t\t-   %227 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %237 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %228 : int = prim::Constant[value=11]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %238 : int = prim::Constant[value=11]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %229 : Tensor = aten::select(%226, %227, %228) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t+   %239 : Tensor = aten::select(%236, %237, %238) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t-   %230 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t+   %240 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t-   %231 : Tensor = aten::copy_(%229, %220, %230) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^  ------\n\t\t+   %241 : Tensor = aten::copy_(%239, %230, %240) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^       ++++++\n\t\t-   %232 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %242 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %233 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      -\n\t\t+   %243 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     +\n\t\t-   %234 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     -\n\t\t+   %244 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      +\n\t\t-   %235 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %245 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %236 : Tensor = aten::slice(%trg, %232, %233, %234, %235) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                                 ^     ^     ^     ^\n\t\t+   %246 : Tensor = aten::slice(%trg, %242, %243, %244, %245) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                                 ^     ^     ^     ^\n\t\t-   %237 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %247 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %238 : int = prim::Constant[value=11]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %248 : int = prim::Constant[value=11]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %input_token.23 : Tensor = aten::select(%236, %237, %238) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^     ^     ^\n\t\t+   %input_token.23 : Tensor = aten::select(%246, %247, %248) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^     ^     ^\n\t\t-   %1033 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?       -\n\t\t+   %1043 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      +\n\t\t-   %1034 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %1044 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?       +\n\t\t-   %1035 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t+   %1045 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t-   %1036 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^\n\t\t+   %1046 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^\n\t\t-   %1037 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      ^\n\t\t+   %1047 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      ^\n\t\t-   %1038 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      ^\n\t\t+   %1048 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      ^\n\t\t-   %1039 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t+   %1049 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t-   %1040 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t+   %1050 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t-   %1041 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t+   %1051 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t    %fc.23 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.25 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.23 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.25 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.137 : Tensor = aten::unsqueeze(%input_token.23, %1041), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                             ^\n\t\t+   %input.137 : Tensor = aten::unsqueeze(%input_token.23, %1051), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                             ^\n\t\t    %weight.117 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.25)\n\t\t-   %embedded.23 : Tensor = aten::embedding(%weight.117, %input.137, %1039, %1040, %1040), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                       ^      ^^^^^^^^\n\t\t+   %embedded.23 : Tensor = aten::embedding(%weight.117, %input.137, %1049, %1050, %1050), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                       ^      ^^^^^^^^\n\t\t    %V.23 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.23)\n\t\t    %W2.23 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.23)\n\t\t    %W1.23 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.23)\n\t\t-   %1052 : Tensor = aten::select(%221, %1036, %1039), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t+   %1062 : Tensor = aten::select(%231, %1046, %1049), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t-   %input.139 : Tensor = aten::unsqueeze(%1052, %1041), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t+   %input.139 : Tensor = aten::unsqueeze(%1062, %1051), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t    %bias.89 : Tensor = prim::GetAttr[name=\"bias\"](%W1.23)\n\t\t    %weight.119 : Tensor = prim::GetAttr[name=\"weight\"](%W1.23)\n\t\t-   %1056 : Tensor = aten::linear(%30, %weight.119, %bias.89), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      - ^^\n\t\t+   %1066 : Tensor = aten::linear(%30, %weight.119, %bias.89), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?       ^^^\n\t\t    %bias.91 : Tensor = prim::GetAttr[name=\"bias\"](%W2.23)\n\t\t    %weight.121 : Tensor = prim::GetAttr[name=\"weight\"](%W2.23)\n\t\t-   %1059 : Tensor = aten::linear(%input.139, %weight.121, %bias.91), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t+   %1069 : Tensor = aten::linear(%input.139, %weight.121, %bias.91), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t-   %1060 : Tensor = aten::add(%1056, %1059, %1041), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      ^                          ^       -------\n\t\t+   %1070 : Tensor = aten::add(%1066, %1069, %1051), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      ^                          ^  +++++++\n\t\t-   %input.141 : Tensor = aten::tanh(%1060), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t+   %input.141 : Tensor = aten::tanh(%1070), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t    %bias.93 : Tensor = prim::GetAttr[name=\"bias\"](%V.23)\n\t\t    %weight.123 : Tensor = prim::GetAttr[name=\"weight\"](%V.23)\n\t\t    %input.143 : Tensor = aten::linear(%input.141, %weight.123, %bias.93), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1065 : Tensor = aten::softmax(%input.143, %1041, %1037), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      ^                                           -------\n\t\t+   %1075 : Tensor = aten::softmax(%input.143, %1051, %1047), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      ^                                       +++++++\n\t\t-   %attention_weights.23 : Tensor = aten::transpose(%1065, %1041, %1038), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^       -------\n\t\t+   %attention_weights.23 : Tensor = aten::transpose(%1075, %1051, %1048), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^  +++++++\n\t\t    %context.23 : Tensor = aten::bmm(%attention_weights.23, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %1068 : Tensor[] = prim::ListConstruct(%embedded.23, %context.23), scope: __module.decoder\n\t\t?      ^\n\t\t+   %1078 : Tensor[] = prim::ListConstruct(%embedded.23, %context.23), scope: __module.decoder\n\t\t?      ^\n\t\t-   %input.145 : Tensor = aten::cat(%1068, %1038), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^      ^\n\t\t+   %input.145 : Tensor = aten::cat(%1078, %1048), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^      ^\n\t\t    %bias_hh_l2.25 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.25)\n\t\t    %bias_ih_l2.25 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.25)\n\t\t    %weight_hh_l2.25 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.25)\n\t\t    %weight_ih_l2.25 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.25)\n\t\t    %bias_hh_l1.25 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.25)\n\t\t    %bias_ih_l1.25 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.25)\n\t\t    %weight_hh_l1.25 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.25)\n\t\t    %weight_ih_l1.25 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.25)\n\t\t    %bias_hh_l0.25 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.25)\n\t\t    %bias_ih_l0.25 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.25)\n\t\t    %weight_hh_l0.25 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.25)\n\t\t    %weight_ih_l0.25 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.25)\n\t\t-   %1082 : Tensor[] = prim::ListConstruct(%weight_ih_l0.25, %weight_hh_l0.25, %bias_ih_l0.25, %bias_hh_l0.25, %weight_ih_l1.25, %weight_hh_l1.25, %bias_ih_l1.25, %bias_hh_l1.25, %weight_ih_l2.25, %weight_hh_l2.25, %bias_ih_l2.25, %bias_hh_l2.25), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^^\n\t\t+   %1092 : Tensor[] = prim::ListConstruct(%weight_ih_l0.25, %weight_hh_l0.25, %bias_ih_l0.25, %bias_hh_l0.25, %weight_ih_l1.25, %weight_hh_l1.25, %bias_ih_l1.25, %bias_hh_l1.25, %weight_ih_l2.25, %weight_hh_l2.25, %bias_ih_l2.25, %bias_hh_l2.25), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^^\n\t\t-   %output.45 : Tensor, %decoder_hidden.25 : Tensor = aten::gru(%input.145, %221, %1082, %1033, %1034, %1035, %1040, %1040, %1033), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.45 : Tensor, %decoder_hidden.25 : Tensor = aten::gru(%input.145, %231, %1092, %1043, %1044, %1045, %1050, %1050, %1043), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                              ++++++++ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1085 : (Tensor, Tensor) = prim::TupleConstruct(%output.45, %decoder_hidden.25)\n\t\t?      ^\n\t\t+   %1095 : (Tensor, Tensor) = prim::TupleConstruct(%output.45, %decoder_hidden.25)\n\t\t?      ^\n\t\t-   %1086 : Tensor, %1087 : Tensor = prim::TupleUnpack(%1085)\n\t\t?      ^               ^                                  ^\n\t\t+   %1096 : Tensor, %1097 : Tensor = prim::TupleUnpack(%1095)\n\t\t?      ^               ^                                  ^\n\t\t-   %1088 : Tensor = aten::squeeze(%1086, %1041), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?       -                             ^      ^\n\t\t+   %1098 : Tensor = aten::squeeze(%1096, %1051), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      +                              ^      ^\n\t\t-   %1089 : Tensor = aten::squeeze(%context.23, %1041), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      -                                           ^\n\t\t+   %1099 : Tensor = aten::squeeze(%context.23, %1051), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?       +                                          ^\n\t\t-   %1090 : Tensor = aten::squeeze(%embedded.23, %1041), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      -                                            ^\n\t\t+   %1100 : Tensor = aten::squeeze(%embedded.23, %1051), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?     +                                             ^\n\t\t-   %1091 : Tensor[] = prim::ListConstruct(%1088, %1089, %1090), scope: __module.decoder\n\t\t?      -                                      ^  -------\n\t\t+   %1101 : Tensor[] = prim::ListConstruct(%1098, %1099, %1100), scope: __module.decoder\n\t\t?     +                                       ^       +++++++\n\t\t-   %input.147 : Tensor = aten::cat(%1091, %1041), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                      -      ^\n\t\t+   %input.147 : Tensor = aten::cat(%1101, %1051), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                     +       ^\n\t\t    %bias.95 : Tensor = prim::GetAttr[name=\"bias\"](%fc.23)\n\t\t    %weight.125 : Tensor = prim::GetAttr[name=\"weight\"](%fc.23)\n\t\t    %output.47 : Tensor = aten::linear(%input.147, %weight.125, %bias.95), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1096 : (Tensor, Tensor) = prim::TupleConstruct(%output.47, %1087)\n\t\t?      -                                                           ^\n\t\t+   %1106 : (Tensor, Tensor) = prim::TupleConstruct(%output.47, %1097)\n\t\t?     +                                                            ^\n\t\t-   %241 : Tensor, %242 : Tensor = prim::TupleUnpack(%1096)\n\t\t?     ^              ^                                  -\n\t\t+   %251 : Tensor, %252 : Tensor = prim::TupleUnpack(%1106)\n\t\t?     ^              ^                                 +\n\t\t-   %243 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %253 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %244 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -\n\t\t+   %254 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +\n\t\t-   %245 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %255 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %246 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %256 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %247 : Tensor = aten::slice(%outputs, %243, %244, %245, %246) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t+   %257 : Tensor = aten::slice(%outputs, %253, %254, %255, %256) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t-   %248 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %258 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %249 : int = prim::Constant[value=12]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %259 : int = prim::Constant[value=12]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %250 : Tensor = aten::select(%247, %248, %249) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t+   %260 : Tensor = aten::select(%257, %258, %259) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^     ^     ^\n\t\t-   %251 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t+   %261 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t-   %252 : Tensor = aten::copy_(%250, %241, %251) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^  ------\n\t\t+   %262 : Tensor = aten::copy_(%260, %251, %261) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^       ++++++\n\t\t-   %253 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %263 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %254 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %264 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %255 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      -\n\t\t+   %265 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     +\n\t\t-   %256 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     -\n\t\t+   %266 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      +\n\t\t-   %257 : Tensor = aten::slice(%trg, %253, %254, %255, %256) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                                 ^     ^     ^     ^\n\t\t+   %267 : Tensor = aten::slice(%trg, %263, %264, %265, %266) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^                                 ^     ^     ^     ^\n\t\t-   %258 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %268 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %259 : int = prim::Constant[value=12]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %269 : int = prim::Constant[value=12]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %input_token.25 : Tensor = aten::select(%257, %258, %259) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^     ^     ^\n\t\t+   %input_token.25 : Tensor = aten::select(%267, %268, %269) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                             ^     ^     ^\n\t\t-   %1097 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %1107 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     +\n\t\t-   %1098 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      -\n\t\t+   %1108 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?     +\n\t\t-   %1099 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?       -\n\t\t+   %1109 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?    +\n\t\t-   %1100 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?       -\n\t\t+   %1110 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      +\n\t\t-   %1101 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      -\n\t\t+   %1111 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?       +\n\t\t-   %1102 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      ^\n\t\t+   %1112 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      ^\n\t\t-   %1103 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t+   %1113 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t-   %1104 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t+   %1114 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t-   %1105 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t+   %1115 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t    %fc.25 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn.27 : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention.25 : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding.27 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.149 : Tensor = aten::unsqueeze(%input_token.25, %1105), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                             ^\n\t\t+   %input.149 : Tensor = aten::unsqueeze(%input_token.25, %1115), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                             ^\n\t\t    %weight.127 : Tensor = prim::GetAttr[name=\"weight\"](%embedding.27)\n\t\t-   %embedded.25 : Tensor = aten::embedding(%weight.127, %input.149, %1103, %1104, %1104), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                       ^      ^^^^^^^^\n\t\t+   %embedded.25 : Tensor = aten::embedding(%weight.127, %input.149, %1113, %1114, %1114), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                       ^      ^^^^^^^^\n\t\t    %V.25 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention.25)\n\t\t    %W2.25 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention.25)\n\t\t    %W1.25 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention.25)\n\t\t-   %1116 : Tensor = aten::select(%242, %1100, %1103), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t+   %1126 : Tensor = aten::select(%252, %1110, %1113), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t-   %input.151 : Tensor = aten::unsqueeze(%1116, %1105), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t+   %input.151 : Tensor = aten::unsqueeze(%1126, %1115), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t    %bias.97 : Tensor = prim::GetAttr[name=\"bias\"](%W1.25)\n\t\t    %weight.129 : Tensor = prim::GetAttr[name=\"weight\"](%W1.25)\n\t\t-   %1120 : Tensor = aten::linear(%30, %weight.129, %bias.97), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^^\n\t\t+   %1130 : Tensor = aten::linear(%30, %weight.129, %bias.97), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^^\n\t\t    %bias.99 : Tensor = prim::GetAttr[name=\"bias\"](%W2.25)\n\t\t    %weight.131 : Tensor = prim::GetAttr[name=\"weight\"](%W2.25)\n\t\t-   %1123 : Tensor = aten::linear(%input.151, %weight.131, %bias.99), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^^\n\t\t+   %1133 : Tensor = aten::linear(%input.151, %weight.131, %bias.99), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^^^^\n\t\t-   %1124 : Tensor = aten::add(%1120, %1123, %1105), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      ^                          ^      ^      ^\n\t\t+   %1134 : Tensor = aten::add(%1130, %1133, %1115), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      ^                          ^      ^      ^\n\t\t-   %input.153 : Tensor = aten::tanh(%1124), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t+   %input.153 : Tensor = aten::tanh(%1134), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t    %bias.101 : Tensor = prim::GetAttr[name=\"bias\"](%V.25)\n\t\t    %weight.133 : Tensor = prim::GetAttr[name=\"weight\"](%V.25)\n\t\t    %input.155 : Tensor = aten::linear(%input.153, %weight.133, %bias.101), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1129 : Tensor = aten::softmax(%input.155, %1105, %1101), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      ^                                          ^      ^\n\t\t+   %1139 : Tensor = aten::softmax(%input.155, %1115, %1111), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?      ^                                          ^      ^\n\t\t-   %attention_weights.25 : Tensor = aten::transpose(%1129, %1105, %1102), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^      ^      ^\n\t\t+   %attention_weights.25 : Tensor = aten::transpose(%1139, %1115, %1112), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                       ^      ^      ^\n\t\t    %context.25 : Tensor = aten::bmm(%attention_weights.25, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %1132 : Tensor[] = prim::ListConstruct(%embedded.25, %context.25), scope: __module.decoder\n\t\t?      ^\n\t\t+   %1142 : Tensor[] = prim::ListConstruct(%embedded.25, %context.25), scope: __module.decoder\n\t\t?      ^\n\t\t-   %input.157 : Tensor = aten::cat(%1132, %1102), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^      ^\n\t\t+   %input.157 : Tensor = aten::cat(%1142, %1112), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                      ^      ^\n\t\t    %bias_hh_l2.27 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn.27)\n\t\t    %bias_ih_l2.27 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn.27)\n\t\t    %weight_hh_l2.27 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn.27)\n\t\t    %weight_ih_l2.27 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn.27)\n\t\t    %bias_hh_l1.27 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn.27)\n\t\t    %bias_ih_l1.27 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn.27)\n\t\t    %weight_hh_l1.27 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn.27)\n\t\t    %weight_ih_l1.27 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn.27)\n\t\t    %bias_hh_l0.27 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn.27)\n\t\t    %bias_ih_l0.27 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn.27)\n\t\t    %weight_hh_l0.27 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn.27)\n\t\t    %weight_ih_l0.27 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn.27)\n\t\t-   %1146 : Tensor[] = prim::ListConstruct(%weight_ih_l0.27, %weight_hh_l0.27, %bias_ih_l0.27, %bias_hh_l0.27, %weight_ih_l1.27, %weight_hh_l1.27, %bias_ih_l1.27, %bias_hh_l1.27, %weight_ih_l2.27, %weight_hh_l2.27, %bias_ih_l2.27, %bias_hh_l2.27), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^\n\t\t+   %1156 : Tensor[] = prim::ListConstruct(%weight_ih_l0.27, %weight_hh_l0.27, %bias_ih_l0.27, %bias_hh_l0.27, %weight_ih_l1.27, %weight_hh_l1.27, %bias_ih_l1.27, %bias_hh_l1.27, %weight_ih_l2.27, %weight_hh_l2.27, %bias_ih_l2.27, %bias_hh_l2.27), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^\n\t\t-   %output.49 : Tensor, %decoder_hidden : Tensor = aten::gru(%input.157, %242, %1146, %1097, %1098, %1099, %1104, %1104, %1097), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                           ^      ^       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %output.49 : Tensor, %decoder_hidden : Tensor = aten::gru(%input.157, %252, %1156, %1107, %1108, %1109, %1114, %1114, %1107), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                                                                           ^      ^    +++++++++++++++   ^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1149 : (Tensor, Tensor) = prim::TupleConstruct(%output.49, %decoder_hidden)\n\t\t?      ^\n\t\t+   %1159 : (Tensor, Tensor) = prim::TupleConstruct(%output.49, %decoder_hidden)\n\t\t?      ^\n\t\t-   %1150 : Tensor, %1151 : Tensor = prim::TupleUnpack(%1149)\n\t\t?      ^               ^                                  ^\n\t\t+   %1160 : Tensor, %1161 : Tensor = prim::TupleUnpack(%1159)\n\t\t?      ^               ^                                  ^\n\t\t-   %1152 : Tensor = aten::squeeze(%1150, %1105), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                              ^      ^\n\t\t+   %1162 : Tensor = aten::squeeze(%1160, %1115), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                              ^      ^\n\t\t-   %1153 : Tensor = aten::squeeze(%context.25, %1105), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                           ^\n\t\t+   %1163 : Tensor = aten::squeeze(%context.25, %1115), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                           ^\n\t\t-   %1154 : Tensor = aten::squeeze(%embedded.25, %1105), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                            ^\n\t\t+   %1164 : Tensor = aten::squeeze(%embedded.25, %1115), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                            ^\n\t\t-   %1155 : Tensor[] = prim::ListConstruct(%1152, %1153, %1154), scope: __module.decoder\n\t\t?       -                                     ^      ^      ^\n\t\t+   %1165 : Tensor[] = prim::ListConstruct(%1162, %1163, %1164), scope: __module.decoder\n\t\t?      +                                      ^      ^      ^\n\t\t-   %input.159 : Tensor = aten::cat(%1155, %1105), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                      ^      ^\n\t\t+   %input.159 : Tensor = aten::cat(%1165, %1115), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                      ^      ^\n\t\t    %bias.103 : Tensor = prim::GetAttr[name=\"bias\"](%fc.25)\n\t\t    %weight.135 : Tensor = prim::GetAttr[name=\"weight\"](%fc.25)\n\t\t    %output.51 : Tensor = aten::linear(%input.159, %weight.135, %bias.103), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1160 : (Tensor, Tensor) = prim::TupleConstruct(%output.51, %1151)\n\t\t?      ^                                                           ^\n\t\t+   %1170 : (Tensor, Tensor) = prim::TupleConstruct(%output.51, %1161)\n\t\t?      ^                                                           ^\n\t\t-   %262 : Tensor, %263 : Tensor = prim::TupleUnpack(%1160)\n\t\t?     ^              ^                                  ^\n\t\t+   %272 : Tensor, %273 : Tensor = prim::TupleUnpack(%1170)\n\t\t?     ^              ^                                  ^\n\t\t-   %264 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %274 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %265 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %275 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %266 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -\n\t\t+   %276 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +\n\t\t-   %267 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %277 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %268 : Tensor = aten::slice(%outputs, %264, %265, %266, %267) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t+   %278 : Tensor = aten::slice(%outputs, %274, %275, %276, %277) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t-   %269 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %279 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %270 : int = prim::Constant[value=13]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %280 : int = prim::Constant[value=13]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %271 : Tensor = aten::select(%268, %269, %270) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^  ------\n\t\t+   %281 : Tensor = aten::select(%278, %279, %280) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                            ^      ++++++\n\t\t-   %272 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t+   %282 : bool = prim::Constant[value=0]()\n\t\t?     ^\n\t\t-   %273 : Tensor = aten::copy_(%271, %262, %272) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^  ------\n\t\t+   %283 : Tensor = aten::copy_(%281, %272, %282) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                           ^       ++++++\n\t\t-   %274 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %284 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %275 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %285 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %276 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %286 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %277 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      -\n\t\t+   %287 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     +\n\t\t-   %278 : Tensor = aten::slice(%trg, %274, %275, %276, %277) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     -                                 ^     ^     ^     ^\n\t\t+   %288 : Tensor = aten::slice(%trg, %284, %285, %286, %287) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?      +                                ^     ^     ^     ^\n\t\t-   %279 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %289 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %280 : int = prim::Constant[value=13]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t+   %290 : int = prim::Constant[value=13]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?     ^\n\t\t-   %input_token : Tensor = aten::select(%278, %279, %280) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                          ^  ------\n\t\t+   %input_token : Tensor = aten::select(%288, %289, %290) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:26:0\n\t\t?                                          ^      ++++++\n\t\t-   %1161 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t+   %1171 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t-   %1162 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t+   %1172 : int = prim::Constant[value=3](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t-   %1163 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t+   %1173 : float = prim::Constant[value=0.](), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?      ^\n\t\t-   %1164 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^\n\t\t+   %1174 : int = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^\n\t\t-   %1165 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      ^\n\t\t+   %1175 : NoneType = prim::Constant(), scope: __module.decoder/__module.decoder.attention\n\t\t?      ^\n\t\t-   %1166 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?       -\n\t\t+   %1176 : int = prim::Constant[value=2](), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?      +\n\t\t-   %1167 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      -\n\t\t+   %1177 : int = prim::Constant[value=-1](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?       +\n\t\t-   %1168 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t+   %1178 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?      ^\n\t\t-   %1169 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t+   %1179 : int = prim::Constant[value=1](), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?      ^\n\t\t    %fc : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"fc\"](%decoder)\n\t\t    %rnn : __torch__.torch.nn.modules.rnn.GRU = prim::GetAttr[name=\"rnn\"](%decoder)\n\t\t    %attention : __torch__.BahdanauAttention = prim::GetAttr[name=\"attention\"](%decoder)\n\t\t    %embedding : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"embedding\"](%decoder)\n\t\t-   %input.161 : Tensor = aten::unsqueeze(%input_token, %1169), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t+   %input.161 : Tensor = aten::unsqueeze(%input_token, %1179), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:13:0\n\t\t?                                                          ^\n\t\t    %weight.137 : Tensor = prim::GetAttr[name=\"weight\"](%embedding)\n\t\t-   %embedded : Tensor = aten::embedding(%weight.137, %input.161, %1167, %1168, %1168), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^^^^^^^^      ^\n\t\t+   %embedded : Tensor = aten::embedding(%weight.137, %input.161, %1177, %1178, %1178), scope: __module.decoder/__module.decoder.embedding # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2542:0\n\t\t?                                                                    ^^^^^^^^      ^\n\t\t    %V : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"V\"](%attention)\n\t\t    %W2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W2\"](%attention)\n\t\t    %W1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"W1\"](%attention)\n\t\t-   %1180 : Tensor = aten::select(%263, %1164, %1167), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t+   %1190 : Tensor = aten::select(%273, %1174, %1177), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?      ^                            ^      ^      ^\n\t\t-   %input.163 : Tensor = aten::unsqueeze(%1180, %1169), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t+   %input.163 : Tensor = aten::unsqueeze(%1190, %1179), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:13:0\n\t\t?                                            ^      ^\n\t\t    %bias.105 : Tensor = prim::GetAttr[name=\"bias\"](%W1)\n\t\t    %weight.139 : Tensor = prim::GetAttr[name=\"weight\"](%W1)\n\t\t-   %1184 : Tensor = aten::linear(%30, %weight.139, %bias.105), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t+   %1194 : Tensor = aten::linear(%30, %weight.139, %bias.105), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W1 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t    %bias.107 : Tensor = prim::GetAttr[name=\"bias\"](%W2)\n\t\t    %weight.141 : Tensor = prim::GetAttr[name=\"weight\"](%W2)\n\t\t-   %1187 : Tensor = aten::linear(%input.163, %weight.141, %bias.107), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t+   %1197 : Tensor = aten::linear(%input.163, %weight.141, %bias.107), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.W2 # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t?      ^\n\t\t-   %1188 : Tensor = aten::add(%1184, %1187, %1169), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?       -                         ^      ^      ^\n\t\t+   %1198 : Tensor = aten::add(%1194, %1197, %1179), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?      +                          ^      ^      ^\n\t\t-   %input.165 : Tensor = aten::tanh(%1188), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t+   %input.165 : Tensor = aten::tanh(%1198), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:17:0\n\t\t?                                       ^\n\t\t    %bias.109 : Tensor = prim::GetAttr[name=\"bias\"](%V)\n\t\t    %weight.143 : Tensor = prim::GetAttr[name=\"weight\"](%V)\n\t\t    %input.167 : Tensor = aten::linear(%input.165, %weight.143, %bias.109), scope: __module.decoder/__module.decoder.attention/__module.decoder.attention.V # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %1193 : Tensor = aten::softmax(%input.167, %1169, %1165), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^^                                          ^      ^\n\t\t+   %1203 : Tensor = aten::softmax(%input.167, %1179, %1175), scope: __module.decoder/__module.decoder.attention # c:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2133:0\n\t\t?     ^^                                          ^      ^\n\t\t-   %attention_weights : Tensor = aten::transpose(%1193, %1169, %1166), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                   ^^      ^      ^\n\t\t+   %attention_weights : Tensor = aten::transpose(%1203, %1179, %1176), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:20:0\n\t\t?                                                   ^^      ^      ^\n\t\t    %context : Tensor = aten::bmm(%attention_weights, %30), scope: __module.decoder/__module.decoder.attention # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\722348354.py:23:0\n\t\t-   %1196 : Tensor[] = prim::ListConstruct(%embedded, %context), scope: __module.decoder\n\t\t?     ^^\n\t\t+   %1206 : Tensor[] = prim::ListConstruct(%embedded, %context), scope: __module.decoder\n\t\t?     ^^\n\t\t-   %input.169 : Tensor = aten::cat(%1196, %1166), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^^      ^\n\t\t+   %input.169 : Tensor = aten::cat(%1206, %1176), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:20:0\n\t\t?                                     ^^      ^\n\t\t    %bias_hh_l2 : Tensor = prim::GetAttr[name=\"bias_hh_l2\"](%rnn)\n\t\t    %bias_ih_l2 : Tensor = prim::GetAttr[name=\"bias_ih_l2\"](%rnn)\n\t\t    %weight_hh_l2 : Tensor = prim::GetAttr[name=\"weight_hh_l2\"](%rnn)\n\t\t    %weight_ih_l2 : Tensor = prim::GetAttr[name=\"weight_ih_l2\"](%rnn)\n\t\t    %bias_hh_l1 : Tensor = prim::GetAttr[name=\"bias_hh_l1\"](%rnn)\n\t\t    %bias_ih_l1 : Tensor = prim::GetAttr[name=\"bias_ih_l1\"](%rnn)\n\t\t    %weight_hh_l1 : Tensor = prim::GetAttr[name=\"weight_hh_l1\"](%rnn)\n\t\t    %weight_ih_l1 : Tensor = prim::GetAttr[name=\"weight_ih_l1\"](%rnn)\n\t\t    %bias_hh_l0 : Tensor = prim::GetAttr[name=\"bias_hh_l0\"](%rnn)\n\t\t    %bias_ih_l0 : Tensor = prim::GetAttr[name=\"bias_ih_l0\"](%rnn)\n\t\t    %weight_hh_l0 : Tensor = prim::GetAttr[name=\"weight_hh_l0\"](%rnn)\n\t\t    %weight_ih_l0 : Tensor = prim::GetAttr[name=\"weight_ih_l0\"](%rnn)\n\t\t-   %1210 : Tensor[] = prim::ListConstruct(%weight_ih_l0, %weight_hh_l0, %bias_ih_l0, %bias_hh_l0, %weight_ih_l1, %weight_hh_l1, %bias_ih_l1, %bias_hh_l1, %weight_ih_l2, %weight_hh_l2, %bias_ih_l2, %bias_hh_l2), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^^\n\t\t+   %1220 : Tensor[] = prim::ListConstruct(%weight_ih_l0, %weight_hh_l0, %bias_ih_l0, %bias_hh_l0, %weight_ih_l1, %weight_hh_l1, %bias_ih_l1, %bias_hh_l1, %weight_ih_l2, %weight_hh_l2, %bias_ih_l2, %bias_hh_l2), scope: __module.decoder/__module.decoder.rnn\n\t\t?      ^^^^\n\t\t-   %output.53 : Tensor, %1212 : Tensor = aten::gru(%input.169, %263, %1210, %1161, %1162, %1163, %1168, %1168, %1161), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                           ^^^^                                  ^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^      ^      ^\n\t\t+   %output.53 : Tensor, %1222 : Tensor = aten::gru(%input.169, %273, %1220, %1171, %1172, %1173, %1178, %1178, %1171), scope: __module.decoder/__module.decoder.rnn # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1394:0\n\t\t?                           ^^^^                                  ^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^      ^      ^\n\t\t-   %1213 : Tensor = aten::squeeze(%output.53, %1169), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                          ^\n\t\t+   %1223 : Tensor = aten::squeeze(%output.53, %1179), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                          ^\n\t\t-   %1214 : Tensor = aten::squeeze(%context, %1169), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                        ^\n\t\t+   %1224 : Tensor = aten::squeeze(%context, %1179), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                        ^\n\t\t-   %1215 : Tensor = aten::squeeze(%embedded, %1169), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                         ^\n\t\t+   %1225 : Tensor = aten::squeeze(%embedded, %1179), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?      ^                                         ^\n\t\t-   %1216 : Tensor[] = prim::ListConstruct(%1213, %1214, %1215), scope: __module.decoder\n\t\t?      ^                                      ^      ^      ^\n\t\t+   %1226 : Tensor[] = prim::ListConstruct(%1223, %1224, %1225), scope: __module.decoder\n\t\t?      ^                                      ^      ^      ^\n\t\t-   %input : Tensor = aten::cat(%1216, %1169), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                  ^      ^\n\t\t+   %input : Tensor = aten::cat(%1226, %1179), scope: __module.decoder # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\2222485363.py:26:0\n\t\t?                                  ^      ^\n\t\t    %bias : Tensor = prim::GetAttr[name=\"bias\"](%fc)\n\t\t    %weight : Tensor = prim::GetAttr[name=\"weight\"](%fc)\n\t\t    %output : Tensor = aten::linear(%input, %weight, %bias), scope: __module.decoder/__module.decoder.fc # c:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134:0\n\t\t-   %283 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %293 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %284 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %294 : int = prim::Constant[value=0]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %285 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %295 : int = prim::Constant[value=9223372036854775807]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %286 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t+   %296 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^\n\t\t-   %287 : Tensor = aten::slice(%outputs, %283, %284, %285, %286) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t+   %297 : Tensor = aten::slice(%outputs, %293, %294, %295, %296) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     ^                                     ^     ^     ^     ^\n\t\t-   %288 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      -\n\t\t+   %298 : int = prim::Constant[value=1]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     +\n\t\t-   %289 : int = prim::Constant[value=14]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     -\n\t\t+   %299 : int = prim::Constant[value=14]() # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?      +\n\t\t-   %290 : Tensor = aten::select(%287, %288, %289) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^^                            ^     ^     ^\n\t\t+   %300 : Tensor = aten::select(%297, %298, %299) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ^ +                           ^     ^     ^\n\t\t-   %291 : bool = prim::Constant[value=0]()\n\t\t?    ^^\n\t\t+   %301 : bool = prim::Constant[value=0]()\n\t\t?    ^^\n\t\t-   %292 : Tensor = aten::copy_(%290, %output, %291) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?     --                         ^^             ^^\n\t\t+   %302 : Tensor = aten::copy_(%300, %output, %301) # C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_15248\\3760564455.py:22:0\n\t\t?    ++                          ^^             ^^\n\t\t    return (%outputs)\n\tFirst diverging operator:\n\tNode diff:\n\t\t- %decoder : __torch__.___torch_mangle_67.Decoder = prim::GetAttr[name=\"decoder\"](%self.1)\n\t\t?                                      -\n\t\t+ %decoder : __torch__.___torch_mangle_79.Decoder = prim::GetAttr[name=\"decoder\"](%self.1)\n\t\t?                                       +\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(dataset)\n",
    "sample_batch = next(data_iter)\n",
    "X_sample = sample_batch['eng_input'].to(device)\n",
    "y_sample = sample_batch['hin_target'].to(device)\n",
    "writer.add_graph(model, [X_sample, y_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a35ebbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(43115, 128)\n",
       "    (rnn): GRU(128, 256, num_layers=3, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): BahdanauAttention(\n",
       "      (W1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (W2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (V): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "    (embedding): Embedding(43015, 128)\n",
       "    (rnn): GRU(384, 256, num_layers=3, batch_first=True)\n",
       "    (fc): Linear(in_features=640, out_features=43015, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # load saved weights and set model to evaluation mode\n",
    "checkpoint_path = \"models/Bahdanau_attention_model_epoch_10.pth\"\n",
    "state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "99830cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crition = nn.CrossEntropyLoss(ignore_index=hin_tokenizer.word_index[hin_tokenizer.padding_token])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "59e62a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    # print(f\"Model saved to {filepath}\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1732b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_lr(epoch, total_epochs, start_lr, end_lr):\n",
    "    \"\"\"\n",
    "    Calculates a linearly interpolated learning rate.\n",
    "    \"\"\"\n",
    "    if epoch >= total_epochs:\n",
    "        return end_lr\n",
    "    \n",
    "    # Formula: start + (end - start) * (progress)\n",
    "    lr = start_lr + (end_lr - start_lr) * (epoch / total_epochs)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d4859ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11:  84%|████████▎ | 458/547 [05:22<01:02,  1.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m X, y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meng_input\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhin_target\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m crition(logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))    \n\u001b[0;32m     14\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem(), epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(tqdm_bar) \u001b[38;5;241m+\u001b[39m i)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[161], line 13\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[1;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m     10\u001b[0m trg_len \u001b[38;5;241m=\u001b[39m trg\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39mout_features\n\u001b[1;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Get all encoder hidden states\u001b[39;00m\n\u001b[0;32m     16\u001b[0m encoder_outputs, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10, TOTAL_EPOCHS):\n",
    "    lr = get_linear_lr(epoch, TOTAL_EPOCHS, START_LR, END_LR)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    tqdm_bar = tqdm(dataset)\n",
    "\n",
    "    for i, batch in enumerate(tqdm_bar):\n",
    "        model.train()\n",
    "        # load batch to device\n",
    "        X, y = batch['eng_input'].to(device), batch['hin_target'].to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(X, y)\n",
    "        loss = crition(logits.view(-1, logits.size(-1)), y.view(-1))    \n",
    "        writer.add_scalar('Training Loss', loss.item(), epoch * len(tqdm_bar) + i)\n",
    "        writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch * len(tqdm_bar) + i)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        tqdm_bar.set_description(f\"Epoch: {epoch+1}\")\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    writer.add_histogram(f'Weights/{name}', param, global_step=i)\n",
    "                    # Logging gradients is also super helpful!\n",
    "                    if param.grad is not None:\n",
    "                        writer.add_histogram(f'Gradients/{name}', param.grad, global_step=i)\n",
    "    \n",
    "    k=0\n",
    "    sumer=0\n",
    "    for d in test_dataset:\n",
    "\n",
    "        model.eval()\n",
    "        tX, ty = d['eng_input'].to(device), d['hin_target'].to(device)\n",
    "        # test loss\n",
    "        test_logits = model(tX, ty)\n",
    "        test_loss = crition(test_logits.view(-1, test_logits.size(-1)), ty.view(-1))\n",
    "        # lat = 'UND' if len(losses_test)<50 else f\"{(sum(losses_test[-50:])/50):.4f}\"\n",
    "        sumer+=test_loss.item()\n",
    "        k+=1\n",
    "    print(\"Average Test Loss: \",sumer/(k+0.00001))\n",
    "    writer.add_scalar('Test Loss', sumer/(k+0.00001), epoch)\n",
    "    \n",
    "    save_model(model, f\"models/Bahdanau_attention_model_epoch_{epoch+1}.pth\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3408e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()\n",
    "# plt.plot(average_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "faf7a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence_with_attention(model, sentence, eng_tokenizer, hin_tokenizer, device, max_len=MAX_SENT_LEN):\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Preprocess\n",
    "    sentence = sentence.lower().replace('!', '').replace('.', '').replace('?', '')\n",
    "    tokens = eng_tokenizer.encode([sentence])[0]\n",
    "    padding_idx = eng_tokenizer.word_index[eng_tokenizer.padding_token]\n",
    "    padded_tokens = [padding_idx] * (max_len - len(tokens)) + tokens\n",
    "    src_tensor = torch.LongTensor(padded_tokens).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 2. Get BOTH encoder outputs and hidden state\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "\n",
    "        start_idx = hin_tokenizer.word_index[hin_tokenizer.start_token]\n",
    "        end_idx = hin_tokenizer.word_index[hin_tokenizer.end_token]\n",
    "        \n",
    "        input_token = torch.LongTensor([start_idx]).to(device)\n",
    "        translated_indices = []\n",
    "\n",
    "        # 3. Step through decoder\n",
    "        for _ in range(max_len):\n",
    "            # Attention Decoder now requires encoder_outputs!\n",
    "            output, hidden, _ = model.decoder(input_token, hidden, encoder_outputs)\n",
    "            \n",
    "            top1 = output.argmax(1)\n",
    "            idx = top1.item()\n",
    "            \n",
    "            if idx == end_idx:\n",
    "                break\n",
    "                \n",
    "            translated_indices.append(idx)\n",
    "            input_token = top1 \n",
    "\n",
    "    return hin_tokenizer.decode([translated_indices])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fe70a8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'> आप कैसे कैसे'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_sentence_with_attention(\n",
    "    model, \"hello how are you\", eng_tokenizer, hin_tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3a22b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
