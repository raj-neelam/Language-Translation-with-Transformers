{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "112fb076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Device name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "\n",
    "writer = SummaryWriter('../../runs/simple_transformer')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc8a45bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111234</th>\n",
       "      <td>And together with their young teachers at the ...</td>\n",
       "      <td>युवा प्रशिक्षकों के नेतृत्व में हाथियों के ये ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114491</th>\n",
       "      <td>Some phone have touch screen.</td>\n",
       "      <td>कुछ फोन में स्पर्शस्क्रीन शामिल हैं.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8452</th>\n",
       "      <td>He must also keep away from all useless works.</td>\n",
       "      <td>अन्य व्यर्थ कर्मों से भी अपने आप को दूर रखा जा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64675</th>\n",
       "      <td>Article 19 also gives a citizen the right of f...</td>\n",
       "      <td>अनुच्छेद 19 भी नागरिक को बोलने की आजादी का अधि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77582</th>\n",
       "      <td>He thinks that his left hand fast bowling is T...</td>\n",
       "      <td>उनका मानना यह भी है कि बायें हाथ की तेज गेंद त...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  English  \\\n",
       "111234  And together with their young teachers at the ...   \n",
       "114491                      Some phone have touch screen.   \n",
       "8452       He must also keep away from all useless works.   \n",
       "64675   Article 19 also gives a citizen the right of f...   \n",
       "77582   He thinks that his left hand fast bowling is T...   \n",
       "\n",
       "                                                    Hindi  \n",
       "111234  युवा प्रशिक्षकों के नेतृत्व में हाथियों के ये ...  \n",
       "114491               कुछ फोन में स्पर्शस्क्रीन शामिल हैं.  \n",
       "8452    अन्य व्यर्थ कर्मों से भी अपने आप को दूर रखा जा...  \n",
       "64675   अनुच्छेद 19 भी नागरिक को बोलने की आजादी का अधि...  \n",
       "77582   उनका मानना यह भी है कि बायें हाथ की तेज गेंद त...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/Dataset_English_Hindi.csv\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac125bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['English'].apply(lambda x: isinstance(x, str)) & data['Hindi'].apply(lambda x: isinstance(x, str))\n",
    "data = data.loc[mask].copy()\n",
    "data['English'] = data['English'].str.lower()\n",
    "data['Hindi'] = data['Hindi'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e9d7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after filtering: 77743\n"
     ]
    }
   ],
   "source": [
    "MAX_SENT_LEN = 15\n",
    "data = data[data['English'].str.split().apply(len) < MAX_SENT_LEN].copy()\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(f\"Rows after filtering: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a566f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Distribution of English Sentence Lengths'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['English'].str.split().apply(len).plot(kind='hist', bins=14, title='Distribution of English Sentence Lengths', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05dc2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, texts):\n",
    "        self.oov_token = \"<|unknown|>\"\n",
    "        self.start_token = \"<|startoftext|>\"\n",
    "        self.end_token = \"<|endoftext|>\"\n",
    "        self.padding_token = \"<|pad|>\"\n",
    "        self.word_index = {self.oov_token: 0, self.start_token: 1, self.end_token: 2, self.padding_token: 3}\n",
    "    \n",
    "        for text in texts:\n",
    "            text = text.replace('!', '')\n",
    "            text = text.replace('.', '')\n",
    "            text = text.replace('(', '')\n",
    "            text = text.replace(')', '')\n",
    "            text = text.replace('?', '')\n",
    "            text = text.replace('-', ' ')\n",
    "\n",
    "            text = text.split()\n",
    "            for word in text:\n",
    "                if word not in self.word_index:\n",
    "                    self.word_index[word] = len(self.word_index)\n",
    "        self.index_word = {idx : word for word, idx in self.word_index.items()}\n",
    "\n",
    "        self.vocab_size = len(self.word_index)\n",
    "    def encode(self, texts):\n",
    "        tokenized_texts = []\n",
    "        for text in texts:\n",
    "            text = text.replace('!', '')\n",
    "            text = text.replace('.', '')\n",
    "            text = text.replace('(', '')\n",
    "            text = text.replace(')', '')\n",
    "            text = text.replace('?', '')\n",
    "            text = text.replace('-', ' ')\n",
    "            tokenized_text = []\n",
    "            text = text.split()\n",
    "            for word in text:\n",
    "                tokenized_text.append(self.word_index.get(word, self.word_index[self.oov_token]))\n",
    "            tokenized_texts.append(tokenized_text)\n",
    "        return tokenized_texts\n",
    "    def decode(self, sequences):\n",
    "        decoded_texts = []\n",
    "        for sequence in sequences:\n",
    "            decoded_text = []\n",
    "            for index in sequence:\n",
    "                decoded_text.append(self.index_word.get(index, self.oov_token))\n",
    "            decoded_texts.append(' '.join(decoded_text))\n",
    "        return decoded_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643d75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 43114\n",
      "Hindi Vocabulary Size: 43014\n"
     ]
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(data['English'])\n",
    "hin_tokenizer = Tokenizer(data['Hindi'])\n",
    "print(f\"English Vocabulary Size: {eng_tokenizer.vocab_size}\")# 80223\n",
    "print(f\"Hindi Vocabulary Size: {hin_tokenizer.vocab_size}\")# 85059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4ecc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 81, 82, 61, 8265, 26950, 0, 0], [93, 103, 109, 2143], [122, 103, 182, 305]]\n",
      "['hello how are you raj neelam <|unknown|> <|unknown|>', 'this is a test', 'what is your name']\n",
      "\n",
      "[[27204, 121, 122, 123, 3304, 28590, 5205, 0], [142, 110, 14353, 79], [403, 432, 113, 79]]\n",
      "['नमस्ते आप कैसे हैं राज नीलम गौरव <|unknown|>', 'यह एक परीक्षण है', 'तुम्हारा नाम क्या है']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = eng_tokenizer.encode([\"hello how are you raj neelam gaurav convolution\", \"this is a test\", \"what is your name\"])\n",
    "print(tokenized_text)\n",
    "print(eng_tokenizer.decode(tokenized_text))\n",
    "print()\n",
    "tokenized_text = hin_tokenizer.encode([\"नमस्ते आप कैसे हैं राज नीलम गौरव कन्वोल्यूशन\", \"यह एक परीक्षण है\", \"तुम्हारा नाम क्या है\"])\n",
    "print(tokenized_text)\n",
    "print(hin_tokenizer.decode(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2284e149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69968, 7775)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data, test_data = train_test_split(data, test_size=0.1)\n",
    "len(data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1df5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 256\n",
    "BATCH_SIZE = 128\n",
    "NEM_LAYER = 4\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "START_LR = 0.001\n",
    "END_LR = 0.00005\n",
    "TOTAL_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64bf46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, eng_tokenizer, hin_tokenizer):\n",
    "        self.data = data\n",
    "        self.eng_tokenizer = eng_tokenizer\n",
    "        self.hin_tokenizer = hin_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng_text = self.data.iloc[idx]['English']\n",
    "        hin_text = self.data.iloc[idx]['Hindi']\n",
    "\n",
    "        eng_tokenized = self.eng_tokenizer.encode([eng_text])[0]\n",
    "        if len(eng_tokenized) > MAX_SENT_LEN:\n",
    "            eng_tokenized = eng_tokenized[:MAX_SENT_LEN]\n",
    "\n",
    "        eng_padded = [self.eng_tokenizer.word_index[self.eng_tokenizer.padding_token]] * (MAX_SENT_LEN - len(eng_tokenized)) + eng_tokenized\n",
    "\n",
    "        hin_tokenized = self.hin_tokenizer.encode([hin_text])[0]\n",
    "\n",
    "        if len(hin_tokenized) > MAX_SENT_LEN - 2:\n",
    "            hin_tokenized = hin_tokenized[:MAX_SENT_LEN - 2]\n",
    "        hin_padded = [self.hin_tokenizer.word_index[self.hin_tokenizer.start_token]] + hin_tokenized + [self.hin_tokenizer.word_index[self.hin_tokenizer.end_token]] + [self.hin_tokenizer.word_index[self.hin_tokenizer.padding_token]] * (MAX_SENT_LEN - len(hin_tokenized) - 2)\n",
    "\n",
    "        return {\n",
    "            'eng_input': torch.tensor(eng_padded),\n",
    "            'hin_target': torch.tensor(hin_padded)\n",
    "        }\n",
    "\n",
    "dataset = DataLoader(MyDataset(data, eng_tokenizer, hin_tokenizer), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = DataLoader(MyDataset(test_data, eng_tokenizer, hin_tokenizer), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c300d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_positional_encoding(context, dimension):\n",
    "    pos = np.arange(context)[:, np.newaxis]\n",
    "    div_term = 1 / (10000 ** (np.arange(0, dimension, 2) / dimension))\n",
    "    \n",
    "    enc = np.zeros((context, dimension))\n",
    "    enc[:, 0::2] = np.sin(pos * div_term)\n",
    "    enc[:, 1::2] = np.cos(pos * div_term)\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a26b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Q = nn.Linear(EMBED_DIM, EMBED_DIM)\n",
    "        self.K = nn.Linear(EMBED_DIM, EMBED_DIM)\n",
    "        self.V = nn.Linear(EMBED_DIM, EMBED_DIM)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        q = self.Q(x)\n",
    "        k = self.K(x)\n",
    "        v = self.V(x)\n",
    "\n",
    "        attention_scores = q @ k.transpose(-2, -1)\n",
    "        scores = attention_scores / (EMBED_DIM ** 0.5)\n",
    "        scores = scores.softmax(dim=-1)\n",
    "\n",
    "        output = torch.matmul(scores, v)\n",
    "        return output    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a8cae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Masked_Self_Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Q = nn.Linear(EMBED_DIM, EMBED_DIM)\n",
    "        self.K = nn.Linear(EMBED_DIM, EMBED_DIM)\n",
    "        self.V = nn.Linear(EMBED_DIM, EMBED_DIM)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        q = self.Q(x)\n",
    "        k = self.K(x)\n",
    "        v = self.V(x)\n",
    "\n",
    "        attention_scores = q @ k.transpose(-2, -1)\n",
    "        scores = attention_scores / (EMBED_DIM ** 0.5)\n",
    "\n",
    "        B, C, _ = x.shape\n",
    "        mask = torch.tril(torch.ones(C, C, device=x.device)).bool()\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        scores = scores.softmax(dim=-1)\n",
    "\n",
    "        output = torch.matmul(scores, v)\n",
    "        return output    \n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     q = self.Q(x)\n",
    "    #     k = self.K(x)\n",
    "    #     v = self.V(x)\n",
    "\n",
    "    #     attention_scores = q @ k.transpose(-2, -1)\n",
    "    #     scores = attention_scores / (EMBED_DIM ** 0.5)\n",
    "\n",
    "    #     B, C, _ = x.shape\n",
    "    #     # 1. Causal mask\n",
    "    #     causal_mask = torch.tril(torch.ones(C, C, device=x.device)).bool()\n",
    "\n",
    "    #     # 2. Padding mask\n",
    "    #     # Detect padding positions from embeddings (safe assumption: pad embedding is consistent)\n",
    "    #     pad_mask = (x.abs().sum(dim=-1) != 0)  # (B, C)\n",
    "    #     pad_mask = pad_mask.unsqueeze(1).expand(B, C, C)\n",
    "\n",
    "    #     # Combine masks\n",
    "    #     combined_mask = causal_mask & pad_mask\n",
    "\n",
    "    #     scores = scores.masked_fill(~combined_mask, -1e9)\n",
    "\n",
    "    #     scores = scores.softmax(dim=-1)\n",
    "\n",
    "    #     output = torch.matmul(scores, v)\n",
    "    #     return output    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc60c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Q = nn.Linear(EMBED_DIM, EMBED_DIM)\n",
    "        self.K = nn.Linear(EMBED_DIM, EMBED_DIM)\n",
    "        self.V = nn.Linear(EMBED_DIM, EMBED_DIM)\n",
    "    def forward(self, hin_vec, eng_vec):\n",
    "        Q = self.Q(hin_vec)\n",
    "        K = self.K(eng_vec)\n",
    "        V = self.V(eng_vec)\n",
    "        \n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / (EMBED_DIM ** 0.5)\n",
    "        scores = attention_scores.softmax(dim=-1)\n",
    "\n",
    "        output = torch.matmul(scores, V)\n",
    "        return output    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78518f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Encoder_Block(nn.Module):\n",
    "    def __init__(self): # inp_dim is vocab size of the english tokenizer\n",
    "        super().__init__()\n",
    "        self.self_attention = Self_Attention()\n",
    "        self.norm1 = nn.LayerNorm(EMBED_DIM)\n",
    "        self.norm2 = nn.LayerNorm(EMBED_DIM)\n",
    "        self.ffnn = nn.Sequential(\n",
    "            nn.Linear(EMBED_DIM, 3*EMBED_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3*EMBED_DIM, EMBED_DIM)\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(DROPOUT_RATE)\n",
    "        self.dropout2 = nn.Dropout(DROPOUT_RATE)\n",
    "\n",
    "\n",
    "    def forward(self, words_vec):  \n",
    "        informed_words = self.self_attention(words_vec)   # (B, C, E) Attention\n",
    "        informed_words = self.dropout1(informed_words) # droupout\n",
    "\n",
    "        words_vec = words_vec + informed_words\n",
    "        words_vec = self.norm1(words_vec) # (B, C, E) Add & Normalize\n",
    "\n",
    "        thought_words = self.ffnn(words_vec) # feef forward neural network\n",
    "\n",
    "        thought_words = self.dropout2(thought_words) # droupout\n",
    "        words_vec = words_vec + thought_words\n",
    "        words_vec = self.norm2(words_vec) # (B, C, E) Add & Normalize\n",
    "\n",
    "        return words_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3630f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Full_Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.word_embedding = nn.Embedding(input_dim, EMBED_DIM)\n",
    "        pe = torch.tensor(\n",
    "            create_positional_encoding(MAX_SENT_LEN, EMBED_DIM),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        self.register_buffer(\"positional_encoding\", pe) # register and save positional encodings\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Transformer_Encoder_Block() for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):                             # (B, C)\n",
    "        embedded = self.word_embedding(x)               # (B, C, E) batch, context_length, embedding\n",
    "        words_vec = self.positional_encoding[:embedded.size(1)] + embedded   # (B, C, E) Adding positonal embeddings\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            words_vec = block(words_vec)\n",
    "        \n",
    "        return words_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc8d3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Decoder_Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attention = Masked_Self_Attention()\n",
    "        self.cross_attention = Cross_Attention() # To do\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(EMBED_DIM, 3 * EMBED_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3 * EMBED_DIM, EMBED_DIM)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(EMBED_DIM)\n",
    "        self.norm2 = nn.LayerNorm(EMBED_DIM)\n",
    "        self.norm3 = nn.LayerNorm(EMBED_DIM)\n",
    "        self.dropout1 = nn.Dropout(DROPOUT_RATE)\n",
    "        self.dropout2 = nn.Dropout(DROPOUT_RATE)\n",
    "        self.dropout3 = nn.Dropout(DROPOUT_RATE)\n",
    "    \n",
    "    def forward(self, word_vec, encoder_output):\n",
    "        informed_words = self.attention(word_vec)\n",
    "        informed_words = self.dropout1(informed_words)\n",
    "        word_vec = self.norm1(informed_words + word_vec)\n",
    "\n",
    "        informed_words = self.cross_attention(word_vec, encoder_output)\n",
    "        informed_words = self.dropout2(informed_words)\n",
    "        word_vec = self.norm2(informed_words + word_vec)\n",
    "\n",
    "        informed_words = self.feed_forward(word_vec)\n",
    "        informed_words = self.dropout3(informed_words)\n",
    "        word_vec = self.norm3(informed_words + word_vec)\n",
    "        \n",
    "        return word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "804590dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Full_Decoder(nn.Module):\n",
    "    def __init__(self, hindi_input_dim, num_layers): # hindi input vocab size\n",
    "        super().__init__()\n",
    "        self.hindi_embedding = nn.Embedding(hindi_input_dim, EMBED_DIM)\n",
    "        pe = torch.tensor(\n",
    "            create_positional_encoding(MAX_SENT_LEN, EMBED_DIM),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        self.register_buffer(\"positional_encoding\", pe) # register and save positional encodings\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Transformer_Decoder_Block() for _ in range(num_layers)]\n",
    "        )\n",
    "        self.unembedding = nn.Linear(EMBED_DIM, hindi_input_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x, encoder_output):                             # (B, C)\n",
    "        hindi_embedded = self.hindi_embedding(x)               # (B, C, E) batch, context_length, embedding\n",
    "        hindi_words_vec = self.positional_encoding[:hindi_embedded.size(1)] + hindi_embedded   # (B, C, E) Adding positonal embeddings\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            hindi_words_vec = block(hindi_words_vec, encoder_output)\n",
    "        \n",
    "        hindi_words_vec_logits = self.unembedding(hindi_words_vec)\n",
    "        return hindi_words_vec_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e01b6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language_Transformer(nn.Module):\n",
    "    def __init__(self, english_vocab, hindi_vocab, num_layers):\n",
    "        super().__init__()\n",
    "        self.encoder = Full_Encoder(english_vocab, num_layers)\n",
    "        self.decoder = Full_Decoder(hindi_vocab, num_layers)\n",
    "    \n",
    "    def forward(self, english_tokens, hindi_tokens):\n",
    "        english_encoder_output = self.encoder(english_tokens)\n",
    "        hindi_vec = self.decoder(hindi_tokens, english_encoder_output)\n",
    "        return hindi_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47ad428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Language_Transformer(eng_tokenizer.vocab_size, hin_tokenizer.vocab_size, NEM_LAYER).to(device)\n",
    "\n",
    "data_iter = iter(dataset)\n",
    "sample_batch = next(data_iter)\n",
    "X_sample = sample_batch['eng_input'].to(device)\n",
    "y_sample = sample_batch['hin_target'].to(device)\n",
    "writer.add_graph(model, [X_sample, y_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a35ebbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved weights and set model to evaluation mode\n",
    "\n",
    "# checkpoint_path = \"models/simple_transformer_1.pth\"\n",
    "# state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.to(device)\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99830cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=hin_tokenizer.word_index[hin_tokenizer.padding_token])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=START_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59e62a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    # print(f\"Model saved to {filepath}\")\n",
    "    torch.cuda.empty_cache()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1732b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_lr(epoch, total_epochs, start_lr, end_lr):\n",
    "    \"\"\"\n",
    "    Calculates a linearly interpolated learning rate.\n",
    "    \"\"\"\n",
    "    if epoch >= total_epochs:\n",
    "        return end_lr\n",
    "    \n",
    "    # Formula: start + (end - start) * (progress)\n",
    "    lr = start_lr + (end_lr - start_lr) * (epoch / total_epochs)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4859ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 547/547 [03:11<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  5.787992333717057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 547/547 [02:48<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  5.086605363800126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 547/547 [03:15<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  4.647401548111442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 547/547 [03:24<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  4.452782553675774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 547/547 [03:01<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  4.392344677142281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 547/547 [02:30<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  4.411887082709811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 547/547 [02:57<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  4.4481219128790235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 547/547 [03:17<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  4.525313921422557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 547/547 [03:22<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss:  4.624467986668736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10:  10%|▉         | 52/547 [00:16<02:40,  3.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m decoder_target \u001b[38;5;241m=\u001b[39m y[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\n\u001b[0;32m     22\u001b[0m     logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     23\u001b[0m     decoder_target\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m )    \n\u001b[0;32m     25\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem(), epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(tqdm_bar) \u001b[38;5;241m+\u001b[39m i)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m, in \u001b[0;36mLanguage_Transformer.forward\u001b[1;34m(self, english_tokens, hindi_tokens)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, english_tokens, hindi_tokens):\n\u001b[0;32m      8\u001b[0m     english_encoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(english_tokens)\n\u001b[1;32m----> 9\u001b[0m     hindi_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhindi_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish_encoder_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hindi_vec\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[19], line 21\u001b[0m, in \u001b[0;36mFull_Decoder.forward\u001b[1;34m(self, x, encoder_output)\u001b[0m\n\u001b[0;32m     18\u001b[0m hindi_words_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding[:hindi_embedded\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m+\u001b[39m hindi_embedded   \u001b[38;5;66;03m# (B, C, E) Adding positonal embeddings\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m---> 21\u001b[0m     hindi_words_vec \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhindi_words_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m hindi_words_vec_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munembedding(hindi_words_vec)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hindi_words_vec_logits\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[18], line 27\u001b[0m, in \u001b[0;36mTransformer_Decoder_Block.forward\u001b[1;34m(self, word_vec, encoder_output)\u001b[0m\n\u001b[0;32m     24\u001b[0m informed_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(informed_words)\n\u001b[0;32m     25\u001b[0m word_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(informed_words \u001b[38;5;241m+\u001b[39m word_vec)\n\u001b[1;32m---> 27\u001b[0m informed_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m informed_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout3(informed_words)\n\u001b[0;32m     29\u001b[0m word_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(informed_words \u001b[38;5;241m+\u001b[39m word_vec)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    Runs the forward pass.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(0, TOTAL_EPOCHS):\n",
    "    lr = get_linear_lr(epoch, TOTAL_EPOCHS, START_LR, END_LR)\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    tqdm_bar = tqdm(dataset)\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "    for i, batch in enumerate(tqdm_bar):\n",
    "        # load batch to device\n",
    "        X, y = batch['eng_input'].to(device), batch['hin_target'].to(device)\n",
    "\n",
    "        # print(\"Max Hindi token id:\", y.max().item())\n",
    "        # print(\"Hindi embedding vocab size:\", model.decoder.hindi_embedding.num_embeddings)\n",
    "        # break\n",
    "\n",
    "        decoder_input = y[:, :-1]\n",
    "        decoder_target = y[:, 1:]\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(X, decoder_input)\n",
    "        loss = criterion(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            decoder_target.reshape(-1)\n",
    "        )    \n",
    "        writer.add_scalar('Training Loss', loss.item(), epoch * len(tqdm_bar) + i)\n",
    "        writer.add_scalar('Learning Rate', optimizer.param_groups[0]['lr'], epoch * len(tqdm_bar) + i)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tqdm_bar.set_description(f\"Epoch: {epoch+1}\")\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    writer.add_histogram(f'Weights/{name}', param, global_step=i)\n",
    "                    # Logging gradients\n",
    "                    if param.grad is not None:\n",
    "                        writer.add_histogram(f'Gradients/{name}', param.grad, global_step=i)\n",
    "    \n",
    "    k=0\n",
    "    sumer=0\n",
    "    for d in test_dataset:\n",
    "\n",
    "        model.eval()\n",
    "        tX, ty = d['eng_input'].to(device), d['hin_target'].to(device)\n",
    "        decoder_input = ty[:, :-1]\n",
    "        decoder_target = ty[:, 1:]\n",
    "        # test loss\n",
    "        test_logits = model(tX, decoder_input)\n",
    "        test_loss = criterion(test_logits.view(-1, test_logits.size(-1)), decoder_target.reshape(-1))\n",
    "        sumer+=test_loss.item()\n",
    "        k+=1\n",
    "    print(\"Average Test Loss: \",sumer/(k+0.00001))\n",
    "    writer.add_scalar('Test Loss', sumer/(k+0.00001), epoch)\n",
    "    \n",
    "    save_model(model, f\"../../models/simple_transformer_epoch_{epoch+1}.pth\")\n",
    "writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1b3a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hello brother how are you can you open the door for me\n",
      "Translation: मजबूत भाई आप मेरे लिए योग्यताएं कर सकते हैं क्या मैं आप मेरे\n"
     ]
    }
   ],
   "source": [
    "user_query = input(\"Enter English Sentence To Translate\")\n",
    "\n",
    "def translate(sentence):\n",
    "    model.eval()\n",
    "    # Tokenize English sentence\n",
    "    eng_tokenized = eng_tokenizer.encode([sentence])[0]\n",
    "    if len(eng_tokenized) > MAX_SENT_LEN:\n",
    "        eng_tokenized = eng_tokenized[:MAX_SENT_LEN]\n",
    "    eng_padded = [eng_tokenizer.word_index[eng_tokenizer.padding_token]] * (MAX_SENT_LEN - len(eng_tokenized)) + eng_tokenized\n",
    "    eng_tensor = torch.tensor([eng_padded]).to(device)\n",
    "\n",
    "    # Encode\n",
    "    with torch.no_grad():\n",
    "        encoder_output = model.encoder(eng_tensor)\n",
    "\n",
    "    # Decode (Auto-regressive)\n",
    "    hin_tokenized = [hin_tokenizer.word_index[hin_tokenizer.start_token]]\n",
    "    \n",
    "    for _ in range(MAX_SENT_LEN):\n",
    "        hin_tensor = torch.tensor([hin_tokenized]).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model.decoder(hin_tensor, encoder_output)\n",
    "        \n",
    "        # Get last token logits\n",
    "        last_token_logits = logits[0, -1, :]\n",
    "        predicted_token_id = torch.argmax(last_token_logits).item()\n",
    "        \n",
    "        if predicted_token_id == hin_tokenizer.word_index[hin_tokenizer.end_token]:\n",
    "            break\n",
    "            \n",
    "        hin_tokenized.append(predicted_token_id)\n",
    "        \n",
    "    # Decode to text\n",
    "    translated_text = hin_tokenizer.decode([hin_tokenized[1:]])[0] # Skip start token\n",
    "    return translated_text\n",
    "\n",
    "print(f\"Input: {user_query}\")\n",
    "print(f\"Translation: {translate(user_query)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f13ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
