{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112fb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "writer = SummaryWriter('runs/Luong_attention_LSTM')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a45bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/Dataset_English_Hindi.csv\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac125bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['English'].apply(lambda x: isinstance(x, str)) & data['Hindi'].apply(lambda x: isinstance(x, str))\n",
    "data = data.loc[mask].copy()\n",
    "data['English'] = data['English'].str.lower()\n",
    "data['Hindi'] = data['Hindi'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e9d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 15\n",
    "data = data[data['English'].str.split().apply(len) < MAX_SENT_LEN].copy()\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(f\"Rows after filtering: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05dc2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, texts):\n",
    "        self.oov_token = \"<|unknown|>\"\n",
    "        self.start_token = \"<|startoftext|>\"\n",
    "        self.end_token = \"<|endoftext|>\"\n",
    "        self.padding_token = \"<|pad|>\"\n",
    "        self.word_index = {self.oov_token: 0, self.start_token: 1, self.end_token: 2, self.padding_token: 3}\n",
    "    \n",
    "        for text in texts:\n",
    "            text = text.replace('!', '')\n",
    "            text = text.replace('.', '')\n",
    "            text = text.replace('(', '')\n",
    "            text = text.replace(')', '')\n",
    "            text = text.replace('?', '')\n",
    "            text = text.replace('-', ' ')\n",
    "\n",
    "            text = text.split()\n",
    "            for word in text:\n",
    "                if word not in self.word_index:\n",
    "                    self.word_index[word] = len(self.word_index) + 1\n",
    "        self.index_word = {idx : word for word, idx in self.word_index.items()}\n",
    "\n",
    "        self.vocab_size = len(self.word_index)\n",
    "    def encode(self, texts):\n",
    "        tokenized_texts = []\n",
    "        for text in texts:\n",
    "            text = text.replace('!', '')\n",
    "            text = text.replace('.', '')\n",
    "            text = text.replace('(', '')\n",
    "            text = text.replace(')', '')\n",
    "            text = text.replace('?', '')\n",
    "            text = text.replace('-', ' ')\n",
    "            tokenized_text = []\n",
    "            text = text.split()\n",
    "            for word in text:\n",
    "                tokenized_text.append(self.word_index.get(word, self.word_index[self.oov_token]))\n",
    "            tokenized_texts.append(tokenized_text)\n",
    "        return tokenized_texts\n",
    "    def decode(self, sequences):\n",
    "        decoded_texts = []\n",
    "        for sequence in sequences:\n",
    "            decoded_text = []\n",
    "            for index in sequence:\n",
    "                decoded_text.append(self.index_word.get(index, self.oov_token))\n",
    "            decoded_texts.append(' '.join(decoded_text))\n",
    "        return decoded_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d75f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokenizer = Tokenizer(data['English'])\n",
    "hin_tokenizer = Tokenizer(data['Hindi'])\n",
    "print(f\"English Vocabulary Size: {eng_tokenizer.vocab_size}\")\n",
    "print(f\"Hindi Vocabulary Size: {hin_tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "START_LR = 0.005\n",
    "END_LR = 0.000001\n",
    "TOTAL_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, test_data = train_test_split(data, test_size=0.05)\n",
    "print(len(data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, eng_tokenizer, hin_tokenizer):\n",
    "        self.data = data\n",
    "        self.eng_tokenizer = eng_tokenizer\n",
    "        self.hin_tokenizer = hin_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng_text = self.data.iloc[idx]['English']\n",
    "        hin_text = self.data.iloc[idx]['Hindi']\n",
    "\n",
    "        eng_tokenized = self.eng_tokenizer.encode([eng_text])[0]\n",
    "        if len(eng_tokenized) > MAX_SENT_LEN:\n",
    "            eng_tokenized = eng_tokenized[:MAX_SENT_LEN]\n",
    "\n",
    "        eng_padded = [self.eng_tokenizer.word_index[self.eng_tokenizer.padding_token]] * (MAX_SENT_LEN - len(eng_tokenized)) + eng_tokenized\n",
    "\n",
    "        hin_tokenized = self.hin_tokenizer.encode([hin_text])[0]\n",
    "\n",
    "        if len(hin_tokenized) > MAX_SENT_LEN - 2:\n",
    "            hin_tokenized = hin_tokenized[:MAX_SENT_LEN - 2]\n",
    "        hin_padded = [self.hin_tokenizer.word_index[self.hin_tokenizer.start_token]] + hin_tokenized + [self.hin_tokenizer.word_index[self.hin_tokenizer.end_token]] + [self.hin_tokenizer.word_index[self.hin_tokenizer.padding_token]] * (MAX_SENT_LEN - len(hin_tokenized) - 2)\n",
    "\n",
    "        return {\n",
    "            'eng_input': torch.tensor(eng_padded),\n",
    "            'hin_target': torch.tensor(hin_padded)\n",
    "        }\n",
    "\n",
    "dataset = DataLoader(MyDataset(data, eng_tokenizer, hin_tokenizer), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = DataLoader(MyDataset(test_data, eng_tokenizer, hin_tokenizer), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78518f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, EMBED_DIM)\n",
    "        self.rnn = nn.LSTM(EMBED_DIM, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        outputs, (h, c) = self.rnn(self.embedding(src))\n",
    "        return outputs, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "luong_attn",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        # Luong Attention 'General' Score: score(h_t, h_s) = h_t^T * W * h_s\n",
    "        self.W = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hidden: (B, H) - this corresponds to h_t (current step hidden state)\n",
    "        # encoder_outputs: (B, T, H) - corresponds to all h_s\n",
    "\n",
    "        # Calculate Energy/Score\n",
    "        # W(encoder_outputs) -> (B, T, H)\n",
    "        # decoder_hidden.unsqueeze(2) -> (B, H, 1)\n",
    "        # bmm((B, T, H), (B, H, 1)) -> (B, T, 1)\n",
    "        \n",
    "        # Project encoder outputs for general score\n",
    "        energy = self.W(encoder_outputs) # (B, T, H)\n",
    "        \n",
    "        # Calculate score: h_t . W(h_s)\n",
    "        scores = torch.bmm(energy, decoder_hidden.unsqueeze(2)) # (B, T, 1)\n",
    "        \n",
    "        # Attention weights\n",
    "        attn_weights = F.softmax(scores, dim=1) # (B, T, 1)\n",
    "        \n",
    "        # Calculate Context Vector\n",
    "        # encoder_outputs: (B, T, H)\n",
    "        # attn_weights.transpose(1, 2) -> (B, 1, T)\n",
    "        # bmm((B, 1, T), (B, T, H)) -> (B, 1, H)\n",
    "        context = torch.bmm(attn_weights.transpose(1, 2), encoder_outputs)\n",
    "        \n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "luong_decoder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, hidden_dim, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.attention = LuongAttention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim + hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_token, hidden, encoder_outputs):\n",
    "        # input_token: (B)\n",
    "        input_token = input_token.unsqueeze(1) # (B, 1)\n",
    "        embedded = self.embedding(input_token) # (B, 1, Emb)\n",
    "\n",
    "        # Run RNN step\n",
    "        # In Luong, we typically feed just the embedding to the RNN (or concatenated with prev context if Input Feeding)\n",
    "        # Here we follow simple approach: Emb -> RNN -> Attn -> Out\n",
    "        rnn_output, (h, c) = self.rnn(embedded, hidden)\n",
    "        # rnn_output: (B, 1, H)\n",
    "\n",
    "        # Calculate Attention\n",
    "        # Use the current RNN output as the query\n",
    "        context, weights = self.attention(rnn_output.squeeze(1), encoder_outputs)\n",
    "        # context: (B, 1, H)\n",
    "\n",
    "        # Concatenate RNN output and Context Vector\n",
    "        # (B, 1, H) cat (B, 1, H) -> (B, 1, 2H)\n",
    "        combined = torch.cat((rnn_output, context), dim=2)\n",
    "        \n",
    "        # Final prediction\n",
    "        prediction = self.fc(combined.squeeze(1))\n",
    "\n",
    "        return prediction, (h, c), weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seq2seq_luong",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size).to(self.device)\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        input_token = trg[:, 0] # <start> token\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, _ = self.decoder(input_token, hidden, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            \n",
    "            # Teacher Forcing\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input_token = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_init",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=eng_tokenizer.vocab_size+1, hidden_dim=HIDDEN_DIM)\n",
    "decoder = LuongDecoder(output_dim=hin_tokenizer.vocab_size+1, embed_dim=EMBED_DIM, hidden_dim=HIDDEN_DIM)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optim_loss",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=hin_tokenizer.word_index[hin_tokenizer.padding_token])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=START_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, iterator, optimizer, criterion, clip=1.0):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in tqdm(iterator):\n",
    "        src = batch['eng_input'].to(device)\n",
    "        trg = batch['hin_target'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # trg: [batch_size, trg_len] -> [batch_size * (trg_len-1)] (exclude start token for loss)\n",
    "        # output: [batch_size, trg_len, vocab] -> [batch_size * (trg_len-1), vocab]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            src = batch['eng_input'].to(device)\n",
    "            trg = batch['hin_target'].to(device)\n",
    "\n",
    "            output = model(src, trg, 0) # Turn off teacher forcing\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(TOTAL_EPOCHS):\n",
    "    train_loss = train_epoch(model, dataset, optimizer, criterion)\n",
    "    valid_loss = evaluate(model, test_dataset, criterion)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')\n",
    "    writer.add_scalar('Training Loss', train_loss, epoch)\n",
    "    writer.add_scalar('Validation Loss', valid_loss, epoch)\n",
    "    \n",
    "    torch.save(model.state_dict(), f'model/Luong_attention_model_epoch_{epoch}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
